{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"changelog.html","title":"Change Log","text":"","tags":["changelog"]},{"location":"changelog.html#v100","title":"v1.0.0","text":"<p>This release introduces significant new features and improvements to the Anoma specification, focusing on:</p> <ul> <li>protocol adapter integration</li> <li>resource machine specifications</li> <li>application-specific documentation</li> </ul> <p>The node architecture has been removed from this (latest) release, but can be found in the v0.2.0 release. We plan to integrate it back in the future, when v2.0.0 comes in.</p>","tags":["changelog"]},{"location":"changelog.html#v020","title":"v0.2.0","text":"<p>This release introduces significant new features and improvements to the Anoma specification, including protocol adapter integration, engine simulation capabilities, and major updates to the Resource Machine specifications. Key highlights include:</p> <ul> <li>Added comprehensive protocol adapter integration documentation</li> <li>Introduced interactive engine simulator with message passing support</li> <li>Updated Resource Machine specifications (post-HHH edition)</li> <li>Reorganized documentation structure and navigation</li> <li>Updated to Juvix stdlib v0.11.0</li> <li>Various CI/CD improvements and tooling updates</li> </ul>","tags":["changelog"]},{"location":"changelog.html#features","title":"Features","text":"<ul> <li>System architecture<ul> <li>#356: Add protocol adapter integration pages</li> <li>#359: Update RM specs (post-HHH edition)</li> <li>#369: Rename <code>resourceLogicProofs</code> to <code>logicVerifierInputs</code></li> </ul> </li> <li>Node architecture<ul> <li>#347: Implement interactive engine simulator with message passing support</li> <li>#355: Add engine simulator with message passing and pretty printing</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#358: Deploy pages to another repo</li> <li>#367: Remove redundant deployment</li> <li>#374: EVM-PA: use permalinks and small improvements</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#fixes","title":"Fixes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#343: Fix mkdocs nav</li> <li>#351: Fix/update github actions</li> <li>#363: Enforce pre-commit checks and remove auto-fix</li> <li>#364: Remove pull request template</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#381: Reorganize navigation in mkdocs.yml</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#changes","title":"Changes","text":"<ul> <li>Juvix types and updates<ul> <li>#361: Bump to stdlib 0.11.0 and name convention used for user-defined data types</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#365: Update project configuration and tooling</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v014","title":"v0.1.4","text":"<p>This release focuses on improving the prose, layout, and documentation structure. Key changes include:</p> <ul> <li>Reorganized node architecture documentation for better clarity</li> <li>Reorganized the navigation bar to be more consistent and easier to use</li> <li>Added a new tutorial: Anomian</li> <li>Several prose improvements on engines, e.g: Mempool Worker Engine,   Executor Engine, Shard Engine</li> <li>CSS changes to improve the layout and readability of the website, like   better separation for headers and footers that improve, for example, the   readability of message interfaces</li> <li>Updated Juvix type definitions to match latest standards</li> <li>Added new definitions for Prelude</li> <li>Improved template engine documentation for easier engine creation</li> </ul>","tags":["changelog"]},{"location":"changelog.html#features_1","title":"Features","text":"<ul> <li>System architecture<ul> <li>#334: Add deletion criterion to delete blobs immediately</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#fixes_1","title":"Fixes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#297: Fixes for issues seen in v0.1.3</li> <li>#306: Add data structures and interfaces used by RM</li> <li>#307: Prose improvements for commitment, decryption, and identity   management engines</li> <li>#308: The Little Anomian</li> <li>#309: Heindel has written up their two cents on the Anomian</li> <li>#310: Heindel/Anomian review v0.2 some ideas for improvements</li> <li>#311: Prose improvements for   Mempool Worker Engine, Executor Engine, and Shard Engine's descriptions.</li> <li>#312: nix flake update to   support Juvix v0.6.9</li> <li>#313: Revision of all message interfaces but not for networking's   engines</li> <li>#314: Add more fixes for message interfaces for consistency</li> <li>#315: Add a few corrections to the Anomian doc</li> <li>#320: Update Network subsystems' engine to comply standard</li> <li>#328: Move string comparison to prelude</li> <li>#331: RM type fixes</li> <li>#332: Improve layout, documentation structure, navigation and   readability with indexes, tags and descriptions</li> <li>#336: some changes, proposed as a result of specs overall review   (revamped)</li> <li>#337: Heindel/anthony/prose 3 suggestions for fixing the markdown</li> </ul> </li> <li>System architecture<ul> <li>#334: Add missing deletion criterion to delete blobs after the   transaction</li> </ul> </li> <li>Juvix types and updates<ul> <li>#298: Update juvix v0.6.9</li> <li>#302: Prelude improvements</li> <li>#305: Add most of the types for RM specs</li> <li>#321: Add Runnable trait and make ordering engines parametric</li> <li>#329: Refactor type definitions to use simplified syntax</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v013","title":"v0.1.3","text":"<p>The major change in this release is the gas payment system introduced in #286, and the description of messages in the Networking subsystem introduced in #294.</p>","tags":["changelog"]},{"location":"changelog.html#fixes_2","title":"Fixes","text":"<ul> <li>Node architecture<ul> <li>#290: Fix english   description for guards to match the Juvix types in Engine Behaviour.</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#288: Improve primitive interfaces diagrams. Use LR mermaid option.</li> </ul> </li> <li>System architecture<ul> <li>#293: Fix formatting issues,   typos, warnings, and broken links related to Proving   system definitions.</li> </ul> </li> </ul> <ul> <li>Tutorial and documentation<ul> <li>#280: Guides: Add hard and soft   requirements for writing pages in the Anoma Specification.</li> <li>#284: Add minimal version of   the template (not visible in the website) and related refactors.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#changes_1","title":"Changes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#296: Add next/prev buttons,   fix footer, change font, add buttons to view/edit source code, and links to   the GitHub repository.</li> </ul> </li> <li>Juvix types and updates<ul> <li>#294: Bump up Juvix version   to v0.6.9 , reorder <code>MailboxID</code> alias, and update Stdlib to v0.9.0</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#features_2","title":"Features","text":"<ul> <li>Python-related changes<ul> <li>#291: Add new command tool   <code>nspec</code> to create new engines based on the minimal version of the Template     Engine files.</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#286: Incorporated gas   payments description. Additionally, made several improvements such as   switching to wiki-style links, adding icons, clarifying proof inputs, fixing   rendering issues, and various other enhancements.</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#292: Move template/template_minimum engines to   docs/tutorial/engines folder. Update imports accordingly.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v012","title":"v0.1.2","text":"<p>Progress on translating the old specification to the new Juvix codebase, fixing typechecking errors. Removed unsupported documents from the codebase. Building specs no longer requires Juvix by default - use <code>PROCESS_JUVIX=true</code> flag with mkdocs to process Juvix Markdown.</p>","tags":["changelog"]},{"location":"changelog.html#fixes_3","title":"Fixes","text":"<ul> <li>Node architecture<ul> <li>#235: Revisit Decryption Engine. Changes to the messages,   environment, and behaviour types to conform the recent template changes.</li> <li>#236: Revisit Encryption Engine and Reads Engine. These are   bundled since they rely on eachother's messages. Changes to the messages, environment, and behavior types to conform   to the recent template changes</li> <li>#262: Updatewriting conventions, Fix template   behaviour diagrams and update Mkdocs Na</li> <li>#263: To the Hardware     Subsystem section, add Local Key Value Store Engine , Logging     Engine and Local Time Series Storage Engine, Wall Clock Engine.</li> <li>#268: Add to Anoma Configuration section, the Identity Subsystem.</li> <li>#269: Fix type error due to   not making configs when spawning engines in Identity Management Engine.</li> <li>#273: Replace X Machine by X   Subsystem in the Node Architecture section.</li> </ul> </li> <li>Python-related changes<ul> <li>#271: update mkdocs juvix plugin v0.4.8</li> <li>#272: Update mkdocs juvix plugin v0.4.9</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#195: Optimize documentation build process and upgrade dependencies</li> <li>#262: Template fixes: diagrams, nav</li> <li>#266: Remove old   documentation and update table of contents: Remove basic-abstractions,   scope, applications, implementations, and several other files that were   decided not to be included in this version of the specification.</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#257: Add description of our   Git workflow and new integration   branches strategy.</li> <li>#265: Rename <code>TemplateCfg</code>   to <code>TemplateLocalCfg</code>, add <code>TemplateCfg</code> similar to <code>TemplateEnv</code>, apply   the same to <code>Ticker</code>.</li> <li>#274: Update engine writing   conventions: #update-the-table-of-contents   and Table of Contents.</li> </ul> </li> <li>Juvix types and updates<ul> <li>#267: Fix all the type   checking errors in engine definitions.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v011","title":"v0.1.1","text":"<p>Major revision of the engine definitions, the template, and the ticker engine.</p>","tags":["changelog"]},{"location":"changelog.html#features_3","title":"Features","text":"<ul> <li>Repository maintenance and CI<ul> <li>#217: Update template engine   files to be more consistent, use backticks for Juvix terms/types in   headlines, uncollapsed sections for type constructors arguments in template   engine files, and auxiliary sections of Juvix code are always collapsed.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#fixes_4","title":"Fixes","text":"<ul> <li>Node architecture<ul> <li>#219: Revisit Commitment Engine. Changes to the messages, environment, and behaviour types to conform the recent template changes.</li> <li>#253: Integration PR that   combines multiple engine-related changes: Engines: Use <code>ByteString</code> in   crypto types #242, Engines:   ByteString type definition #255,   Engines: <code>EngineMsg</code> revision #241,   EngineID: make <code>EngineName</code> compulsory #256, Engines: Engine type revision #244,  <code>EngineMsg</code>: add type param #258, Engines: add <code>GuardEval</code> and <code>ActionExec</code> #260, and Engines: Behaviour template revision #226.</li> <li>#256: Make <code>EngineName</code>   compulsory in <code>EngineID</code>.</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#218: Rename <code>EngineMessage</code>    type to <code>EngineMsg</code> and <code>mkEngineMessage</code> to <code>mkEngineMsg</code>.</li> <li>#220: Fix the deployment of    the latest version by deploying the website if the branch name is <code>main</code> or    matches the semver pattern, and add information about the version and the    commit hash to the title for reference.</li> <li>#222: Remove SML codebase as   not used any more and any other reference in the markdown files</li> <li>#225: Fix navigation table    for the identity component</li> <li>#227: Update Juvix version in Nix flake due to breaking changes, and   also the input packages while at it.</li> <li>#250: Update policy on Juvix typechecking. The whole codebase in a   PR should typecheck before merging</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#257: Refactor the Git strategy: introduce integration PRs for   better overview of complex changes</li> </ul> </li> <li>Juvix types and updates<ul> <li>#221: Update the prelude to   incorporate the latest changes in the <code>Stdlib</code>, including the addition of   applicative and monad traits, and the integration of the <code>containers</code> library.   This update also includes changes to data type definitions, with the <code>@</code>   syntax now used for declaration, creation, and matching on records, and other   removals like <code>: Type</code> for implicit arguments and function-style declarations.</li> <li>#226: Update Template &amp; Ticker Behaviour according to the engine &amp; message type changes. The examples have been improved with better clarity. The documentation now uses headlines instead of collapsible boxes and definition lists instead of tables. A new diagram template has been added that illustrates conditions and effects of actions.</li> <li>#241: <code>EngineMsg</code>-related changes: rename <code>MessageID</code> to <code>EngineMsgID</code>, add <code>getEngineMsgFrom(Timestamped)Trigger</code>, and rename <code>getMessageFrom(Timestamped)Trigger</code> to <code>getMsgFrom(Timestamped)Trigger</code>.</li> <li>#242: Use <code>ByteString</code> in crypto types.</li> <li>#244: Major refactoring of   engine-related types. The <code>Engine</code> type now includes a <code>cfg</code> field of type   <code>EngineConfig</code> containing static configuration (engine name and local node   ID). For consistency, <code>EngineEnvironment</code> has been renamed to <code>EngineEnv</code>. The   <code>EngineBehaviour</code> type has undergone several changes: the conflict solver has   been removed (to be replaced by new mechanism in   #246), precomputation results are   now passed directly as action arguments, and the <code>action</code> field has been   replaced with action labels defined by label type.</li> <li>#249: Remove <code>name</code> field in Engine instances due to PR 242</li> <li>#255: Make ByteString <code>String</code> instead of <code>Nat</code></li> <li>#258: Engine-related changes: add type parameter to parameterized the type of message and rename <code>EngineConfig</code> to <code>EngineCfg</code></li> <li>#260: Revise engine behaviour type: add <code>GuardEval (Seq)</code> and <code>ActionExec (First &amp; Any)</code>, <code>EngineCfg</code>: add <code>getEngineIDFromEngineCfg</code>. Partially addresses #246.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v010","title":"v0.1.0","text":"<p>This is the first release of Anoma's Spec project, following the semantic-versioning scheme. This version includes all the changes from the creation of this repository. From here on, we will keep a changelog of all the changes that are made to the project per version, with better documentation and descriptions of the changes.</p>","tags":["changelog"]},{"location":"changelog.html#breaking-changes","title":"Breaking changes","text":"<ul> <li>Node architecture<ul> <li>#179: Reorganize node architecture   documentation structure</li> <li>#192: Port identity engines to v2 template</li> </ul> </li> <li>System architecture<ul> <li>#210: Fix engine message, environment and   behavior layout</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#29: Remove unused libraries</li> <li>#30: Remove juvix hook in pro of mkdos Juvix   plugin</li> <li>#53: Setup: require only python 3.9</li> <li>#60: Restructure for v2</li> <li>#64: Change KV Storage Deletion Documentation</li> <li>#65: Delete Compute and Randomness Engines</li> <li>#69: Remove outdates files from arch1 and fix   formatting</li> <li>#104: Refactor scope, basic types, and   application architecture sections</li> <li>#115: Refactor file and folder names: add   snake_case convention</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#bug-fixes","title":"Bug fixes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#4: Fix mike</li> <li>#9: Add batch of fixes</li> <li>#10: Fix Index: quick links and remove empty types   pages</li> <li>#18: Fix TODO, add todos.py script, and more   formatting issues</li> <li>#19: Remove todos on deploy, fix wikilinks warnings</li> <li>#21: Fix whitespaces</li> <li>#22: Fix indexes generation with macros and optimize   caching</li> <li>#24: Fix minors</li> <li>#25: CI fixes</li> <li>#74: Fix broken links in navigation bar and a few   pages</li> <li>#77: Fix CI: deploy website by PRs against main, v1,   and v2</li> <li>#78: Fix: CI doesnt trigger on edits</li> <li>#91: Fix default views and deploys in the CI</li> <li>#96: Fix navigation bar and more broken links due #60</li> <li>#101: Fix typos and small improve wording</li> <li>#105: Fix warnings messages due to recent refactors</li> <li>#122: Fix support for Juvix Markdown snippets</li> <li>#123: Fix merging conflicts chris-update-basic-types</li> <li>#124: Fix tutorial nav structure and broken links in   the footer</li> <li>#132: Fix minor issues with directories and filenames</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#features_4","title":"Features","text":"<ul> <li>Application documentation<ul> <li>#198: Add transparent RM implementation documentation</li> </ul> </li> <li>Python-related changes<ul> <li>#133: Add support for multi-line wiki-style links</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#2: Add better support for WikiLinks and other goodies</li> <li>#3: Update README and run pre-commit</li> <li>#5: Add Ubuntu dependencies to the CI</li> <li>#6: Use site_url for link generation</li> <li>#7: Add new hook for images</li> <li>#8: Add lightboxes to images, fix local image loading</li> <li>#11: Improve link resolution for urls outside nav</li> <li>#14: Add Last updated time to the footer and other   fixes</li> <li>#15: Add a more explicit MathJax config</li> <li>#17: Revised macros configuration</li> <li>#20: Refactor hooks</li> <li>#23: Add previews for PRs</li> <li>#27: Fix url indexes and improve PR previews</li> <li>#28: Add tutorial basic instructions</li> <li>#31: Translate Haskell snippets to Juvix and fix typos</li> <li>#51: Configuration Engine</li> <li>#52: Add nix flake</li> <li>#56: Add page on dynamic code loading</li> <li>#58: Homogeneous consensus for V2</li> <li>#59: Readme: tighten up install instructions</li> <li>#61: Updates kudos spec</li> <li>#63: Counter example</li> <li>#68: Add New Engine Specifications from Anoma Elixir   Database</li> <li>#75: Add proof-of-stake example</li> <li>#80: Re-introduced full execution machine for V2</li> <li>#81: Add BibTeX entries and fix configuration</li> <li>#84: Add templates for defining engine systems</li> <li>#92: Add global table of contents</li> <li>#95: Continue v2 updates</li> <li>#97: Add git branching strategy</li> <li>#98: Add citation instructions and restructure markdown   tutorials</li> <li>#99: Delete previews for closed PRs on gh-pages branch</li> <li>#100: Split CI workflows: deploy, pull-request, clean-   ups</li> <li>#103: Additional reorganization &amp; updates</li> <li>#117: Tweaks to message types in basics</li> <li>#120: Refactor tutorial organization and add a few   more on conventions</li> <li>#121: Improve look&amp;feel, organized nav, hide extra   links and move them to the footer</li> <li>#127: Update basic abstractions</li> <li>#131: Add RMv3 content</li> <li>#135: Show PR number in the site name</li> <li>#209: Add changelog management system</li> <li>#214: Add GitHub template for creating PRs</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#134: Refactor tutorial for wiki-style links</li> </ul> </li> <li>Juvix types and updates<ul> <li>#128: Add new Juvix definitions from PR-84</li> <li>#130: Translate SML Identity definitions to Juvix</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"everything.html","title":"Everything","text":"<pre><code>module everything;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"everything.html#prelude","title":"Prelude","text":"<pre><code>import prelude;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"everything.html#system","title":"System","text":"<pre><code>import arch.system.identity.identity;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"everything.html#resource-machine","title":"Resource Machine","text":"<pre><code>import arch.system.state.resource_machine.data_structures.transaction.transaction_with_payment;\nimport arch.system.state.resource_machine.data_structures.transaction.transaction;\nimport arch.system.state.resource_machine.data_structures.transaction.transaction_function;\nimport arch.system.state.resource_machine.data_structures.transaction.delta_proof;\nimport arch.system.state.resource_machine.data_structures.compliance_unit.compliance_proof;\nimport arch.system.state.resource_machine.data_structures.compliance_unit.compliance_unit;\nimport arch.system.state.resource_machine.data_structures.action.resource_logic_proof;\nimport arch.system.state.resource_machine.data_structures.action.index;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.resource_commitment;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.kind;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.nullifier;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.delta;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.introduction;\nimport arch.system.state.resource_machine.data_structures.resource.index;\nimport arch.system.state.resource_machine.primitive_interfaces.transaction_function_vm;\nimport arch.system.state.resource_machine.primitive_interfaces.set;\nimport arch.system.state.resource_machine.primitive_interfaces.nullifier_set;\nimport arch.system.state.resource_machine.primitive_interfaces.map;\nimport arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_types;\nimport arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_delta;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.fixed_size_type;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.hash;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.delta_hash;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.arithmetic;\nimport arch.system.state.resource_machine.primitive_interfaces.index;\nimport arch.system.state.resource_machine.primitive_interfaces.ordered_set;\nimport arch.system.state.resource_machine.primitive_interfaces.commitment_accumulator;\nimport arch.system.state.resource_machine.notes.storage;\nimport arch.system.state.resource_machine.notes.function_formats.transaction_function_format;\nimport arch.system.state.resource_machine.notes.applications;\nimport arch.system.state.resource_machine.notes.roles_and_requirements;\nimport arch.system.state.resource_machine.notes.nockma;\nimport arch.system.state.resource_machine.notes.nockma_runnable;\nimport arch.system.state.resource_machine.notes.runnable;\nimport arch.system.state.resource_machine.index;\nimport arch.system.state.resource_machine.execution_flow.flow;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"prelude.html","title":"Prelude","text":"Juvix imports <pre><code>module prelude;\nimport Stdlib.Trait open public;\nimport Stdlib.Trait.Ord open using {Ordering; module Ordering; Equal; isEqual} public;\nimport Stdlib.Trait.Eq open using {==} public;\nimport Stdlib.Debug.Fail open using {failwith};\nimport Stdlib.Data.Fixity open public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#juvix-specs-prelude","title":"Juvix Specs Prelude","text":"<p>The following are frequent and basic abstractions used in the Anoma specification.</p>","tags":["prelude","index"]},{"location":"prelude.html#combinators","title":"Combinators","text":"<pre><code>import Stdlib.Function open\n  using {\n    &lt;&lt;;\n    &gt;&gt;;\n    const;\n    id;\n    flip;\n    &lt;|;\n    |&gt;;\n    iterate;\n    &gt;-&gt;;\n  } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#useful-type-classes","title":"Useful Type Classes","text":"","tags":["prelude","index"]},{"location":"prelude.html#functor","title":"<code>Functor</code>","text":"<pre><code>import Stdlib.Trait.Functor.Polymorphic as Functor;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#applicative","title":"<code>Applicative</code>","text":"<pre><code>import Stdlib.Trait.Applicative as Applicative\n  open using\n  { Applicative;\n  } public;\nimport Stdlib.Trait.Applicative as Applicative\n  open using\n  { Applicative;\n  } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#monad","title":"<code>Monad</code>","text":"<pre><code>import Stdlib.Trait.Monad as Monad\n  open using {Monad} public;\nimport Stdlib.Trait.Monad as Monad\n  open using {Monad} public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#join","title":"<code>join</code>","text":"<p>Join function for monads</p> <pre><code>join\n  {M : Type -&gt; Type}\n  {A}\n  {{Monad M}}\n  (mma : M (M A)) : M A :=\n  bind mma id;  -- using the built-in `bind`\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#bifunctor","title":"<code>Bifunctor</code>","text":"<p>Two-argument functor</p> <pre><code>trait\ntype Bifunctor (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    bimap {A B C D} :  (A -&gt; C) -&gt; (B -&gt; D) -&gt; F A B -&gt; F C D\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#associativeproduct","title":"<code>AssociativeProduct</code>","text":"<p>Product with associators</p> <pre><code>trait\ntype AssociativeProduct (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    assocLeft {A B C} : F A (F B C) -&gt; F (F A B) C;\n    assocRight {A B C} : F (F A B) C -&gt; F A (F B C)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#commutativeproduct","title":"<code>CommutativeProduct</code>","text":"<p>Product with commuters</p> <pre><code>trait\ntype CommutativeProduct (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    swap {A B} : F A B -&gt; F B A;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unitalproduct","title":"<code>UnitalProduct</code>","text":"<p>Product with units</p> <pre><code>trait\ntype UnitalProduct U (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    unitLeft {A} : A -&gt; F U A;\n    unUnitLeft {A} : F U A -&gt; A;\n    unitRight {A} : A -&gt; F A U;\n    unUnitRight {A} : F A U -&gt; A;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#traversable","title":"<code>Traversable</code>","text":"<pre><code>import Stdlib.Trait.Traversable as Traversable\n  open using {\n    Traversable;\n    sequenceA;\n    traverse;\n    } public;\nimport Stdlib.Trait.Traversable as Traversable\n  open using {\n    Traversable;\n    sequenceA;\n    traverse;\n    } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#bool","title":"Bool","text":"<p>The type <code>Bool</code> represents boolean values (<code>true</code> or <code>false</code>). Used for logical operations and conditions.</p> <pre><code>import Stdlib.Data.Bool as Bool\n  open using\n  { Bool;\n    true;\n    false;\n    &amp;&amp;;\n    ||;\n    not;\n    or;\n    and;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>verdad : Bool := true;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#xor","title":"<code>xor</code>","text":"<p>Exlusive or</p> <pre><code>xor (a b : Bool) : Bool :=\n  if\n    | a := not b\n    | else := b\n  ;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nand","title":"<code>nand</code>","text":"<p>Not and</p> <pre><code>nand (a b : Bool) : Bool := not (and a b);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nor","title":"<code>nor</code>","text":"<p>Not or</p> <pre><code>nor (a b : Bool) : Bool := not (or a b);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nat","title":"<code>Nat</code>","text":"<p>The type <code>Nat</code> represents natural numbers (non-negative integers). Used for counting and indexing.</p> <pre><code>import Stdlib.Data.Nat as Nat\n  open using\n  { Nat;\n    zero;\n    suc;\n    natToString;\n    +;\n    sub;\n    *;\n    div;\n    mod;\n    ==;\n    &lt;=;\n    &gt;;\n    &lt;;\n    min;\n    max;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>ten : Nat := 10;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pred","title":"<code>pred</code>","text":"<p>Predecessor function for natural numbers.</p> <pre><code>pred (n : Nat) : Nat :=\n  case n of {\n    | zero := zero\n    | suc k := k\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#booltonat","title":"<code>boolToNat</code>","text":"<p>Convert boolean to a Bool to a Nat in the standard way of circuits.</p> <pre><code>boolToNat (b : Bool) : Nat :=\n  if\n    | b := 0\n    | else := 1\n  ;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#iszero","title":"<code>isZero</code>","text":"<p>Check if a natural number is zero.</p> <pre><code>isZero (n : Nat) : Bool :=\n  case n of {\n    | zero := true\n    | suc k := false\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#iseven-and-isodd","title":"<code>isEven</code> and <code>isOdd</code>","text":"<p>Parity checking functions</p> <pre><code>isEven (n : Nat) : Bool := mod n 2 == 0;\n</code></pre> <pre><code>isOdd (n : Nat) : Bool := not (isEven n);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#foldnat","title":"<code>foldNat</code>","text":"<p>Fold over natural numbers.</p> <pre><code>terminating\nfoldNat {B} (z : B) (f : Nat -&gt; B -&gt; B) (n : Nat) : B :=\n  case n of {\n    | zero := z\n    | suc k := f k (foldNat z f k)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#iter","title":"<code>iter</code>","text":"<p>Iteration of a function.</p> <pre><code>iter {A} (f : A -&gt; A) (n : Nat) (x : A) : A :=\n  foldNat x \\{_ y := f y} n;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#exp","title":"<code>exp</code>","text":"<p>The exponentiation function.</p> <pre><code>exp (base : Nat) (exponent : Nat) : Nat :=\n  iter \\{product := base * product} exponent 1;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#factorial","title":"<code>factorial</code>","text":"<p>The factorial function.</p> <pre><code>factorial : Nat -&gt; Nat := foldNat 1 \\{k r := suc k * r};\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#gcd","title":"<code>gcd</code>","text":"<p>Greatest common divisor function.</p> <pre><code>terminating\ngcd (a b : Nat) : Nat :=\n  case b of {\n    | zero := a\n    | suc _ := gcd b (mod a b)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#lcm","title":"<code>lcm</code>","text":"<p>Least common multiple function.</p> <pre><code>lcm (a b : Nat) : Nat :=\n  case b of {\n    | zero := zero\n    | suc _ :=\n      case a of {\n        | zero := zero\n        | suc _ := div (a * b) (gcd a b)\n      }\n    };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#string","title":"<code>String</code>","text":"<p>The type <code>String</code> represents sequences of characters. Used for text and communication.</p> <pre><code>import Stdlib.Data.String\n  as String\n  open using\n  { String;\n    ++str;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>hello : String := \"Hello, World!\";\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#comparison-instance-for-string","title":"Comparison instance for <code>String</code>","text":"<pre><code>stringCmp (s1 s2 : String) : Ordering :=\n  if\n    | s1 == s2 := Ordering.Equal\n    | else := Ordering.GreaterThan\n  ;\n\ninstance\nStringOrd : Ord String :=\n  Ord.mk@{\n    compare := stringCmp;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#bytestring","title":"<code>ByteString</code>","text":"<pre><code>ByteString : Type := String;\n</code></pre> <p>A basic type for representing binary data.</p> <pre><code>emptyByteString : ByteString := \"\";\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unit","title":"<code>Unit</code>","text":"<p>The type <code>Unit</code> represents a type with a single value. Often used when a function does not return any meaningful value.</p> <pre><code>import Stdlib.Data.Unit\n  as Unit\n  open using {\n    Unit;\n    unit\n  } public;\n</code></pre> <p>For example,</p> <pre><code>unitValue : Unit := unit;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#trivial","title":"<code>trivial</code>","text":"<p>Unique function to the unit. Universal property of terminal object.</p> <pre><code>trivial {A} : A -&gt; Unit := const unit;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#empty","title":"<code>Empty</code>","text":"<p>The type <code>Empty</code> represents a type with a single value. Often used when a function does not return any meaningful value.</p> <pre><code>axiom Empty : Type;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#explode","title":"<code>explode</code>","text":"<p>Unique function from empty. Universal property of initial object.</p> <pre><code>axiom explode {A} : Empty -&gt; A;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pair-a-b","title":"<code>Pair A B</code>","text":"<p>The type <code>Pair A B</code> represents a tuple containing two elements of types <code>A</code> and <code>B</code>. Useful for grouping related values together.</p> <pre><code>import Stdlib.Data.Pair as Pair;\nopen Pair using { Pair } public;\nopen Pair using { , };\n\nimport Stdlib.Data.Pair as Pair\n  open using\n  { ordProductI;\n    eqProductI\n  } public;\n</code></pre> <pre><code>import Stdlib.Data.Fixity open;\nsyntax alias mkPair := ,;\n</code></pre> <p>For example,</p> <pre><code>pair : Pair Nat Bool := mkPair 42 true;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fst-and-snd","title":"<code>fst</code> and <code>snd</code>","text":"<p>Projections</p> <pre><code>fst {A B} : Pair A B -&gt; A\n  | (mkPair a _) := a;\n</code></pre> <pre><code>snd {A B} : Pair A B -&gt; B\n  | (mkPair _ b) := b;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#paircommutativeproduct","title":"<code>PairCommutativeProduct</code>","text":"<p>Swap components</p> <pre><code>instance\nPairCommutativeProduct : CommutativeProduct Pair :=\n  CommutativeProduct.mk@{\n    swap := \\{p := mkPair (snd p) (fst p)}\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pairassociativeproduct","title":"<code>PairAssociativeProduct</code>","text":"<p>Pair associations</p> <pre><code>instance\nPairAssociativeProduct : AssociativeProduct Pair :=\n  AssociativeProduct.mk@{\n    assocLeft := \\{p :=\n      let pbc := snd p;\n      in mkPair (mkPair (fst p) (fst pbc)) (snd pbc)\n    };\n    assocRight := \\{p :=\n      let pab := fst p;\n      in mkPair (fst pab) (mkPair (snd pab) (snd p))\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pairunitalproduct","title":"<code>PairUnitalProduct</code>","text":"<p>Unit maps for pairs and units</p> <pre><code>instance\nPairUnitalProduct : UnitalProduct Unit Pair :=\n  UnitalProduct.mk@{\n    unitLeft := \\{a := mkPair unit a};\n    unUnitLeft := snd;\n    unitRight := \\{a := mkPair a unit};\n    unUnitRight := \\{{A} := fst};\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pairbifunctor","title":"<code>PairBifunctor</code>","text":"<p>Map functions over pairs</p> <pre><code>instance\nPairBifunctor : Bifunctor Pair :=\n  Bifunctor.mk@{\n    bimap := \\{f g p := mkPair (f (fst p)) (g (snd p))};\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fork","title":"<code>fork</code>","text":"<p>Universal property of pairs</p> <pre><code>fork\n  {A B C}\n  (f : C -&gt; A)\n  (g : C -&gt; B)\n  (c : C) : Pair A B :=\n  mkPair (f c) (g c);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#result-a-b","title":"<code>Result A B</code>","text":"<p>The <code>Result A B</code> type represents either a success with a value of <code>ok x</code> with <code>x</code> of type <code>A</code> or an error with value <code>error e</code> with <code>e</code> of type <code>B</code>.</p> <pre><code>import Stdlib.Data.Result.Base as Result;\nopen Result using { Result; ok; error } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#either-a-b","title":"<code>Either A B</code>","text":"<p>The type <code>Either A B</code>, or sum type of <code>A</code> and <code>B</code>, represents a value of type <code>A</code> or <code>B</code>. It is equivalent to <code>Result A B</code>, however, the meaning of the values is different. There is no such thing as an error or success value in the <code>Either</code> type, instead the values are either <code>left a</code> of type <code>A</code> or <code>right b</code> of type <code>B</code>.</p> <pre><code>syntax alias Either := Result;\nsyntax alias left := error;\nsyntax alias right := ok;\n</code></pre> <p>For example,</p> <pre><code>thisString : Either String Nat := left \"Error!\";\nthisNumber : Either String Nat := right 42;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#isleft-and-isright","title":"<code>isLeft</code> and <code>isRight</code>","text":"<p>Check components of either.</p> <pre><code>isLeft {A B} (e : Either A B) : Bool :=\n  case e of {\n    | left _ := true\n    | right _ := false\n  };\n</code></pre> <pre><code>isRight {A B} (e : Either A B) : Bool :=\n  case e of {\n    | left _ := false\n    | right _ := true\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fromleft","title":"<code>fromLeft</code>","text":"<p>Get left element (with default)</p> <pre><code>fromLeft {A B} (e : Either A B) (d : A) : A :=\n  case e of {\n    | (left x) := x\n    | (right _) := d\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fromright","title":"<code>fromRight</code>","text":"<p>Get right element (with default)</p> <pre><code>fromRight {A B} (e : Either A B) (d : B) : B :=\n  case e of {\n    | (left _) := d\n    | (right x) := x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eithercommutativeproduct","title":"<code>EitherCommutativeProduct</code>","text":"<p>Swap elements</p> <pre><code>swapEither {A B} (e : Either A B) : Either B A :=\n  case e of {\n    | (left x) := right x\n    | (right x) := left x\n  };\n</code></pre> <pre><code>instance\nEitherCommutativeProduct : CommutativeProduct Either :=\n  CommutativeProduct.mk@{ swap := swapEither };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherbifunctor","title":"<code>EitherBifunctor</code>","text":"<p>Map onto elements of either</p> <pre><code>eitherBimap\n  {A B C D}\n  (f : A -&gt; C)\n  (g : B -&gt; D)\n  (e : Either A B) : Either C D :=\n  case e of {\n    | (left a) := left (f a)\n    | (right b) := right (g b)\n  };\n</code></pre> <pre><code>instance\nEitherBifunctor : Bifunctor Either :=\n  Bifunctor.mk@{\n    bimap := eitherBimap\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherunitalproduct","title":"<code>EitherUnitalProduct</code>","text":"<p>Unit maps for Either and Empty</p>","tags":["prelude","index"]},{"location":"prelude.html#ununitlefteither","title":"<code>unUnitLeftEither</code>","text":"<pre><code>unUnitLeftEither {A} (e : Either Empty A) : A :=\n  case e of {\n    | left x := explode x\n    | right x := x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#ununitrighteither","title":"<code>unUnitRightEither</code>","text":"<pre><code>unUnitRightEither {A} (e : Either A Empty) : A :=\n  case e of {\n    | left x := x\n    | (right x) := explode x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherunitalproduct_1","title":"<code>EitherUnitalProduct</code>","text":"<p>Unit maps for Either and Empty</p> <pre><code>instance\nEitherUnitalProduct : UnitalProduct Empty Either :=\n  UnitalProduct.mk@{\n    unitLeft := right;\n    unUnitLeft := unUnitLeftEither;\n    unitRight := \\{{A} := left};\n    unUnitRight := unUnitRightEither;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fuse","title":"<code>fuse</code>","text":"<p>Universal property of coproduct</p> <pre><code>fuse\n  {A B C}\n  (f : A -&gt; C)\n  (g : B -&gt; C)\n  (e : Either A B) : C :=\n  case e of {\n    | (left x) := f x\n    | (right x) := g x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherassociativeproduct","title":"<code>EitherAssociativeProduct</code>","text":"<p>Association functions for either</p>","tags":["prelude","index"]},{"location":"prelude.html#assoclefteither","title":"<code>assocLeftEither</code>","text":"<pre><code>assocLeftEither\n  {A B C}\n  (e : Either A (Either B C)) : Either (Either A B) C :=\n  case e of {\n    | (left x) := left (left x)\n    | (right ebc) :=\n      case ebc of {\n        | (left y) := left (right y)\n        | (right z) := right z\n      }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#assocrighteither","title":"<code>assocRightEither</code>","text":"<pre><code>assocRightEither\n  {A B C}\n  (e : Either (Either A B) C)\n  : Either A (Either B C) :=\n  case e of {\n    | (left eab) :=\n      case eab of {\n        | (left x) := left x\n        | (right y) := right (left y)\n      }\n    | (right z) := right (right z)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherassociativeproduct_1","title":"<code>EitherAssociativeProduct</code>","text":"<pre><code>instance\nEitherAssociativeProduct : AssociativeProduct Either :=\n  AssociativeProduct.mk@{\n    assocLeft := assocLeftEither;\n    assocRight := assocRightEither;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#option-a","title":"<code>Option A</code>","text":"<p>The type <code>Option A</code> represents an optional value of type <code>A</code>. It can be either <code>Some A</code> (containing a value) or <code>None</code> (no value). This type is an alias for <code>Maybe A</code> from the standard library.</p> <pre><code>import Stdlib.Data.Maybe as Maybe;\nopen Maybe using {\n    Maybe;\n    just;\n    nothing\n  };\n</code></pre> <pre><code>syntax alias Option := Maybe;\nsyntax alias some := just;\nsyntax alias none := nothing;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#isnone","title":"<code>isNone</code>","text":"<p>Check if an optional value is <code>none</code>:</p> <pre><code>isNone {A} (x : Option A) : Bool\n  := case x of {\n  | none := true\n  | some _ := false\n  }\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#issome","title":"<code>isSome</code>","text":"<p>Check if an optional value is <code>some</code>:</p> <pre><code>isSome {A} (x : Option A) : Bool := not (isNone x);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fromoption","title":"<code>fromOption</code>","text":"<p>Extract the value from an <code>Option</code> term:</p> <pre><code>fromOption {A} (x : Option A) (default : A) : A :=\n  case x of {\n  | none := default\n  | some x := x\n};\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#option","title":"<code>option</code>","text":"<p>Map over option with default</p> <pre><code>option\n  {A B}\n  (o : Option A)\n  (default : B)\n  (f : A -&gt; B)\n  : B :=\n  case o of {\n    | none := default\n    | some x := f x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#filteroption","title":"<code>filterOption</code>","text":"<p>Filter option according to predicate</p> <pre><code>filterOption\n  {A}\n  (p : A -&gt; Bool)\n  (opt : Option A) : Option A :=\n  case opt of {\n    | none := none\n    | some x :=\n      if\n        | p x := some x\n        | else := none\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#list-a","title":"<code>List A</code>","text":"<p>The type <code>List A</code> represents a sequence of elements of type <code>A</code>. Used for collections and ordered data.</p> <pre><code>import Stdlib.Data.List as List\n  open using {\n  List;\n  nil;\n  ::;\n  isElement;\n  head;\n  tail;\n  length;\n  take;\n  drop;\n  ++;\n  reverse;\n  any;\n  all;\n  zip;\n} public;\n</code></pre> <p>For example,</p> <pre><code>numbers : List Nat := 1 :: 2 :: 3 :: nil;\n-- alternative syntax:\nniceNumbers : List Nat := [1 ; 2 ; 3];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#findindex","title":"<code>findIndex</code>","text":"<p>Get the first index of an element satisfying a predicate if such an index exists and none, otherwise.</p> <pre><code>findIndex {A} (predicate : A -&gt; Bool) : List A -&gt; Option Nat\n  | nil := none\n  | (x :: xs) :=\n    if\n      | predicate x := some zero\n      | else := case findIndex predicate xs of\n        | none := none\n        | some i := some (suc i);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#last","title":"<code>last</code>","text":"<p>Get last element of a list</p> <pre><code>last {A} (lst : List A) (default : A) : A :=\n  head default (reverse lst);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#most","title":"<code>most</code>","text":"<p>Get list with last element dropped</p> <pre><code>most {A} (lst : List A) : List A :=\n  tail (reverse lst);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#snoc","title":"<code>snoc</code>","text":"<p>Prepend element to a list</p> <pre><code>snoc {A} (xs : List A) (x : A) : List A :=\n  xs ++ [x];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#uncons","title":"<code>uncons</code>","text":"<p>Split one layer of list</p> <pre><code>uncons {A} : List A -&gt; Option (Pair A (List A))\n  | nil := none\n  | (x :: xs) := some (mkPair x xs)\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unsnoc","title":"<code>unsnoc</code>","text":"<p>Split one layer of list from the end</p> <pre><code>unsnoc {A} : List A -&gt; Option (Pair (List A) A)\n  | nil := none\n  | (x :: xs) := some (mkPair (most (x :: xs)) (last xs x))\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unfold","title":"<code>unfold</code>","text":"<p>Unfold a list, layerwise</p> <pre><code>terminating\nunfold {A B}\n  (step : B -&gt; Option (Pair A B))\n  (seed : B) : List A :=\n  case step seed of\n    | none := nil\n    | some (x, seed') := x :: unfold step seed';\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unzip","title":"<code>unzip</code>","text":"<p>Unzip a list of pairs into two lists</p> <pre><code>terminating\nunzip {A B}\n  (xs : List (Pair A B)) : Pair (List A) (List B) :=\n  case xs of {\n    | nil := mkPair nil nil\n    | p :: ps :=\n      let unzipped := unzip ps\n      in mkPair (fst p :: fst unzipped) (snd p :: snd unzipped)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#partitioneither","title":"<code>partitionEither</code>","text":"<p>Partition a list</p> <pre><code>partitionEither\n  {A B} (es : List (Either A B)) : Pair (List A) (List B) :=\n  foldr\n    (\\{e acc :=\n      case e of {\n        | left a := mkPair (a :: (fst acc)) (snd acc)\n        | right b := mkPair (fst acc) (b :: (snd acc))\n      }})\n    (mkPair nil nil)\n    es;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#partitioneitherwith","title":"<code>partitionEitherWith</code>","text":"<pre><code>partitionEitherWith\n  {A B C}\n  (f : C -&gt; Either A B)\n  (es : List C) : Pair (List A) (List B) :=\n  partitionEither (map f es);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#catoptions","title":"<code>catOptions</code>","text":"<p>Collapse list of options</p> <pre><code>catOptions {A} : List (Option A) -&gt; List A :=\n  foldr\n    (\\{opt acc :=\n      case opt of {\n        | none := acc\n        | some x := x :: acc\n      }})\n    nil;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#maximumby","title":"<code>maximumBy</code>","text":"<p>Get the maximal element of a list.</p> <pre><code>maximumBy {A B} {{Ord B}}\n  (f : A -&gt; B)\n  (lst : List A)\n  : Option A :=\n  let maxHelper := \\{curr acc :=\n    case acc of {\n      | none := some curr\n      | some maxVal :=\n        if\n          | f curr &gt; f maxVal := some curr\n          | else := some maxVal\n    }\n  };\n  in foldr maxHelper none lst;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#minimumby","title":"<code>minimumBy</code>","text":"<p>Get the minimal element of a list.</p> <pre><code>minimalBy {A B} {{Ord B}}\n  (f : A -&gt; B)\n  (lst : List A)\n  : Option A :=\n  let minHelper := \\{curr acc :=\n    case acc of {\n      | none := some curr\n      | some minVal :=\n        if\n          | f curr &lt; f minVal := some curr\n          | else := some minVal\n    }\n  };\n  in foldr minHelper none lst;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#chunksof","title":"<code>chunksOf</code>","text":"<p>Splits a list into chunks of size <code>n</code>. The last chunk may be smaller than <code>n</code> if the length of the list is not divisible by <code>n</code>.</p> <p>Example:</p> <ul> <li>chunksOf 2 [1;2;3;4;5] = [[1;2]; [3;4]; [5]]</li> </ul> <pre><code>terminating\nchunksOf {A} : (chunkSize : Nat) -&gt; (list : List A) -&gt; List (List A)\n  | zero _ := nil\n  | _ nil := nil\n  | n xs := take n xs :: chunksOf n (drop n xs);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#sliding","title":"<code>sliding</code>","text":"<p>Returns all contiguous sublists of size <code>n</code>. If <code>n</code> is larger than the list length, returns empty list. If <code>n</code> is zero, returns empty list.</p> <p>Example: - sliding 2 [1;2;3;4] = [[1;2]; [2;3]; [3;4]]</p> <pre><code>sliding {A} : (windowSize : Nat) -&gt; (list : List A) -&gt; List (List A)\n  | zero _ := nil\n  | n xs :=\n    let\n      len : Nat := length xs;\n      terminating\n      go : List A -&gt; List (List A)\n        | nil := nil\n        | ys :=\n          if\n            | length ys &lt; n := nil\n            | else := take n ys :: go (tail ys);\n    in if\n      | n &gt; len := nil\n      | else := go xs;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#span","title":"<code>span</code>","text":"<p>Takes a predicate and a list, and returns a tuple where:</p> <ul> <li>First element is the longest prefix of the list that satisfies the predicate</li> <li>Second element is the remainder of the list</li> </ul> <pre><code>span {A} (p : A -&gt; Bool) : List A -&gt; Pair (List A) (List A)\n  | nil := mkPair nil nil\n  | (x :: xs) :=\n    if\n      | p x :=\n        let\n          (ys1, ys2) := span p xs;\n        in mkPair (x :: ys1) ys2\n      | else := mkPair nil (x :: xs);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#groupby-and-group","title":"<code>groupBy</code> and <code>group</code>","text":"<p>Groups consecutive elements in a list that satisfy a given equality predicate.</p> <p>Example:</p> <ul> <li>groupBy (==) [1;1;2;2;2;3;1;1] = [[1;1];[2;2;2];[3];[1;1]]</li> </ul> <pre><code>terminating\ngroupBy {A} (eq : A -&gt; A -&gt; Bool) : List A -&gt; List (List A)\n  | nil := nil\n  | (x :: xs) :=\n    case span (eq x) xs of\n      ys1, ys2 := (x :: ys1) :: groupBy eq ys2;\n</code></pre> <pre><code>group {A} {{Eq A}} : List A -&gt; List (List A) := groupBy (==)\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nubby","title":"<code>nubBy</code>","text":"<p>Returns a list with duplicates removed according to the given equivalence function, keeping the first occurrence of each element. Unlike regular ;nub;, this function allows specifying a custom equality predicate.</p> <p>Examples:</p> <ul> <li>nubBy ({x y := mod x 3 == mod y 3}) [1;2;3;4;5;6] = [1;2;3]</li> <li>nub [1;1;2;2;3;3] = [1;2;3]</li> </ul> <pre><code>nubBy {A} (eq : A -&gt; A -&gt; Bool) : List A -&gt; List A :=\n  let\n    -- Checks if an element is already in the accumulator\n    elemBy (x : A) : List A -&gt; Bool\n      | nil := false\n      | (y :: ys) := eq x y || elemBy x ys;\n\n    go : List A -&gt; List A -&gt; List A\n      | acc nil := reverse acc\n      | acc (x :: xs) :=\n        if\n          | elemBy x acc := go acc xs\n          | else := go (x :: acc) xs;\n  in go nil;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nub","title":"<code>nub</code>","text":"<pre><code>nub {A} {{Eq A}} : List A -&gt; List A := nubBy (==);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#powerlists","title":"<code>powerlists</code>","text":"<p>Generate all possible sublists of a list. Each element can either be included or not.</p> <pre><code>powerlists {A} : List A -&gt; List (List A)\n  | nil := nil :: nil\n  | (x :: xs) :=\n    let\n      rest : List (List A) := powerlists xs;\n      withX : List (List A) := map ((::) x) rest;\n    in rest ++ withX;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#set-a","title":"<code>Set A</code>","text":"<p>The type <code>Set A</code> represents a collection of unique elements of type <code>A</code>. Used for sets of values.</p> <pre><code>import Stdlib.Data.Set as Set open using {\n    Set; module Set;\n    difference;\n    union;\n    insert;\n    eqSetI;\n    ordSetI;\n    isSubset;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>uniqueNumbers : Set Nat := Set.fromList [1 ; 2 ; 2 ; 2; 3];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#setmap","title":"<code>setMap</code>","text":"<pre><code>setMap {A B} {{Ord B}} (f : A -&gt; B) (set : Set A) : Set B :=\n  Set.fromList (map f (Set.toList set));\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#setjoin","title":"<code>setJoin</code>","text":"<p>Collapse a set of sets into a set</p> <pre><code>setJoin {A} {{Ord A}} (sets : Set (Set A)) : Set A :=\n  for (acc := Set.empty) (innerSet in sets) {\n    Set.union acc innerSet\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#disjointunion","title":"<code>disjointUnion</code>","text":"<pre><code>--- Computes the disjoint union of two ;Set;s.\ndisjointUnion {T} {{Ord T}} (s1 s2 : Set T) : Result (Set T) (Set T) :=\n  case Set.intersection s1 s2 of\n    | Set.empty := ok (Set.union s1 s2)\n    | s := error s;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#symmetricdifference","title":"<code>symmetricDifference</code>","text":"<p>Caclulate the symmetric difference of two sets.</p> <pre><code>symmetricDifference\n  {A} {{Ord A}} (s1 s2 : Set A) : Set A :=\n  let\n    in1not2 := difference s1 s2;\n    in2not1 := difference s2 s1;\n  in union in1not2 in2not1;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#cartesianproduct","title":"<code>cartesianProduct</code>","text":"<p>Generate the set of all cartesian products of a set.</p> <pre><code>cartesianProduct\n  {A B}\n  {{Ord A}} {{Ord B}}\n  (s1 : Set A)\n  (s2 : Set B)\n  : Set (Pair A B) :=\n  let\n    -- For a fixed element from set1, create a set of all pairs with elements from s2\n    pairsForElement (a : A) : Set (Pair A B) :=\n      for (acc := Set.empty) (b in s2) {\n        insert (mkPair a b) acc\n      };\n\n    -- Create set of sets, each containing pairs for one element from s1\n    pairSets : Set (Set (Pair A B)) :=\n      for (acc := Set.empty) (a in s1) {\n        insert (pairsForElement a) acc\n      };\n  in setJoin pairSets;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#powerset","title":"<code>powerset</code>","text":"<p>Generate the powerset (set of all subsets) of a set.</p> <pre><code>powerset {A} {{Ord A}} (s : Set A) : Set (Set A) :=\n  let\n    elements := Set.toList s;\n    subLists := powerlists elements;\n  in Set.fromList (map Set.fromList subLists);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#ispropersubset","title":"<code>isProperSubset</code>","text":"<p>Checks if all elements of <code>set1</code> are in <code>set2</code>, and that the two sets are not the same.</p> <pre><code>isProperSubset {A} {{Eq A}} {{Ord A}} (set1 set2 : Set A) : Bool :=\n  isSubset set1 set2 &amp;&amp; not (set1 == set2)\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#map-k-v","title":"<code>Map K V</code>","text":"<p>The type <code>Map K V</code> represents a collection of key-value pairs, sometimes called a dictionary, where keys are of type <code>K</code> and values are of type <code>V</code>.</p> <pre><code>import Stdlib.Data.Map as Map public;\nopen Map using {\n    Map\n  } public;\n</code></pre> <p>For example,</p> <pre><code>codeToken : Map Nat String := Map.fromList [ (1 , \"BTC\") ; (2 , \"ETH\") ; (3, \"ANM\")];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#updatelookupwithkey","title":"<code>updateLookupWithKey</code>","text":"<p>Updates a value at a specific key using the update function and returns both the old value (if the key existed) and the updated map.</p> <pre><code>updateLookupWithKey\n  {Key Value}\n  {{Ord Key}}\n  (updateFn : Key -&gt; Value -&gt; Option Value)\n  (k : Key)\n  (map : Map Key Value)\n  : Pair (Option Value) (Map Key Value) :=\n  let\n    oldValue : Option Value := Map.lookup k map;\n    newMap : Map Key Value :=\n      case oldValue of {\n        | none := map\n        | some v :=\n          case updateFn k v of {\n            | none := Map.delete k map\n            | some newV := Map.insert k newV map\n          }\n      };\n  in oldValue, newMap;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapkeys","title":"<code>mapKeys</code>","text":"<p>Maps all keys in the Map to new keys using the provided function. If the mapping function is not injective (maps different keys to the same key), later entries in the map will overwrite earlier ones with the same new key.</p> <pre><code>mapKeys\n  {Key1 Key2 Value}\n  {{Ord Key2}}\n  (fun : Key1 -&gt; Key2)\n  (map : Map Key1 Value)\n  : Map Key2 Value :=\n  Map.fromList\n    (for (acc := nil) ((k, v) in Map.toList map) {\n      (fun k, v) :: acc\n    });\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#restrictkeys","title":"<code>restrictKeys</code>","text":"<p>Restrict a map to only contain keys from the given set.</p> <pre><code>restrictKeys\n  {Key Value}\n  {{Ord Key}}\n  (map : Map Key Value)\n  (validKeys : Set.Set Key)\n  : Map Key Value :=\n  for (acc := Map.empty) (k, v in map) {\n    if\n      | Set.isMember k validKeys := Map.insert k v acc\n      | else := acc\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#withoutkeys","title":"<code>withoutKeys</code>","text":"<p>Remove all entries from a map whose keys appear in the given set.</p> <pre><code>withoutKeys\n  {Key Value}\n  {{Ord Key}}\n  (map : Map Key Value)\n  (invalidKeys : Set.Set Key)\n  : Map Key Value :=\n  for (acc := Map.empty) (k, v in map) {\n    if\n      | Set.isMember k invalidKeys := acc\n      | else := Map.insert k v acc\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mappartition","title":"<code>mapPartition</code>","text":"<p>Split a map according to a predicate on values. Returns a pair of maps, (matching, non-matching).</p> <pre><code>mapPartition\n  {Key Value}\n  {{Ord Key}}\n  (predicate : Value -&gt; Bool)\n  (map : Map Key Value)\n  : Pair (Map Key Value) (Map Key Value) :=\n  for (matching, nonMatching := Map.empty, Map.empty) (k, v in map) {\n    if\n      | predicate v := Map.insert k v matching, nonMatching\n      | else := matching, Map.insert k v nonMatching\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#partitionwithkey","title":"<code>partitionWithKey</code>","text":"<p>Split a map according to a predicate that can examine both key and value. Returns a pair of maps, (matching, non-matching).</p> <pre><code>partitionWithKey\n  {Key Value}\n  {{Ord Key}}\n  (predicate : Key -&gt; Value -&gt; Bool)\n  (map : Map Key Value)\n  : Pair (Map Key Value) (Map Key Value) :=\n  for (matching, nonMatching := Map.empty, Map.empty) (k, v in map) {\n    if\n      | predicate k v := Map.insert k v matching, nonMatching\n      | else := matching, Map.insert k v nonMatching\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapoption","title":"<code>mapOption</code>","text":"<p>Apply a partial function to all values in the map, keeping only the entries where the function returns 'some'.</p> <pre><code>mapOption\n  {Key Value1 Value2} {{Ord Key}}\n  (f : Value1 -&gt; Option Value2)\n  (map : Map Key Value1)\n  : Map Key Value2 :=\n  for (acc := Map.empty) (k, v in map) {\n    case f v of {\n      | none := acc\n      | some v' := Map.insert k v' acc\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapoptionwithkey","title":"<code>mapOptionWithKey</code>","text":"<p>Same as mapOption but allows the function to examine the key as well.</p> <pre><code>mapOptionWithKey\n  {Key Value1 Value2} {{Ord Key}}\n  (f : Key -&gt; Value1 -&gt; Option Value2)\n  (map : Map Key Value1)\n  : Map Key Value2 :=\n  for (acc := Map.empty) (k, v in map) {\n    case f k v of {\n      | none := acc\n      | some v' := Map.insert k v' acc\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapeither","title":"<code>mapEither</code>","text":"<p>Apply a function that returns Either to all values in the map.</p> <pre><code>mapEither\n  {Key Value Error Result}\n  {{Ord Key}}\n  (f : Value -&gt; Either Error Result)\n  (map : Map Key Value)\n  : Pair (Map Key Error) (Map Key Result) :=\n  for (lefts, rights := Map.empty, Map.empty) (k, v in map) {\n    case f v of {\n      | error e := Map.insert k e lefts, rights\n      | ok r := lefts, Map.insert k r rights\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapeitherwithkey","title":"<code>mapEitherWithKey</code>","text":"<p>Same as mapEither but allows the function to examine the key as well.</p> <pre><code>mapEitherWithKey\n  {Key Value Error Result}\n  {{Ord Key}}\n  (f : Key -&gt; Value -&gt; Either Error Result)\n  (map : Map Key Value)\n  : Pair (Map Key Error) (Map Key Result) :=\n  for (lefts, rights := Map.empty, Map.empty) (k, v in map) {\n    case f k v of {\n      | error e := Map.insert k e lefts, rights\n      | ok r := lefts, Map.insert k r rights\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#undefined-values","title":"Undefined values","text":"<p>The term <code>undef</code> is a placeholder for unspecified values.</p>","tags":["prelude","index"]},{"location":"prelude.html#undef","title":"<code>undef</code>","text":"<pre><code>axiom undef {A} : A;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#todo","title":"<code>TODO</code>","text":"<pre><code>axiom TODO {A} : A;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#omap-k-v","title":"<code>OMap K V</code>","text":"<p>A simple map implementation represented as a function from keys to optional values. Note: Unlike <code>Stdlib.Data.Map</code>, this implementation does not require an <code>Ord</code> instance for the key type <code>K</code>. However, operations like <code>insert</code>, <code>delete</code>, and <code>fromList</code> require an <code>Eq</code> instance instead of an <code>Ord</code> instance.</p> <p>Meant for usage with <code>String</code> which does not have a working <code>Ord</code> instance but does have a working <code>Eq</code> instance.</p> <pre><code>module OMap;\n\n  type OMap K V := mk@{\n    omap : K -&gt; Option V\n  };\n\n  -- The empty map maps every key to `none`.\n  empty {K V} : OMap K V := OMap.mk \\{_ := none};\n\n  -- Look up a key in the map.\n  lookup {K V} (k : K) (m : OMap K V) : Option V := OMap.omap m k;\n\n  -- Insert a key-value pair. Requires an equality function for the key type.\n  insert {K V} {{Eq K}} (k : K) (v : V) (m : OMap K V) : OMap K V :=\n    OMap.mk@{omap := \\{k' := if | k == k' := some v\n                                | else := OMap.omap m k'}};\n\n  -- Delete a key. Requires an equality function for the key type.\n  delete {K V} {{Eq K}} (k : K) (m : OMap K V) : OMap K V :=\n    OMap.mk@{omap := \\{k' := if | k == k' := none\n                                | else := OMap.omap m k'}};\n\n  -- Create a map from a list of key-value pairs. Requires an equality function.\n  fromList {K V} {{Eq K}} (pairs : List (Pair K V)) : OMap K V :=\n    foldl (\\{m (k, v) := insert k v m}) empty pairs;\n\n  -- Map a function over the values of the map.\n  map {K V1 V2} (f : V1 -&gt; V2) (m : OMap K V1) : OMap K V2 :=\n    OMap.mk@{omap := \\{k := Functor.map f (OMap.omap m k)}};\n\n  -- Apply a function that returns an Option to values, keeping only `some` results.\n  mapOption {K V1 V2} (f : V1 -&gt; Option V2) (m : OMap K V1) : OMap K V2 :=\n    OMap.mk@{omap := \\{k := case OMap.omap m k of { none := none | some v1 := f v1 }}};\n\n  -- Apply a function that returns an Option to keys and values, keeping only `some` results.\n  mapOptionWithKey {K V1 V2} (f : K -&gt; V1 -&gt; Option V2) (m : OMap K V1) : OMap K V2 :=\n    OMap.mk@{omap := \\{k := case OMap.omap m k of { none := none | some v1 := f k v1 }}};\n\n  -- Fold over the map *given a specific list of keys*.\n  -- Note: A true fold isn't possible without knowing the domain.\n  foldWithKeys {K V Acc} (f : K -&gt; V -&gt; Acc -&gt; Acc) (init : Acc) (keys : List K) (m : OMap K V) : Acc :=\n    foldl\n      (\\{acc k := case OMap.omap m k of { none := acc | some v := f k v acc }})\n      init\n      keys;\n\n  -- Create a map with a single key-value pair.\n  singleton {K V} {{Eq K}} (k : K) (v : V) : OMap K V :=\n    OMap.mk@{omap := \\{k' := if | k == k' := some v | else := none}};\n\nend;\n</code></pre>","tags":["prelude","index"]},{"location":"arch/overview.html","title":"Anoma architecture","text":"<p>The Anoma architecture is the blueprint that defines the structure and behaviour of the components that make up the Anoma protocol. There is one high-level component: the System architecture<sup>1</sup>.</p>","tags":["index"],"boost":2},{"location":"arch/overview.html#system-architecture","title":"System architecture","text":"<p>Defines the high-level structure and behaviour of the distributed network, including:</p> <ul> <li>Distributed state management </li> <li>Core data types and data flow for Network operations</li> <li>System-wide properties and guarantees</li> </ul> <ol> <li> <p>The Node architecture is a work-in-progress and can be found in the v0.2.0 release.\u00a0\u21a9</p> </li> </ol>","tags":["index"],"boost":2},{"location":"arch/integrations/adapters/index.html","title":"Protocol Adapters","text":"<p>A protocol adapter provides executor engine and shard engine functionality on a foreign blockchain protocol (adaptee) being independent of the Anoma protocol (target). In other words, it processes resource machine (RM) transactions and updates the RM state in correspondence with the adaptee's state changes.</p> <p>In order to support a protocol adapter, the adaptee protocol has to be programmable (i.e., support smart contracts).</p>","tags":["index","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/index.html#instances","title":"Instances","text":"<ul> <li>Ethereum Virtual Machine protocol adapter prototype (settlement-only)</li> </ul>","tags":["index","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html","title":"Ethereum Virtual Machine Protocol Adapter","text":"<p>The Ethereum Virtual Machine (EVM) protocol adapter is a smart contract written in Solidity that can be deployed to EVM compatible chains and roll-ups to connect them to the Anoma protocol. In general, the aim of the protocol adapter is to allow Anoma applications to be run on existing EVM-compatible chains (similar to how drivers allow an operating system to be run on different pieces of physical hardware).</p> <p>The current prototype is a settlement-only protocol adapter, i.e., it is only capable of processing fully-evaluated transaction functions and therefore does not implement the full executor engine behaviour.</p> <p>The implementation can be found in the <code>anoma/evm-protocol-adapter</code> GH repo.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#supported-networks","title":"Supported Networks","text":"<p>For the upcoming product version v0.3, only the Sepolia network will be supported.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#storage","title":"Storage","text":"<p>The protocol adapter contract inherits the following storage components as Solidity contracts:</p> <ul> <li>Commitment Accumulator</li> <li>Nullifier Set</li> <li>Blob Storage</li> </ul> <p>Only the protocol adapter can call non-view functions implemented by the storage components.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#commitment-accumulator","title":"Commitment Accumulator","text":"<p>The implementation uses a modified version of the OpenZeppelin <code>MerkleTree</code> v.5.2.0 that populates the binary tree from left to right and stores commitment indices in a hash table</p> <pre><code> mapping(bytes32 commitment =&gt; uint256 index) internal _indices;\n</code></pre> <p>allowing for commitment existence checks.</p> <p>In addition to the leaves, the modified Merkle tree implementation stores also the intermediary node hashes, which allows to obtain Merkle proofs directly from the contract.</p> <p>Historical Merkle tree roots are stored in an OpenZeppelin <code>EnumerableSet</code> v5.2.0 allowing for existence checks.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#nullifier-set","title":"Nullifier Set","text":"<p>The implementation uses an OpenZeppelin <code>EnumerableSet</code> v5.2.0 to store nullifiers of consumed resources and allow for existence checks.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#blob-storage","title":"Blob Storage","text":"<p>The implementation uses a simple hash table to store blobs content-addressed.</p> <pre><code>mapping(bytes32 blobHash =&gt; bytes blob) internal _blobs;\n</code></pre> <p>From the list of deletion criteria, the current blob storage implementation supports the following two:</p> <pre><code>enum DeletionCriterion {\n    Immediately,\n    Never\n}\n</code></pre>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#hash-function","title":"Hash Function","text":"<p>For hashing, we compute the SHA-256 hash of the strictly ABI-encoded data. SHA-256 is available as a pre-compile in both the EVM and RISC ZERO zkVM.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#types-computable-components","title":"Types &amp; Computable Components","text":"<p>The RM-related type and computable component definitions in Solidity can be found in the <code>src/Types.sol</code> and <code>src/libs/ComputableComponents.sol</code> file, respectively.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#proving-systems","title":"Proving Systems","text":"<p>For resource logic proof and compliance proof generation, we use RISC ZERO's proving libraries.</p> <p>For proof verification, we use the RISC ZERO verifier contracts.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#resource-logic-proofs","title":"Resource Logic Proofs","text":"<p>For the current prototype and the only supported example application basic shielded Kudos , we use a specific circuit resulting in the loss of function privacy. This will be improved in future iterations.</p> <p>The associated types are defined in <code>proving/Compliance.sol</code>.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#compliance-proofs","title":"Compliance Proofs","text":"<p>Compliance units have a fixed size and contain references to one consumed and one created resource. For transaction with \\(n_\\text{consumed} \\neq n_\\text{created}\\), we expect padding resources (ephemeral resources with quantity 0) to be used.</p> <p>The associated types are defined in <code>proving/Compliance.sol</code>.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#delta-proofs","title":"Delta Proofs","text":"<p>The delta values are computed as 2D points (<code>uint256[2]</code>) on the <code>secp256k1</code> (K-256) elliptic curve and can be verified using ECDSA.</p> <p>The associated elliptic curve addition and conversion methods are defined in <code>proving/Delta.sol</code>. The curve implementation is taken from Witnet's <code>eliptic-curve-solidity</code> library v0.2.1. This includes</p> <ul> <li>curve parameters</li> <li>curve addition (<code>ecAdd</code>)</li> <li>curve multiplication (<code>ecMul</code>)</li> </ul> <p>We use the zero delta public key derived from the private key <code>0</code>.</p> <p>As the verifying key (a.k.a. message digest), we use the keccak-256 hash over the list of all nullifier and commitments pairs being obtained by iterating over the compliance units (see <code>src/proving/Delta.sol</code>).</p> <p>For key recovery from the verifying key and signature, we use OpenZeppelin's <code>ECDSA</code> library.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#evm-and-rm-state-correspondence","title":"EVM and RM State Correspondence","text":"<p>Taking a protocol adapter contract-centric viewpoint, we distinguish between two types of EVM state:</p> <ol> <li>Internal resource machine (RM) state being maintained inside the protocol adapter contract that is constituted by commitments, nullifiers, and blobs (see Storage).</li> <li>External state existing in smart contracts which are independent of the protocol adapter and its internal RM state.</li> </ol> <p>To interoperate with state in external contracts, the protocol adapter contract can, during transaction execution, make read and write calls to them and create and consume corresponding resources in its internal state reflecting the external state reads and writes.</p> <p>We achieve this by creating an indirection layer separating the protocol adapter from the external contract and resources that should be created and consumed in consequence. It consists of:</p> <ul> <li>A forwarder contract that<ul> <li>performs the actual state read or write calls into the target contract and returns eventual return data</li> <li>is custom-built for the target contract to call and permissionlessly deployed by 3rd parties</li> </ul> </li> </ul> <ul> <li>A calldata carrier resource (singleton) that<ul> <li>must be part of the action data structure containing the forwarder call instruction</li> <li>carries the inputs and outputs of the forwarded call</li> <li>expresses constraints over other resources that must be present and correspond to the external call</li> </ul> </li> </ul> <p>and allows the application to ensure the correspondence.</p> <p></p> <p>This works as follows:</p> <p>The protocol adapter accepts an optional <code>ForwarderCalldata</code> struct with the RM transaction object as part of the action object (see <code>src/Types.sol</code>):</p> <p><pre><code>struct ForwarderCalldata {\n    address untrustedForwarderContract;\n    bytes input;\n    bytes output;\n}\n</code></pre> The struct contains the address of the forwarder contract and <code>bytes input</code> data required for the intended state read or write calls on the target contract. It also contains the <code>bytes output</code> data that must match the data returned from the call.</p> <p>The protocol adapter ensures the <code>ForwarderCalldata</code> is part of the app data of the singleton calldata carrier resources that has a pre-determined kind being referenced in the forwarder contract.</p> <p>Note</p> <p>In the current, settlement-only protocol adapter design, the <code>output</code> data must already be known during proving time to be checked by resource logics and therefore is part of the <code>ForwarderCalldata</code> struct.</p> <p>The binding between the created calldata carrier resource and the called forwarder contract is ensured through the protocol adapter, which</p> <ol> <li>is the exclusive caller of the forwarder contract,</li> <li>ensures the presence of the created calldata carrier resource in correspondence to the call in the transaction,</li> <li>ensures that the forwarder contract call input data, call output data, and address is available in the app data entry of the created calldata carrier resource under its commitment,</li> <li>ensures that the kind of the created calldata carrier resource matches the kind being immutably referenced in the forwarder contract. This way, the calldata carrier resource logic and label are fully determined by the forwarder contract.</li> </ol> <p>Because the calldata carrier resource is a singleton, we know that the consumption of the old carrier is guaranteed through the transaction balance property.</p> <p>The created calldata carrier resource, in turn, can enforce creation or consumption of other resources corresponding to external state.</p> <p>In the following we describe the components in more detail.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#forwarder-contract","title":"Forwarder Contract","text":"<p>The forwarder contract</p> <ul> <li>is only callable by the protocol adapter</li> <li>has the address to the external contract it corresponds to</li> <li>forwards arbitrary calls to the external contract to read and write its state and changes the call context (i.e., <code>msg.sender</code> and <code>msg.data</code>)</li> <li>returns the call return data to the protocol adapter</li> </ul> <p>The resulting indirection has the purpose to keep custom logic such as</p> <ul> <li>callback logic (e.g., required by ERC-721 or ERC-1155 tokens)</li> <li>escrow logic (e.g., required to wrap owned state into resources)</li> <li>event logic (e.g., required for EVM indexers)</li> </ul> <p>separate and independent of the protocol adapter contract. This allows the forwarder contract to be custom-built and permissionlessly deployed by untrusted 3rd parties.</p> <p>Besides referencing the external contract by its address, the forwarder contract must also reference the resource kind of the associated calldata carrier resource that the protocol adapter will require be created. This allows the forwarder contract to also to enforce its own contract address to be part of the carrier resource label, which ensures that the correspondence between the forwarder and carrier resource is unique.</p> <p>Note</p> <p>The mutual dependency between - the calldata carrier resource label containing the forwarder contract address - the forwarder contract referencing the calldata carrier resource label</p> <pre><code>can be established by deterministic deployment or post-deployment initialization of the forwarder contract.\n</code></pre>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#implementation-details","title":"Implementation Details","text":"<p>A minimal implementation is shown below:</p> <pre><code>contract ExampleForwarder is Ownable {\n  bytes32 internal immutable _CALLDATA_CARRIER_RESOURCE_KIND;\n  address internal immutable _CONTRACT;\n\n    constructor(address protocolAdapter, bytes32 calldataCarrierLogicRef) Ownable(protocolAdapter) {\n        _CALLDATA_CARRIER_RESOURCE_KIND = ComputableComponents.kind({\n            logicRef: calldataCarrierLogicRef,\n            labelRef: sha256(abi.encode(address(this)))\n        });\n    }\n\n  function forwardCall(bytes calldata input) external onlyOwner returns (bytes memory output) {\n      output = _CONTRACT.functionCall(input);\n  }\n\n  function calldataCarrierResourceKind() external view returns (bytes32 kind){\n      kind = _CALLDATA_CARRIER_RESOURCE_KIND;\n  }\n}\n</code></pre> <p>The required calldata is passed with the RM transaction object as part of the <code>Action</code> struct (see <code>src/Types.sol</code>).</p> <pre><code>struct ForwarderCalldata {\n    address untrustedForwarderContract;\n    bytes input;\n    bytes output;\n}\n</code></pre> <p>On transaction execution by the protocol adapter, the <code>ForwarderCalldata</code> struct is processed as follows:</p> <pre><code>function _executeForwarderCall(ForwarderCalldata calldata call) internal {\n    bytes memory output = IForwarder(call.untrustedForwarder).forwardCall(call.input);\n\n    if (keccak256(output) != keccak256(call.output)) {\n        revert ForwarderCallOutputMismatch({ expected: call.output, actual: output });\n    }\n}\n</code></pre> <p>The forwarder contract base class can be found in <code>src/ForwarderBase.sol</code>.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#calldata-carrier-resource","title":"Calldata Carrier Resource","text":"<p>A calldata carrier resource is a singleton (i.e., it has a unique kind ensuring that only a single instance with quantity 1 exists) being bound to an associated forwarder contract. By default, calldata carrier resources can be consumed by everyone (because their nullifier key commitment is derived from the universal identity).</p> <p>Note</p> <p>When the singleton calldata carrier resource is consumed in a transaction, subsequent transactions in the same block cannot consume it anymore. This effectively limits the current design to a single forwarder contract call per block (if the commitment of the latest, unspent calldata carrier resource is not known to the subsequent transaction ahead of time). This will be improved in upcoming protocol adapter versions.</p> <p>The calldata carrier resource object is passed to the protocol adapter together with the <code>ForwarderCalldata</code> struct (see <code>src/Types.sol</code>):</p> <pre><code>struct ResourceForwarderCalldataPair {\n    Resource carrier;\n    ForwarderCalldata call;\n}\n</code></pre> <p>This allows the protocol adapter to ensure that 1. the calldata carrier resource kind matches the one referenced in the forwarder contract and 2. a corresponding <code>action.appData</code> entry exists for the calldata carrier resource commitment tag that includes the <code>ForwarderCalldata</code>.</p> <p>The latter allows calldata carrier to inspect the <code>bytes input</code> and <code>bytes output</code> in the <code>ForwarderCalldata</code> and ensure the creation and consumption of resources corresponding to the external state reads or writes in the same action. Moreover, it can integrity check that its own label matches the <code>untrustedForwarderContract</code> address.</p> <p>This enables applications, such as wrapping ERC20 tokens into resources, which works by 1. transferring tokens from an owner into the forwarder contract via <code>transferFrom</code> and 2. initializing an owned resource with a corresponding quantity and the kind being specified in the forwarder contract.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#resources-corresponding-to-external-state","title":"Resources Corresponding to External State","text":"<p>Resources can correspond to EVM state and correspond to a specific calldata carrier resource kind being referenced in their label. Their initialization and finalization logic requires a created calldata carrier resource to be part of the same action.</p>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm.html#transaction-flow","title":"Transaction Flow","text":"<p>The protocol adapter transaction flow is shown below:</p> <p></p> <ol> <li>A user Alice calls a transaction function of a Juvix application to produce an ARM transaction object (here expressing an intent) as well as the instances and witnesses for the various proof types (resource logic, compliance, and delta proofs).</li> <li>The transaction function requests proofs from the RISC ZERO backend.</li> <li>The backend returns the proofs for the transaction object.</li> <li>The Anoma client sends the intent transaction object    to the intent pool.</li> <li>Another user Bob expresses his intent (see 1. to 3.).</li> <li>See 4.</li> <li>A solver Sally monitors the intent pool and sees the intent transactions by Alice and Bob and finds a match (using her algorithm).</li> <li>Sally composes the intent transactions and adds her own actions s.t. the transaction becomes balanced &amp; valid. She converts the transaction object into the format required by the EVM protocol adapter.</li> <li>Sally being connected to an Ethereum node makes an <code>eth_sendTransaction</code> call into the protocol adapter's <code>execute(Transaction tx)</code> function, which she signs with the private key of her account.</li> <li>The protocol adapter verifies the proofs from 3. by calling a RISC ZERO verifier contract deployed on the network.</li> <li>The protocol adapter makes an optional forwarder contract call by using the <code>ForwarderCalldata.input</code> data.</li> <li>The forwarder contract forwards the call to an external target contract to read from or write to its state.</li> <li>Optional return data is passed back to the forwarder contract.</li> <li>Return data (that can be empty) is passed to the protocol adapter contract allowing it to conduct integrity checks (by requiring the same data to be part of <code>action.appData</code>).</li> <li> <p>The protocol adapter updates its internal state by storing</p> <ul> <li>nullifiers of consumed resources</li> </ul> <ul> <li>commitments of created resources</li> </ul> <ul> <li>blobs with deletion criteria <code>!= DeletionCriterion.Immediately</code>.</li> </ul> </li> </ol>","tags":["work-in-progress","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/system/identity/identity.html","title":"Identity Architecture Types","text":"Juvix imports <pre><code>module arch.system.identity.identity;\nimport prelude open;\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-architecture","title":"Identity Architecture","text":"Type definitions <pre><code>type OrdKey OrdKeyType :=\n  mkOrdKey@{\n    compare : OrdKeyType -&gt; OrdKeyType -&gt; Ordering\n  };\n</code></pre> <pre><code>type HASH OrdKeyType Hashable :=\n  mkHASH@{\n    ordKey : OrdKey OrdKeyType;\n    hash : Hashable -&gt; OrdKeyType\n  };\n</code></pre> <pre><code>-- Note: instance of this with Data.Map should be made\ntype OrdMap (OrdKeyType : Type) (MapCon : Type -&gt; Type) :=\n  mkMap {\n    ordKey : OrdKey OrdKeyType;\n    empty {A} : MapCon A;\n    map {A B} : (A -&gt; B) -&gt; MapCon A -&gt; MapCon B;\n    insert {A} : Pair (MapCon A) (Pair OrdKeyType A) -&gt; MapCon A;\n    foldl {A B} : (Pair A B -&gt; B) -&gt; B -&gt; MapCon A -&gt; B;\n    intersectWith {A B C} : (Pair A B -&gt; C) -&gt; Pair (MapCon A) (MapCon B) -&gt; MapCon C;\n    all {A} : (A -&gt; Bool) -&gt; MapCon A -&gt; Bool\n    -- Bunch of stuff, see https://www.smlnj.org/doc/smlnj-lib/Util/sig-OrdMap.html\n  };\n</code></pre> <p>The base abstraction of the protocol is a knowledge-based identity  interface, where the identity of an agent is defined entirely on the  basis of whether or not they know some secret information.</p> <p>Agents can use private information (likely randomness) to create an  internal identity, from which they can derive an  external identity to which it corresponds. The external identity can be shared with other parties. The agent who knows the internal identity can sign messages, which any  agent who knows the external identity can verify, and any agent who  knows the external identity can encrypt messages which the agent with  knowledge of the internal identity can decrypt. This identity interface is independent of the particular cryptographic  mechanisms, which may vary.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-interface","title":"Identity Interface","text":"","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#internal-identity","title":"Internal Identity","text":"<p>An internal identity includes private information necessary for signing and  decryption. Formally, an internal identity has two parts: a Signer and a Decryptor.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signer-juvix-type","title":"Signer Juvix Type","text":"<p>A signature describing a type <code>SignerType</code> that can cryptographically  <code>sign</code> (or credibly commit) to something (a <code>Signable</code>), forming a  <code>Commitment</code>. Implementations should ultimately include, for example  BLS keys,   which should be able to sign anything that can be marshaled into a   bitstring.</p> <p>Properties:</p> <ul> <li> <p>In general, every <code>S : Signer</code> needs a corresponding <code>V : Verifier</code>, and   every <code>s : SignerType</code> needs a corresponding <code>v : VerifierType</code>, such that:</p> <ul> <li>For any message <code>m</code> : <code>verify v m x = (x = (sign s m))</code></li> </ul> <ul> <li>for most cryptosystems, a computationally bounded adversary should not be   able to approximate <code>s</code> knowing only <code>v</code>.</li> </ul> </li> </ul> <pre><code>type Signer SignerType Signable Commitment :=\n  mkSigner@{\n    sign : SignerType -&gt; Signable -&gt; Commitment\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#decryptor-juvix-type","title":"Decryptor Juvix Type","text":"<p>A signature describing a type <code>DecryptorType</code> that can cryptographically  <code>decrypt</code> something (a <code>Ciphertext</code>), resulting in a <code>Plaintext</code>  (or <code>none</code>, if decryption fails). Implementations should ultimately include, for example,  AES-256  keys,  which should be able to decrypt bitstrings into anything that  can be unmarshaled from a bitstring.</p> <p>Properties:</p> <ul> <li>a computationally bounded adversary should not be able to   approximate <code>decrypt d</code> without knowledge of <code>d</code>.</li> </ul> <ul> <li><code>decrypt</code> should take polynomial time (in the size of its inputs)</li> </ul> <ul> <li> <p>Each <code>D : Decryptor</code> should have a corresponding <code>E : Encryptor</code>, and   each <code>d : DecryptorType</code> has a corresponding <code>e : EncryptorType</code> such   that:</p> <ul> <li>for all <code>c : Ciphertext</code>, <code>p : Plaintext</code>:   <code>decrypt d c = Some p</code> iff <code>c = encrypt e p</code></li> </ul> <ul> <li>if <code>d = e</code>, we call this \"symmetric encryption,\" and otherwise   it's \"asymmetric encryption\"</li> </ul> </li> </ul> <pre><code>type Decryptor DecryptorType Plaintext Ciphertext :=\n  mkDecryptor@{\n    decrypt : DecryptorType -&gt; Ciphertext -&gt; Option Plaintext\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#internal-identity-juvix-type","title":"Internal Identity Juvix Type","text":"<p>An Internal Identity structure simply specifies everything specified by both Signer and Decryptor.</p> <p>An Internal Identity structure specifies the necessary types and  functions for both a Signer and a Decryptor. Implementations should ultimately include, for example,  RSA private keys,  which should be able to decrypt integers into anything that can be  unmarshaled from a bitstring, and sign anything which can be  marshaled into a bytestring to form an integer.</p> <p>An internal_identity includes:</p> <ul> <li>a type <code>SignerType</code> that can cryptographically   <code>sign</code> (or credibly commit) to something (a <code>Signable</code>), forming a   <code>Commitment</code>.</li> </ul> <ul> <li>a type <code>DecryptorType</code> that can cryptographically <code>decrypt</code> something   (a <code>Ciphertext</code>), resulting in a <code>Plaintext</code>   (or <code>none</code>, if decryption fails).</li> </ul> <p>Properties are inherited from <code>Signer</code> and <code>Decryptor</code>.</p> <pre><code>type InternalIdentity\n    SignerType\n    Signable\n    Commitment\n    DecryptorType\n    Plaintext\n    Ciphertext :=\n  mkInternalIdentity@{\n    signer : Signer SignerType Signable Commitment;\n    decryptor : Decryptor DecryptorType Plaintext Ciphertext\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#external-identity","title":"External Identity","text":"<p>An external identity includes only public information. An external identity can verify signatures produced by an internal identity, and encrypt messages the internal identity can then decrypt. Formally, an external identity has two parts: a verifier and an Encryptor. Each is hashable: any structure specifying verifier and Encryptor types must also specify a hash function, so that external identities can be specified by hash.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#verifier-juvix-type","title":"Verifier Juvix Type","text":"<p>A signature describing a type <code>VerifierType</code> that can cryptographically  <code>verify</code> that a <code>Commitment</code> (or cryptographic signature) corresponds  to a given message (a <code>Signable</code>), and was signed by the <code>SignerType</code>  corresponding to this <code>VerifierType</code>. A <code>VerifierType</code> can be hashed (producing a unique identifier), so a  structure with signature <code>Verifier</code> must specify a <code>VerifierHash</code>  structure defining a suitable <code>hash</code> function. Implementations should ultimately include, for example  BLS  identities.</p> <p>Properties:</p> <ul> <li> <p>In general, every <code>V : Verifier</code> needs a corresponding <code>S : Signer</code>, and   every <code>s : SignerType</code> needs a corresponding <code>v : VerifierType</code>, such that:</p> <ul> <li>For any message <code>m</code> : <code>verify v m x = (x = (sign s m))</code></li> </ul> <ul> <li>for most cryptosystems, a computationally bounded adversary should not be   able to approximate <code>s</code> knowing only <code>v</code>.</li> </ul> </li> </ul> <pre><code>type Verifier OrdKey VerifierType Signable Commitment :=\n  mkVerifier@{\n    verify : VerifierType -&gt; Signable -&gt; Commitment -&gt; Bool;\n    verifierHash : HASH OrdKey VerifierType\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#encryptor-juvix-type","title":"Encryptor Juvix Type","text":"<p>A signature describing a type <code>EncryptorType</code> that can cryptographically  <code>encrypt</code> a <code>Plaintext</code> (message) to create a <code>Ciphertext</code> readable  only by the corresponding <code>DecryptorType</code>. An <code>EncryptorType</code> can be hashed (producing a unique identifier), so a  structure with signature <code>Encryptor</code> must specify an <code>encryptorHash</code>  structure defining a suitable hash function. Implementations should ultimately include, for example,  AES-256  keys,  which should be able to decrypt bitstrings into anything that  can be  unmarshaled from a bitstring.</p> <p>Properties:</p> <ul> <li><code>encrypt</code> should take polynomial time (in the size of its inputs)</li> </ul> <ul> <li> <p>Each <code>E : Encryptor</code> should have a corresponding <code>D : Decryptor</code>, and   each <code>d : DecryptorType</code> has a corresponding <code>e : EncryptorType</code> such   that:</p> <ul> <li>for all <code>c : Ciphertext</code>, <code>p : Plaintext</code>:   <code>decrypt d c = Some p</code> iff <code>c = encrypt e p</code></li> </ul> <ul> <li>if <code>d = e</code>, we call this \"symmetric encryption,\" and otherwise   it's \"asymmetric encryption.\"   In an asymmetric cryptosystem, a computationally bounded adversary   should not be able to approximate <code>d</code> knowing only <code>e</code>.</li> </ul> </li> </ul> <pre><code>type Encryptor OrdKey EncryptorType Plaintext Ciphertext :=\n  mkEncryptor@{\n    encrypt : EncryptorType -&gt; Plaintext -&gt; Ciphertext;\n    encryptorHash : HASH OrdKey EncryptorType\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#external-identity-juvix-type","title":"External Identity Juvix Type","text":"<p>An External Identity structure specifies the necessary types and  functions for both a Verifier and an Encryptor. Implementations should ultimately include, for example,  RSA public keys.</p> <p>An external_identity includes:</p> <ul> <li>a type <code>VerifierType</code> that can cryptographically <code>verify</code> that a   <code>Commitment</code> (or cryptographic signature) corresponds to a given   message (a <code>Signable</code>), and was signed by the <code>SignerType</code>   corresponding to this <code>VerifierType</code>.</li> </ul> <ul> <li>a type <code>EncryptorType</code> that can cryptographically <code>encrypt</code> a   <code>Plaintext</code> (message) to create a <code>Ciphertext</code> readable only by the   corresponding <code>DecryptorType</code>.</li> </ul> <p>Properties are inherited from <code>Verifier</code> and <code>Encryptor</code>.</p> <pre><code>type ExternalIdentity\n  VerifierOrdKeyType\n  VerifierType\n  Signable\n  Commitment\n  EncryptorOrdKeyType\n  EncryptorType\n  Plaintext\n  Ciphertext\n  :=\n  mkExternalIdentity@{\n    verifier : Verifier VerifierOrdKeyType VerifierType Signable Commitment;\n    encryptor : Encryptor EncryptorOrdKeyType EncryptorType Plaintext Ciphertext\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-juvix-type","title":"Identity Juvix Type","text":"<p>An Identity structure, formally, specifies all the types for  corresponding internal and external identities. So, for a given Identity structure <code>I</code>, its <code>VerifierType</code> should be the  type of objects that can verify <code>Commitment</code>s produced by a  corresponding object of type <code>SignerType</code>. Likewise, its <code>DecryptorType</code> should be the type of objects that can decrypt  <code>Ciphertext</code>s produced by a corresponding object of type  <code>EncryptorType</code>. Implementations should ultimately include, for example,  RSA  public / private keys sytems.</p> <p>An Identity includes:</p> <ul> <li>a type <code>SignerType</code> that can cryptographically <code>sign</code> (or credibly commit) to something (an <code>InternalSignable</code>), forming an <code>InternalCommitment</code>.</li> </ul> <ul> <li>a type <code>DecryptorType</code> that can cryptographically <code>decrypt</code> something (an <code>InternalCiphertext</code>), resulting in an <code>InternalPlaintext</code> (or <code>none</code>, if decryption fails).</li> </ul> <ul> <li>a type <code>VerifierType</code> that can cryptographically <code>verify</code> that an <code>ExternalCommitment</code> (or cryptographic signature) corresponds to a given message (an <code>ExternalSignable</code>), and was signed by the <code>SignerType</code> corresponding to this <code>VerifierType</code>.</li> </ul> <ul> <li>a type <code>EncryptorType</code> that can cryptographically <code>encrypt</code> an <code>ExternalPlaintext</code> (message) to create an <code>ExternalCiphertext</code> readable only by the corresponding <code>DecryptorType</code>.</li> </ul> <p>Properties are inherited from <code>Verifier</code>, <code>Encryptor</code>, <code>Signer</code>, and <code>Decryptor</code>.</p> <pre><code>type Identity\n  SignerType\n  InternalSignable\n  InternalCommitment\n  DecryptorType\n  InternalCiphertext\n  InternalPlaintext\n  VerifierOrdKeyType\n  VerifierType\n  ExternalSignable\n  ExternalCommitment\n  EncryptorOrdKeyType\n  EncryptorType ExternalPlaintext ExternalCiphertext\n   :=\n  mkIdentity@{\n    internalIdentity : InternalIdentity SignerType InternalSignable InternalCommitment DecryptorType InternalPlaintext InternalCiphertext;\n    externalIdentity : ExternalIdentity VerifierOrdKeyType VerifierType ExternalSignable ExternalCommitment EncryptorOrdKeyType EncryptorType ExternalPlaintext ExternalCiphertext\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-relation","title":"SignsFor Relation","text":"<p>Some identities may have the authority to sign statements on behalf of other  identities. For example, Alice might grant Bob the authority to sign arbitrary messages on her behalf. We write this relationship as Bob <code>signsFor</code> Alice.</p> <p>In general, <code>signsFor</code> is a partial order over identities. This means <code>signsFor</code> is transitive: if A <code>signsFor</code> B and B <code>signsFor</code> C, then A <code>signsFor</code> C. The <code>signsFor</code> relation becomes especially useful with regard to composed identities, discussed below.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-evidence","title":"SignsFor Evidence","text":"<p>We do not specify all the ways one might know if one identity <code>signsFor</code> another. In general, an Identity Engine might accept (and perhaps store) a variety of forms of evidence as proof. As one simple form of evidence, we can specify a format for signed statements from B that proves some specified A <code>signsFor</code> B.</p> <p>Note that <code>signsFor</code> evidence cannot be revoked, and so a <code>signsFor</code> relation is not stateful: it cannot depend on the current state of, for example, a blockchain.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-juvix-type","title":"SignsFor Juvix Type","text":"<p>Formally, a <code>signsFor</code> relation requires a type of evidence, and a  <code>Verifier</code> structure. This codifies a belief about what <code>VerifierType</code>'s <code>Commitments</code> are  \"at least as good as\" another <code>VerifierType</code>'s. Evidence can be signed statements, proofs, or even local state about beliefs.</p> <p>For example, suppose <code>Alice</code> wants to grant authority to <code>Bob</code> to  <code>sign</code> on her behalf. Nodes who want to take this into account might accept some sort of  <code>e : Evidence</code>, perhaps a signed statement from <code>Alice</code>, so that they  can recognize that <code>signsFor e (Bob, Alice)</code>.</p> <p>Note that <code>signsFor</code> is not symmetric: <code>signsFor e (x,y)</code> does not  imply that any <code>z</code> exists such that <code>signsFor z (y,x)</code>.</p> <pre><code>type SignsFor OrdKey VerifierType Signable Commitment Evidence :=\n  mkSignsFor@{\n    verifier : Verifier OrdKey VerifierType Signable Commitment;\n    signsFor : Evidence -&gt; (Pair VerifierType VerifierType) -&gt; Bool\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-equivalence","title":"SignsFor Equivalence","text":"<p>We can also define a kind of identity equivalence : A <code>signsSameAs</code> B  precisely when A <code>signsFor</code> B and B <code>signsFor</code> A. This means that (in  general), if you want to sign a message as A, but for whatever reason it's cheaper to sign a message as B, it's safe to just use B instead, and vice  versa.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-relation","title":"ReadsFor Relation","text":"<p>Similar to <code>signsFor</code>, it is useful to sometimes note that one identity can read  information encrypted to another identity. For example, suppose Alice gives her private <code>DecryptorType</code> to Bob, and wants to let everyone know that Bob can  now read anything encrypted to Alice. Nodes who want to take this into  account might accept some sort of <code>evidence</code>, perhaps a signed statement from Alice, so that they can recognize that Bob <code>readsFor</code> Alice.</p> <p>Like <code>signsFor</code>, <code>readsFor</code> is a partial order over identities. This means <code>readsFor</code> is transitive: if A <code>readsFor</code> B and B <code>readsFor</code> C, then A <code>readsFor</code> C. The <code>readsFor</code> relation becomes especially useful with regard to composed identities, discussed below.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-evidence","title":"ReadsFor Evidence","text":"<p>We do not specify all the ways one might know if one identity <code>readsFor</code>  another. In general, an Identity Engine might accept (and perhaps store) a variety of forms of evidence as proof. As one simple form of  evidence, we can specify a format for signed statements from B that proves A <code>readsFor</code> B.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-juvix-type","title":"ReadsFor Juvix Type","text":"<p>Formally, a <code>readsFor</code> relation requires a type of evidence, and an  <code>Encryptor</code> structure. This codifies a belief about what <code>Decryptor</code>s can read other  <code>Encryptor</code>s ciphertext. Evidence can be signed statements, proofs, or even local state about beliefs.</p> <p>Specifically, if a node expresses a <code>readsFor</code> relation, and  <code>readsFor e (x,y)</code>, then the node believes that any node knowing the  decryptor corresponding to <code>x</code> can decrypt <code>encrypt y p</code>. If there is some Plaintext <code>p</code> such that some node knowing a decryptor  corresponding to <code>x</code> cannot read <code>encrypt y p</code>, then the node's  beliefs, as encoded in the <code>readsFor</code> relation, are incorrect.</p> <p>For example, suppose <code>Alice</code> gives her private <code>DecryptorType</code> to <code>Bob</code>,  and wants to let everyone know that <code>Bob</code> can now read anything  encrypted to <code>Alice</code>. Nodes who want to take this into account might accept some sort of  <code>e : Evidence</code>, perhaps a signed statement from <code>Alice</code>, so that they  can recognize that <code>readsFor e (Bob, Alice)</code>.</p> <p>Note that <code>readsFor</code> is not symmetric: <code>readsFor e (x,y)</code> does not  imply that any <code>z</code> exists such that <code>readsFor z (y,x)</code>.</p> <pre><code>type ReadsFor (OrdKey EncryptorType Plaintext Ciphertext Evidence : Type) :=\n  mkReadsFor {\n    encryptor : Encryptor OrdKey EncryptorType Plaintext Ciphertext;\n    readsFor : Evidence -&gt; (Pair EncryptorType EncryptorType) -&gt; Bool\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#equivalence","title":"Equivalence","text":"<p>We can also define a kind of identity equivalence: A <code>readsSameAs</code> B precisely when A <code>readsFor</code> B and B <code>readsFor</code> A. This means that, in general, if you want to encrypt a message to A, but for whatever reason it's cheaper to encrypt a message for B, it's safe to just use B instead, and vice versa.</p> <p>In total, A <code>equivalent</code> B when A <code>readsSameAs</code> B and A <code>signsSameAs</code> B. This means that (in general) A and B can be used interchangeably.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#composition","title":"Composition","text":"<p>There are a variety of ways to refer to groups of identities as  single, larger identities.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#threshold-composition","title":"Threshold Composition","text":"<p>Suppose we want an identity M that refers to any majority from a  set of shareholders. A signature from M would require that a majority of shareholders  participated in signing, and encrypting information for M would  require that a majority of shareholders participate in decryption. To construct M, we start with a set of shareholder identities, each  paired with a weight (their share), and define a weight threshold  which specifies the minimum weight for a \"majority.\"</p> <p>There are several ways we could imagine constructing Threshold  Composition Identities, but without specifying anything about the  underlying identities:</p> <ul> <li>A threshold composition identity signature is a map from (hashes of)    external identities, to signatures.   To verify a signature for some message <code>x</code>, we verify each signature    with <code>x</code> and its external identity, and check that the weights of    the external identities sum to at least the threshold.</li> </ul> <ul> <li>A threshold composition identity encrypted message is a map from    (hashes of) external identities, to ciphertexts.   To decrypt, any subset of internal identities with weights summing    to at least the threshold must decrypt their corresponding    ciphertexts, and the resulting plaintexts must be combined using an    erasure coding scheme.</li> </ul>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#threshold-composition-juvix-type-signer-and-verifier","title":"Threshold Composition Juvix Type (Signer and verifier)","text":"<p>A <code>ThresholdCompose</code> <code>VerifierType</code> consists of a  threshold (<code>Nat</code>), and a set of <code>VerifierType</code>s, each paired with a  weight (<code>Nat</code>).  (this set is encoded as a <code>Map.map</code> from hashes of <code>verifiers</code> to   <code>Pair Nat VerifierType</code> pairs). <code>Commitments</code> are simply <code>Map</code>s from hashes of the underlying  identities to <code>Commitments</code> signed by that identitity. A <code>Commitment</code> verifies iff the set of valid Commitments included  correspond to a set of <code>verifiers</code> whose weights sum to at least  the threshold. Note that this satisfies both signatures <code>Verifier</code> and <code>Signer</code>.</p> <p>In general, <code>ThresholdCompose</code> <code>SignerType</code>s and <code>VerifierType</code>s may not be  used much directly. Instead, nodes can make more efficient identities (using cryptographic  signature aggregation techniques), and express their relationship to  <code>ThresholdCompose</code> <code>VerifierType</code>s as a <code>SignsFor</code> relationship. This will let nodes reason about identities using simple  <code>ThresholdCompose</code> <code>VerifierType</code>s, while actually using more efficient  implementations.</p> <p>Formally, to specify a <code>ThresholdCompose</code>, we need:</p> <ul> <li><code>verifier</code>, the structure of the underlying <code>Verifiers</code>.</li> </ul> <ul> <li><code>signer</code>, the corresponding structure of the underlying <code>Signers</code>.</li> </ul> <ul> <li><code>map : OrdMap</code>, to be used to encode weights and <code>Commitment</code>s.   (Note that this needs the <code>OrdKey</code> to be the hash type of the    underlying <code>verifier</code>)</li> </ul> <ul> <li><code>thresholdComposeHash</code>, which specifies a <code>hash</code> function that can    hash our composed <code>VerifierType</code>s (type <code>ComposeHashable VerifierType MapCon</code>).</li> </ul> <pre><code>type ComposeHashable (VerifierType : Type) (MapCon : Type -&gt; Type) :=\n  mkComposeHashable {\n    threshold : Nat;\n    weights : MapCon (Pair Nat VerifierType)\n  };\n</code></pre> <p>A <code>ThresholdCompose</code> structure provides:</p> <ul> <li><code>map : OrdMap</code> the underlying <code>OrdMap</code> used in    <code>VerifierType</code> and <code>Commitment</code></li> </ul> <ul> <li><code>underlyingVerifier : Verifier</code> the structure describing    the types of the underlying <code>VerifierType</code>s which can be composed.</li> </ul> <ul> <li><code>underlyingSigner : Signer</code> the structure describing    the types of the underlying <code>SignerType</code>s which can be composed.</li> </ul> <ul> <li><code>VerifierHash : HASH</code> describes the hash function for    hashing these composed <code>verifiers</code></li> </ul> <ul> <li>The <code>SignerType</code> type of the composed verifiers is the type of composed signers.    These are just <code>MapCon Commitment</code>, meaning each is    stored under the hash of the corresponding    <code>VerifierType</code>.    This <code>SignerType</code> does not need to encode weights or threshold.</li> </ul> <ul> <li>The <code>VerifierType</code> type of composed verifiers. These are    <code>ComposeHashable VerifierType MapCon</code></li> </ul> <ul> <li>The <code>Signable</code> type , being the type of message that can be signed. This is    exactly the same as what the underlying verifiers can sign    (<code>Signable</code> of <code>underlyingVerifier</code>).</li> </ul> <ul> <li>The <code>Commitment</code> type describes composed signatures, these are a    <code>MapCon</code> from hashes of underlying verifiers to signatures    (<code>Commitment</code> of <code>underlyingVerifier</code>)</li> </ul> <ul> <li>The <code>sign</code> function creates a <code>Commitment</code> using all    <code>underlyingSigner</code> <code>SignerType</code>s in the composed <code>SignerType</code>.</li> </ul> <ul> <li>The <code>verify</code> function returns true iff the set of valid Commitments included    correspond to a set of <code>underlyingVerifier</code> <code>VerifierType</code>s whose weights    sum to at least the threshold.</li> </ul> <ul> <li>The <code>signerCompose</code> function constructs a composed <code>SignerType</code> from a list of    <code>Pair VerifierType SignerType</code> pairs.    Note that each <code>SignerType</code> must be paired with its correct <code>VerifierType</code>,     or the composed <code>SignerType</code> will not produce verifiable     <code>Commitment</code>s.</li> </ul> <ul> <li> <p>The <code>verifierCompose</code> function is useful for constructing the composition of    a list of verifiers.   Returns a composed <code>VerifierType</code>.   Its arguments are:</p> <ul> <li>the threshold (<code>Nat</code>)</li> </ul> <ul> <li>a <code>list</code> of weights(<code>Nat</code>), <code>VerifierType</code> pairs.</li> </ul> </li> </ul> <ul> <li>The <code>verifierAnd</code> function creates a composed <code>VerifierType</code> that is the \"&amp;&amp;\" of    two input verifiers: a <code>SignerType</code> must encode the information of the    signers for both <code>x</code> and <code>y</code> to sign statements <code>verifierAnd x y</code>    will verify.</li> </ul> <ul> <li>The <code>verifierOr</code> function creates a composed <code>VerifierType</code> that is the \"||\" of    two input verifiers: a <code>SignerType</code> must encode the information of the    signers for either <code>x</code> or <code>y</code> to sign statements <code>verifierOr x y</code>    will verify.</li> </ul> <pre><code>type ThresholdCompose\n  ( OrdKey : Type ) ( MapCon : Type -&gt; Type )\n  ( VerifierType Signable Commitment SignerType VerifierHashOrdKeyType : Type)\n  :=\n  mkThresholdCompose {\n    map : OrdMap OrdKey MapCon;\n    underlyingVerifier : Verifier OrdKey VerifierType Signable Commitment;\n    underlyingSigner : Signer SignerType Signable Commitment;\n    verifierHash : HASH VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon);\n\n    sign : MapCon SignerType -&gt; Signable -&gt; MapCon Commitment;\n    verify : (ComposeHashable VerifierType MapCon) -&gt; Signable -&gt; MapCon Commitment -&gt; Bool;\n    signerCompose : List (Pair VerifierType SignerType) -&gt; MapCon SignerType;\n    verifierCompose : Nat -&gt; List (Pair Nat VerifierType) -&gt; (ComposeHashable VerifierType MapCon);\n    verifierAnd : VerifierType -&gt; VerifierType -&gt; (ComposeHashable VerifierType MapCon);\n    verifierOr : VerifierType -&gt; VerifierType -&gt; (ComposeHashable VerifierType MapCon);\n  };\n</code></pre> <pre><code>projectVerifier\n  { MapCon : Type -&gt; Type }\n  { OrdKey VerifierType Signable Commitment SignerType VerifierHashOrdKeyType : Type }\n  ( tc : ThresholdCompose OrdKey MapCon VerifierType Signable Commitment SignerType VerifierHashOrdKeyType ) :\n  Verifier VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon) Signable (MapCon Commitment) :=\n  Verifier.mkVerifier@{\n    verify := ThresholdCompose.verify tc;\n    verifierHash := ThresholdCompose.verifierHash tc;\n  };\n</code></pre> <pre><code>ThresholdComposeFunctor\n  { MapCon : Type -&gt; Type }\n  { OrdKey VerifierType Signable Commitment SignerType VerifierHashOrdKeyType : Type }\n  (verifier : Verifier OrdKey VerifierType Signable Commitment)\n  (signer : Signer SignerType Signable Commitment)\n  (mapIn : OrdMap OrdKey MapCon)\n  (thresholdComposeHash : HASH VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon)) :\n  ThresholdCompose\n    OrdKey MapCon\n    VerifierType Signable Commitment\n    SignerType\n    VerifierHashOrdKeyType\n  :=\n  ThresholdCompose.mkThresholdCompose@{\n    map := mapIn;\n    underlyingVerifier := verifier;\n    underlyingSigner := signer;\n    verifierHash := thresholdComposeHash;\n    sign := \\ {s m := OrdMap.map map \\ { i := Signer.sign underlyingSigner i m } s};\n    verify := \\ {\n      | (ComposeHashable.mkComposeHashable t ws) s c := (\n          t &lt;= (\n            OrdMap.foldl map \\{(mkPair x y) := x + y} 0 (\n              OrdMap.intersectWith map (\n                \\{ | (mkPair (mkPair w v) x) :=\n                      if | (Verifier.verify underlyingVerifier v s x) := w\n                         | else := 0\n                }\n            ) (mkPair ws c)))\n      )\n    };\n\n    signerCompose := \\{ l :=\n        foldl\n        \\{ m (mkPair v s) :=\n          OrdMap.insert map (mkPair m (mkPair (\n            HASH.hash (Verifier.verifierHash underlyingVerifier) v\n          ) s))\n        }\n        (OrdMap.empty map) l\n    };\n\n    verifierCompose := \\{\n      threshold weights :=\n        (ComposeHashable.mkComposeHashable threshold\n          (foldl\n            \\ { m (mkPair w v) :=\n              OrdMap.insert map (mkPair m (mkPair (\n                HASH.hash (Verifier.verifierHash underlyingVerifier) v\n              ) (mkPair w v)))\n            }\n            (OrdMap.empty map) weights\n        ))\n    };\n\n    verifierAnd := \\{ x y := verifierCompose 2 [(mkPair 1 x); (mkPair 1 y)]};\n    verifierOr := \\{ x y := verifierCompose 1 [(mkPair 1 x); (mkPair 1 y)] };\n  };\n</code></pre> <p>While this construction is rather naive, it is general, and crucially, we can reason about  equivalence with any number of more interesting schemes:</p> <ul> <li>We can show that a threshold RSA signature scheme <code>signsSameAs</code> as a Threshold Composition    Identity.</li> </ul> <ul> <li>We can show that a secret sharing scheme <code>readsSameAs</code> a Threshold Composition Identity.</li> </ul> <p>By phrasing our discussion in terms of equivalence and Threshold Composition Identities, we can  abstract over the actual cryptography used. We can also derive some <code>signsFor</code> and <code>readsFor</code>  relations that must hold, by looking at the relations that must hold for Threshold Composition Identities:</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-threshold-composition","title":"<code>signsFor</code> Threshold Composition","text":"<p>Like any identity, Threshold Composition Identities can define any number of ways to delegate signing power, or be delegated signing power. However, some cases should always hold: A <code>signsFor</code> B if every identity in A has no more weight (divided by threshold) than identities it <code>signsFor</code> in B. This implies that any collection of identities that can sign as A can also sign as B.</p> <p>A <code>signsFor</code> relation for easy comparison of   <code>ThresholdCompose</code> <code>VerifierType</code>s  x <code>signsFor</code> y if every underlying VerifierType in x has no more   weight (divided by threshold) as verifiers it <code>signsFor</code> in y. This implies that anything which can sign as x can also sign  as y.</p> <p>This requires an underlying <code>S : SignsFor</code> for comparing the weighted  signers in x and y, which in turn may require evidence. No additional evidence is required.</p> <p>Other parameters necessary to define the <code>ThresholdCompose</code> <code>verifiers</code> include:</p> <ul> <li><code>signer</code>, the corresponding structure of the underlying <code>signers</code>.</li> </ul> <ul> <li><code>map : OrdMap</code>, to be used to encode weights and <code>Commitment</code>s.   (Note that this needs <code>OrdKey</code> to be the hash type of the    underlying <code>verifier</code>)</li> </ul> <ul> <li><code>thresholdComposeHash</code>, which specifies a <code>hash</code> function that can    hash our composed <code>VerifierType</code>s (type    <code>ComposeHashable VerifierType MapCon</code>).</li> </ul> <pre><code>type ThresholdComposeSignsFor\n  ( OrdKey VerifierType Signable Commitment Evidence : Type )\n  ( MapCon : Type -&gt; Type )\n  ( VerifierHashOrdKeyType )\n  :=\n  mkThresholdComposeSignsFor {\n    underlyingSignsFor : SignsFor OrdKey VerifierType Signable Commitment Evidence;\n    verifier : ThresholdCompose OrdKey MapCon VerifierType Signable Commitment VerifierType VerifierHashOrdKeyType;\n    signsFor : Evidence -&gt; Pair (ComposeHashable VerifierType MapCon) (ComposeHashable VerifierType MapCon) -&gt; Bool;\n  };\n</code></pre> <pre><code>projectSignsFor\n  { OrdKey VerifierType Signable Commitment Evidence }\n  { MapCon : Type -&gt; Type }\n  { VerifierHashOrdKeyType : Type }\n  ( tc : ThresholdComposeSignsFor OrdKey VerifierType Signable Commitment Evidence MapCon VerifierHashOrdKeyType ) :\n  SignsFor VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon) Signable (MapCon Commitment) Evidence :=\n  SignsFor.mkSignsFor@{\n    verifier := projectVerifier (ThresholdComposeSignsFor.verifier tc);\n    signsFor := ThresholdComposeSignsFor.signsFor tc;\n  };\n</code></pre> <pre><code>ThresholdComposeSignsForFunctor\n  { OrdKey VerifierType Signable Commitment Evidence }\n  { MapCon : Type -&gt; Type }\n  { VerifierHashOrdKeyType : Type }\n  ( S : SignsFor OrdKey VerifierType Signable Commitment Evidence )\n  ( signer : Signer VerifierType Signable Commitment)\n  ( map : OrdMap OrdKey MapCon )\n  ( thresholdComposeHash : HASH VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon) ) :\n  ThresholdComposeSignsFor OrdKey VerifierType Signable Commitment Evidence MapCon VerifierHashOrdKeyType\n  :=\n  ThresholdComposeSignsFor.mkThresholdComposeSignsFor@{\n    underlyingSignsFor := S;\n    verifier := ThresholdComposeFunctor (SignsFor.verifier underlyingSignsFor) signer map thresholdComposeHash;\n    signsFor := \\{\n      e (mkPair (ComposeHashable.mkComposeHashable t0 w0) (ComposeHashable.mkComposeHashable t1 w1)) :=\n        OrdMap.all map\n          \\{ (mkPair w v) :=\n              (w * t1) &lt;=\n              ((OrdMap.foldl map\n                \\{ (mkPair (mkPair x v1) s) :=\n                    if | (SignsFor.signsFor underlyingSignsFor e (mkPair v v1)) := x + s\n                       | else := s\n                }\n                0 w1\n                ) * t0)\n          }\n          w0\n    };\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#encryptor-threshold-composition","title":"<code>Encryptor</code> Threshold Composition","text":"<p>DANGER: NOT YET IMPLEMENTED</p> <p>Implementing this requires secret sharing.  The threshold composed <code>encryptor</code> is a threshold, and a set of weights  paired with <code>UnderlyingEncryptor.encryptor</code>s. There are stored in a <code>Map.map</code>  under their hashes, to ensure uniqueness.</p> <p>The idea is that an encrypted <code>plaintext</code> should only be  decryptable by a <code>decryptor</code> that encodes the information from a  set of <code>decryptor</code>s corresponding to a set of <code>encryptor</code>s whose  weight sums to at least the threshold.</p> <pre><code>type ThresholdComposeEncryptor\n  (OrdKey EncryptorType Plaintext Ciphertext : Type)\n  (MapCon : Type -&gt; Type)\n  (EncryptorHashOrdKeyType : Type)\n  :=\n  mkThresholdComposeEncryptor@{\n    map : OrdMap OrdKey MapCon;\n    underlyingEncryptor : Encryptor OrdKey EncryptorType Plaintext Ciphertext;\n    encryptorHash : HASH EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon);\n    compose : Nat -&gt; List (Pair Nat EncryptorType) -&gt; ComposeHashable EncryptorType MapCon;\n    encrypt : (ComposeHashable EncryptorType MapCon) -&gt; Plaintext -&gt; Ciphertext;\n  };\n</code></pre> <pre><code>projectEncryptor\n  {OrdKey EncryptorType Plaintext Ciphertext}\n  {MapCon : Type -&gt; Type}\n  {EncryptorHashOrdKeyType}\n  (tc : ThresholdComposeEncryptor OrdKey EncryptorType Plaintext Ciphertext MapCon EncryptorHashOrdKeyType) :\n  Encryptor EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon) Plaintext Ciphertext\n  :=\n  Encryptor.mkEncryptor@{\n    encrypt := ThresholdComposeEncryptor.encrypt tc;\n    encryptorHash := ThresholdComposeEncryptor.encryptorHash tc;\n  };\n</code></pre> <pre><code>axiom encrypt_DUMMY\n  {EncryptorType Plaintext Ciphertext}\n  {MapCon}\n  : (ComposeHashable EncryptorType MapCon) -&gt; Plaintext -&gt; Ciphertext;\n</code></pre> <pre><code>ThresholdComposeEncryptorFunctor\n  {OrdKey EncryptorType Plaintext Ciphertext}\n  {MapCon : Type -&gt; Type}\n  {EncryptorHashOrdKeyType}\n  (encryptor : Encryptor OrdKey EncryptorType Plaintext Ciphertext)\n  (mapIn : OrdMap OrdKey MapCon)\n  (thresholdComposeHash : HASH EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon)) :\n  ThresholdComposeEncryptor OrdKey EncryptorType Plaintext Ciphertext MapCon EncryptorHashOrdKeyType\n  := ThresholdComposeEncryptor.mkThresholdComposeEncryptor@{\n    map := mapIn;\n    underlyingEncryptor := encryptor;\n    encryptorHash := thresholdComposeHash;\n    compose := \\{\n      t w :=\n        ComposeHashable.mkComposeHashable@{\n          threshold := t;\n          weights :=\n            foldl\n              \\{m (mkPair w e) :=\n                OrdMap.insert map (mkPair m (mkPair (HASH.hash (Encryptor.encryptorHash underlyingEncryptor) e) (mkPair w e)))\n              }\n              (OrdMap.empty map) w\n        }\n    };\n    encrypt := encrypt_DUMMY;\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-threshold-composition","title":"<code>readsFor</code> Threshold Composition","text":"<p>Like any identity, ThresholdCompositionIdentities can have arbitrary  <code>readsFor</code> relationships. However, some cases should always hold : A <code>readsFor</code> B if every  identity in A has no more weight (divided by threshold) than  identities it <code>readsFor</code> in B. This implies that any collection of identities that can read messages  encrypted with A can also read messages encrypted as B.</p> <p>A <code>readsFor</code> relation for easy comparison of   <code>ThresholdComposeEncryptor</code> <code>EncryptorType</code>s  x <code>readsFor</code> y if every underlying <code>EncryptorType</code> in x has no more   weight (divided by threshold) as encryptors it <code>readsFor</code> in y. This implies that anything which can decrypt as x can also decrypt  as y.</p> <p>This requires an underlying <code>R : ReadsFor</code> for comparing the weighted  encryptors in  x and y, which in turn may require evidence. No additional evidence is required.</p> <pre><code>type ThresholdComposeReadsFor\n  ( OrdKey EncryptorType Plaintext Ciphertext Evidence : Type )\n  ( MapCon : Type -&gt; Type )\n  ( EncryptorHashOrdKeyType : Type )\n  :=\n  mkThresholdComposeReadsFor@{\n    underlyingReadsFor : ReadsFor OrdKey EncryptorType Plaintext Ciphertext Evidence;\n    encryptor : ThresholdComposeEncryptor OrdKey EncryptorType Plaintext Ciphertext MapCon EncryptorHashOrdKeyType;\n    readsFor : Evidence -&gt; Pair (ComposeHashable EncryptorType MapCon) (ComposeHashable EncryptorType MapCon) -&gt; Bool;\n  };\n</code></pre> <pre><code>projectReadsFor\n  { OrdKey VerifierType Signable Commitment Evidence }\n  { MapCon : Type -&gt; Type }\n  { EncryptorHashOrdKeyType : Type }\n  ( tc : ThresholdComposeReadsFor\n          OrdKey\n          VerifierType\n          Signable\n          Commitment\n          Evidence\n          MapCon\n          EncryptorHashOrdKeyType ) :\n    ReadsFor\n    EncryptorHashOrdKeyType\n    (ComposeHashable VerifierType MapCon)\n    Signable\n    Commitment\n    Evidence\n  := ReadsFor.mkReadsFor@{\n    encryptor := projectEncryptor (ThresholdComposeReadsFor.encryptor tc);\n    readsFor := ThresholdComposeReadsFor.readsFor tc;\n  };\n</code></pre> <pre><code>ThresholdComposeReadsForFunctor\n  { OrdKey EncryptorType Plaintext Ciphertext Evidence}\n  { MapCon : Type -&gt; Type }\n  { EncryptorHashOrdKeyType}\n  ( r : ReadsFor OrdKey EncryptorType Plaintext Ciphertext Evidence )\n  ( map : OrdMap OrdKey MapCon )\n  ( thresholdComposeHash : HASH EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon) ) :\n  ThresholdComposeReadsFor OrdKey EncryptorType Plaintext Ciphertext Evidence MapCon EncryptorHashOrdKeyType\n  :=\n  ThresholdComposeReadsFor.mkThresholdComposeReadsFor@{\n    underlyingReadsFor := r;\n    encryptor := ThresholdComposeEncryptorFunctor (ReadsFor.encryptor underlyingReadsFor) map thresholdComposeHash;\n    readsFor := \\{\n      e (mkPair (ComposeHashable.mkComposeHashable t0 w0) (ComposeHashable.mkComposeHashable t1 w1)) :=\n        OrdMap.all map\n          \\{ (mkPair w v) :=\n              (w * t1) &lt;=\n              ((OrdMap.foldl map\n                \\{ (mkPair (mkPair x v1) s) :=\n                    if | (ReadsFor.readsFor underlyingReadsFor e (mkPair v v1)) := x + s\n                       | else := s\n                }\n                0 w1\n              ) * t0)\n          }\n          w0\n    };\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#and-identities","title":"\"And\" Identities","text":"<p>We can compose identities with conjunction: A <code>&amp;&amp;</code> B is the identity which requires an agent to have both A's internal identity and B's internal identity to sign or decrypt. It represents A and B working together. In practice, A <code>&amp;&amp;</code> B can be defined as a special case of Threshold composition (see <code>verifierAnd</code> above).</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#or-identities","title":"\"Or\" Identities","text":"<p>We can compose identities with disjunction as well: A <code>||</code> B requires an agent to have either A's internal identity or B's internal identity. It represents either A or B, without specifying which. In practice, A <code>||</code> B can be defined as a special case of Threshold Composition (see <code>verifierOr</code> above).</p> <p>In principle, we could define things differently: Threshold Composition could be defined using <code>&amp;&amp;</code> and <code>||</code> as primitives, by building a disjunction of every possible conjunction that satisfies the threshold. In several important cases, however, this takes much more space to express, so we use the equally general and more numerically efficient threshold composition abstraction.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#opaque-composition","title":"Opaque Composition","text":"<p>A group of agents can also compose an opaque identity such that composition information is not available to the outside. One example would be using distributed key generation and a threshold cryptosystem e.g. Threshold RSA. Here the agents compute one RSA keypair together, with only shares of the private key being generated by each agent. Decryption of messages encrypted to the single public key then requires cooperation of a subset of agents holding key shares, fulfilling the threshold requirements. This group would have a single External Identity based on a regular RSA public key, and it would not necessarily be clear how the identity was composed.</p> <p>Specific evidence could prove that this threshold cryptosystem identity is <code>equivalent</code> to some  <code>ThresholdCompose</code> identity. This kind of proof requires <code>readsFor</code> and <code>signsFor</code> relations tailored to the cryptosystem used. Once equivalence is proven, however, one could use the threshold  cryptosystem identity for efficiency, but reason using the  <code>ThresholdCompose</code> identity.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#special-identities","title":"Special identities","text":"<p>The following special identities illustrate the generality of our identity abstractions:</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#true-all","title":"\"true / All\"","text":"<p>Anyone can sign and decrypt (<code>verify</code> returns true and <code>encrypt</code> returns the <code>Plaintext</code>). No secret knowledge is required, so all agents can take on this identity.</p> <p>The true identity preserves structure under conjunction (x <code>&amp;&amp;</code> true <code>equivalent</code> x) and forgets structure under disjunction (x <code>||</code> true <code>equivalent</code> true).</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#false-none","title":"\"false / None\"","text":"<p>No one can sign or decrypt (<code>verify</code> returns false and <code>encrypt</code>  returns empty string). No secret knowledge exists that fulfills these  requirements, so no agent can take on this identity.</p> <p>The false identity forgets structure under disjunction  (x <code>&amp;&amp;</code> false <code>equivalent</code> false) and preserves structure under  disjunction (x <code>||</code> false <code>equivalent</code> x).</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-names","title":"Identity Names","text":"<p>Sometimes it is useful to have a name for an external identity before the relevant cryptographic values are available. For example, we might refer to \"a quorum of validators from chain <code>X</code> at epoch <code>Y</code>\". Before epoch <code>Y</code> has begun, chain <code>X</code> may not have yet decided who constitutes a quorum.</p> <p>It would be possible to build a <code>Verifier</code>, where the evidence that the signers are in fact a quorum of validators from chain <code>X</code> at epoch <code>Y</code> is part of the signature. One might later build a simpler <code>Verifier</code>, which elides this evidence, and then prove that the two <code>signsSameAs</code> using the evidence. However, barring some really exciting cryptography, we'd need to know the quorums from chain <code>X</code> at epoch <code>Y</code> before we could make an <code>Encryptor</code>.</p> <p>We therefore introduce a new type, Identity Name, which represents a placeholder to be filled in when an appropriate external identity can be found. Specifically, each type of identity name comes with a predicate, which can be satisfied by an external identity, and accompanying evidence. Identity names can also be hashed, like external identities.</p> <p>Identity names can be described in two structures: one for checking that  a <code>VerifierType</code> corresponds with an <code>IdentityName</code>, and one for checking  that an <code>EncryptorType</code> corresponds with an <code>IdentityName</code>. The same name can refer to both a <code>VerifierType</code> and an <code>EncryptorType</code>.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#verifier-name-juvix-type","title":"Verifier Name Juvix Type","text":"<p>An <code>IdentityName</code> can be mapped to an appropriate <code>VerifierType</code>  when suitable <code>Evidence</code> is found. Here, <code>checkVerifierName</code> defines what evidence is acceptable for a  <code>VerifierType</code>.</p> <p>Note that <code>IdentityName</code>s are also hashable: we require a structure  <code>verifierNameHash</code> that details how to hash them.</p> <pre><code>type VerifierName\n  (OrdKey VerifierType Signable Commitment Evidence IdentityName VerifierNameHashOrdKeyType) :=\n  mkVerifierName {\n    verifier : Verifier OrdKey VerifierType Signable Commitment;\n    checkVerifierName : IdentityName -&gt; VerifierType -&gt; Evidence -&gt; Bool;\n    verifierNameHash : HASH VerifierNameHashOrdKeyType IdentityName\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#encryptor-name-juvix-type","title":"Encryptor Name Juvix Type","text":"<p>An <code>IdentityName</code> can be mapped to an appropriate Encryptor <code>EncryptorType</code>  when suitable <code>Evidence</code> is found. Here, <code>checkEncryptorName</code> defines what evidence is acceptable for an  <code>Encryptor</code> <code>EncryptorType</code>. Note that <code>IdentityName</code>s are also hashable: we require a structure  <code>encryptorNameHash</code> that details how to hash them.</p> <pre><code>type EncryptorName\n  (OrdKey EncryptorType Plaintext Ciphertext Evidence IdentityName EncryptorNameHashOrdKeyType) :=\n  mkEncryptorName {\n    verifier : Encryptor OrdKey EncryptorType Plaintext Ciphertext;\n    checkEncryptorName : IdentityName -&gt; EncryptorType -&gt; Evidence -&gt; Bool;\n    encryptorNameHash : HASH EncryptorNameHashOrdKeyType IdentityName\n  };\n</code></pre> <p>For example, for the identity name \"a quorum of validators from chain <code>X</code> at epoch <code>Y</code>\", a satisfying external identity would be composed from the validators selected for epoch <code>Y</code>, and the accompanying evidence would be a light-client proof from chain <code>X</code> that these are the correct validators for epoch <code>Y</code>.</p> <p>Note that multiple identity names can refer to the same external identity, and in principle, multiple external identities could have the same identity name. Usually, multiple external identities only have the same identity name when there is Byzantine behaviour, but that is not explicitly part of the identity abstractions at this layer.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#sub-identities","title":"Sub-Identities","text":"<p>One particularly common case for identity names is when one party (the super-identity) wants to designate a specific name they use to refer to another identity. Here, the super-identity is acting like a certificate authority: they designate which external identity corresponds with this identity name. This sub-identity is often something the super-identity controls: a specific machine they own, or a process they run on that machine. Such a sub-identity might be associated with a string, such as <code>\"acceptor\"</code>, which might designate the process participating in consensus within a validator. In this case, the predicate should check that the super-identity has signed a statement declaring that the external identity matches the sub-identity.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#notation","title":"\".\" Notation","text":"<p>Because sub-identities using string names are so common, we have a short-cut notation for expressing identity names. Given some identity Alice, for any string <code>\"foo\"</code>, Alice.foo is an identity name. For example, even before they learn anything about Alice, validators might refer to Alice.acceptor to mean the specific process Alice is running to participate in consensus. The identity Alice can sign statements to let people know what external identity they should (immutably) use for Alice.foo or Alice.acceptor. These are left associative, so Alice.foo can designate Alice.foo.bar (shorthand for (Alice.foo).bar) and Alice.foo.bar can designate Alice.foo.bar.baz (shorthand for ((Alice.foo).bar).baz), and so on. These are a special case of sub-identities: X.Y is a sub-identity of X.</p> <p>Formally, we use <code>mkPair (hash Alice) \"foo\"</code> as the Juvix representation of Alice.foo:</p> <p>A specific kind of identity name, wher ethe evidence is a signed  statement from a specified parent saying that it associates this  VerifierType with a specific <code>name</code>.</p> <p>Here,</p> <ul> <li><code>Name</code> is the type the parent identifies with a child.   For example, for <code>name = string</code>, and some identity Alice, we can specify   <code>(hash(Alice),\"bob\")</code>, or Alice.bob, as the identity that   Alice refers to as <code>\"bob\"</code>.</li> </ul> <ul> <li><code>child</code> : <code>Verifier</code> type that can be identified with a name.</li> </ul> <ul> <li> <p><code>parent</code> : <code>Verifier</code> type that signs evidence statements.</p> <p>Crucially, it must be able to sign tuples of the form (string, name, child's hash type) In our example, where Alice refers to Bob as Alice.<code>\"bob\"</code>, <code>child</code> describes Bob, <code>parent</code> describes Alice, and <code>name</code> describes <code>\"bob\"</code>.</p> </li> </ul> <ul> <li><code>hash</code> Describes what will become the <code>verifierNameHash</code>.   Crucially, it must be able to hash pairs of the form   (parent's hash type, name)</li> </ul> <pre><code>SubVerifierFunctor\n  (OrdKey VerifierType Signable Commitment Name ParentOrdKeyType : Type)\n  (child : Verifier OrdKey VerifierType Signable Commitment)\n  (parent : Verifier ParentOrdKeyType VerifierType (Pair String (Pair Name OrdKey)) Commitment)\n  (hash : HASH ParentOrdKeyType (Pair ParentOrdKeyType Name)) :\n  VerifierName OrdKey VerifierType Signable Commitment (Pair VerifierType Commitment) (Pair ParentOrdKeyType Name) ParentOrdKeyType :=\n  VerifierName.mkVerifierName@{\n    verifier := child;\n    checkVerifierName := \\{\n      (mkPair ph n) c (mkPair pv pc) :=\n        (Verifier.verify parent pv (mkPair \"I identify this verifier with this name : \" (mkPair n (HASH.hash (Verifier.verifierHash child) c))) pc) &amp;&amp;\n        ((OrdKey.compare (HASH.ordKey (Verifier.verifierHash parent)) ph (HASH.hash (Verifier.verifierHash parent) pv)) == Equal)\n    };\n    verifierNameHash := hash;\n  }\n</code></pre> <p>In other words, we have a specific, standardized thing an external identity can sign to designate that another external identity corresponds to a \".\" name.</p> <p>Note that we can use \".\" sub-identities for purposes other than identifying identities that the super-identity controls. Alice might have a friend Bob, and designate his external identity as Alice.bob. This is an example of a place where \"sub-identity-ness\" is not transitive: Alice.bob.carol is (Alice.bob).carol, a sub-identity of Alice.bob, so it is up to Bob to designate which external identity he associates with <code>\"carol\"</code>, and Alice has no say: Alice.bob.carol is not a sub-identity of Alice.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-engine","title":"Identity Engine","text":"<p>In practice, using Identity Names requires each physical machine to maintain a mapping from identity names to known external identities. The machine does not have to store the accompanying evidence for each, although it might be useful to do so sometimes (for example, in order to present to a third party). When any process on that machine wants to do any operation using an identity name instead of an external identity, it can query this mapping to see if there is a known external identity to use for that operation.</p> <p>An Identity Engine can also store evidence for known <code>signsFor</code> and <code>readsFor</code> relationships, and help choose which external identity is most efficient for a task. For example, if an agent wants to encrypt a message to \"a quorum of validators from chain <code>X</code> at epoch <code>Y</code>\", they would first resolving the identity name to an identity (possibly a Threshold Composed Identity), and might then ask if there is some known equivalent identity (such as a threshold encryption identity) with cheaper encryption.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-name-resolution","title":"Identity Name Resolution","text":"<p>There is no general mechanism for finding external identities (and accompanying evidence) for arbitrary identity names, with arbitrary forms of evidence. However, for some common types of identity names, such as \".\" sub-identities, we can establish a standard server and query language, which participating Identity Engines can query to resolve those identity names.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/state/resource_machine/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.index;\n</code></pre>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#introduction","title":"Introduction","text":"<p>The Anoma Resource Machine (ARM) is the part of the Anoma protocol that defines and enforces the rules for valid state updates that satisfy users' preferences. The new proposed state is then agreed on by the consensus participants. In that sense the role of the Anoma Resource Machine in the Anoma protocol is similar to the role of the Ethereum Virtual Machine in the Ethereum protocol.</p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#data-structures","title":"Data structures","text":"<p>The atomic unit of the ARM state is called a resource. Resources are immutable, they can be created once and consumed once. The system state is represented by the set of active resources: the resources that were created but not nullified.</p> <p>Transactions produced by the ARM represent the proposed state update. They consist of actions, which group resources with the same execution context.</p> <p>Ensuring the correctness of the transaction is achieved with the help of non-interactive proofs attached to it:</p> <ol> <li>to prove the transaction is balanced correctly, there are delta proofs. Balance is the criterion of a transaction's completeness.</li> <li>to prove the transaction complies with the ARM rules, there are compliance proofs. Actions are partitioned into compliance units that define the compliance proof scope.</li> <li>to prove the transaction satisfies the user constraints, there are resource logic proofs.</li> </ol> <p></p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#common-flavours-of-arms","title":"Common flavours of ARMs","text":"<p>A resource machine instantiation is called shielded if it achieves both data and function privacy. Any other resource machine is considered transparent from the privacy perspective.</p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#the-role-of-the-arm","title":"The role of the ARM","text":"<p>The ARM is used to create, compose, and verify transactions. It is stateless and run by every node that processes transactions. Anoma users submit their intents to the intent gossip network in the form of unbalanced ARM transactions with metadata, which are received and processed by solvers that output balanced ARM transactions. These transactions are then ordered and finally sent to the executor node, that verifies and executes the transactions in the determined order, updating the global state.</p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#the-specification","title":"The specification","text":"<p>This specification describes a common interface shared by all ARM instantiations. Depending on the primitive instantiation choices, the resulting ARM instantiation will have different properties. For example, using zk-SNARKs to create and verify the ARM proofs might result in a succinct or even shielded ARM instantiation. The ARM interface is designed to provide interoperability between different ARM instantiations.</p> <p>The design of the Anoma Resource Machine was significantly inspired by the Zcash protocol.</p> <ul> <li>Keywords: anoma, blockchain technology, protocol design, resource machine</li> </ul>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/data_structures/action/index.html","title":"Action","text":"<p>icon: material/file-document-outline search:   exclude: false   boost: 2</p> <pre><code>module arch.system.state.resource_machine.data_structures.action.index;\n</code></pre>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#action","title":"Action","text":"<p>An action is a composite structure of type <code>Action</code> that contains the following components:</p> Component Type Description <code>logicVerifierInputs</code> <code>Map Tag LogicVerifierInputs</code> For each resource tag, contains the associated logic proof and everything required to verify it. The structure of <code>LogicVerifierInputs</code> is further described below. <code>complianceUnits</code> <code>List ComplianceUnit</code> The set of transaction's compliance units <code>actionTreeSize</code> Determines the depth of the Merkle tree used to store input resources. If not specified, the depth is set to the smallest necessary to fit all the input resources."},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#logicverifierinputs","title":"<code>LogicVerifierInputs</code>","text":"Name Type Description <code>verifyingKey</code> <code>ResourceLogicProvingSystem.verifyingKey</code> Contains the verifying key used to verify the logic proof <code>applicationData</code> <code>(ResourcePayload, DiscoveryPayload, ExternalPayload, ApplicationPayload)</code> Contains inputs required to verify the RL proof. Each payload type is <code>List(BitString, DeletionCriterion)</code>. The tuple entries are further described below. The deletion criterion field is further described here. <code>proof</code> <code>ResourceLogicProvingSystem.Proof</code>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#applicationdata","title":"<code>applicationData</code>","text":"<p>Application data contains the inputs required to verify the RL proof. It has four entries, all of which of type <code>List (BitString, DeletionCriterion)</code>:</p> <ol> <li><code>ResourcePayload</code> \u2013 contains resource-object-related data. For example, encrypted (or not) resource object.</li> <li><code>DiscoveryPayload</code> \u2013 contains data related to discovery, for example, FMD ciphertext.</li> <li><code>ExternalPayload</code> \u2013 contains data associated with external calls, for example, <code>forwarderCallData</code> from Ethereum.</li> <li><code>ApplicationPayload</code> \u2013 contains other data expected by the resource logic, for example, a signature to be verified.</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#definitions","title":"Definitions","text":"<p>Actions partition the state change induced by a transaction and limit the evaluation context of resource logics: proofs created in the context of an action have access only to the resources associated with the action. A resource is said to be associated with an action if its tag is a key of the <code>logicVerifierInputs</code> map. A resource is associated with at most two actions: resource creation is associated with exactly one action and resource consumption is associated with exactly one action. A resource is said to be consumed in the action for a valid action if its nullifier is a key of the <code>logicVerifierInputs</code> map. A resource is said to be created in the action for a valid action if its commitment is a key of the <code>logicVerifierInputs</code> map.</p> <p>Note</p> <p>Unlike transactions, actions don't need to be balanced, but if an action is valid and balanced, it is sufficient to create a balanced transaction.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#interface","title":"Interface","text":"<ol> <li><code>create(List (NullifierKey, Resource, deltaExtraInput, CMtreePath, CMTreeRoot, List (BitString, DeletionCriterion)), List (Resource, deltaExtraInput, List (BitString, DeletionCriterion)), appWitness: BitString) -&gt; Action</code></li> <li><code>verify(Action) -&gt; Bool</code></li> <li><code>delta(Action) -&gt; DeltaHash</code></li> <li><code>to_instance(Action, Tag) -&gt; Maybe ResourceLogicProvingSystem.Instance</code></li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#proofs","title":"Proofs","text":"<p>For each resource consumed or created in the action, it is required to provide a proof that the logic associated with that resource evaluates to <code>True</code> given the input parameters that describe the state transition induced by the action. The number of such proofs in an action equals to the amount of resources (both created and consumed) in that action, even if some resources have the same logics. Resource logic proofs are further described here.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#create","title":"<code>create</code>","text":"<ol> <li><code>complianceUnits</code>: Partition the resources into compliance units and compute a compliance proof for each unit</li> <li><code>logicVerifierInputs</code>: For each resource, compute a resource logic proof and associate each proof with the tag of the resource and other components that are required to verify it.</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#verify","title":"<code>verify</code>","text":"<p>Validity of an action can only be determined for actions that are associated with a transaction. Assuming that an action is associated with a transaction, an action is considered valid if all of the following conditions hold:</p> <ol> <li>All resource logic proofs associated with the action are valid</li> <li>All compliance proofs associated with the action are valid: <code>cu.verify() = True for cu in complianceUnits</code></li> <li><code>logicVerifierInputs</code> keys = the list of tags associated with <code>complianceUnits</code> (ignoring the order)</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#delta","title":"<code>delta</code>","text":"<p><code>action.delta()</code> computes the action delta. Action delta is computed from <code>r.delta()</code> of the resources that comprise the action and defined as <code>action.delta() = sum(cu.delta() for cu in action.complianceUnits)</code>.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#to_instance","title":"<code>to_instance</code>","text":"<p>This function assembles the instance required to verify a resource logic proof from the data in the action.</p> <p>The main task is to assemble the <code>consumed</code> and <code>created</code> lists of resources. The proposed mechanism works as follows: 1. Iterate over all compliance units and accumulate the lists of created and consumed resources. The resulting list of consumed resources contains all consumed resources in the action. The resulting list of created resources contains all created resources in the action. 2. Erase the <code>self</code> resource from the relevant list. If the resource is consumed and its nullifier is stored under index <code>n</code> in the list of consumed resources, the resulting list is <code>l[0], l[1], ..., l[n - 1], l[n + 1], ...</code>. Keep the list of created resources the same. 3. If <code>self</code> is created, erase the resource from the list of created resources as in step 2. Keep the list of consumed resources the same. For each resource we assemble an instance for, we erase only one resource - itself - from one list.</p> <p>Note</p> <p>When verifying multiple logic proofs from the same action, it might make sense to create the 'full' lists once and erase resources one at a time to create a particular instance. Note that the next instance must be created from the original <code>full</code> list, not the list with previously erased resources.</p> <p>All other fields of the instance (resource tag, <code>isConsumed</code>, <code>applicationData</code>) are taken from the relevant entry of the <code>logicVerifierInputs</code> map.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html","title":"Resource logic proof","text":"<p>icon: material/file-document-outline search:   exclude: false   boost: 2</p> <pre><code>module arch.system.state.resource_machine.data_structures.action.resource_logic_proof;\n</code></pre>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#resource-logic-proof","title":"Resource logic proof","text":"<p>Resource logic proofs attest to validity of resource logics. A resource logic is a computable predicate associated with a resource (this resource is referred to as <code>self</code> in this context) that constrains the creation and consumption of a resource. Each time a resource is created or consumed, the corresponding resource logic proof is required in order for the action (and thus the transaction) to be valid.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#action-tree","title":"Action tree","text":"<p>When proving, resource logics take as input resources created and consumed in that action.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#instance","title":"Instance","text":"<ol> <li>Resource's commitment/nullifier</li> <li><code>isConsumed</code> - a flag that tells the logic if the resource is consumed or created. Can be inferred from the position of the tag in the corresponding compliance unit.</li> <li><code>actionTreeRoot</code>. Action tree is a Merkle tree that contains commitments and nullifiers of the action resources. The resource logic takes as input the root of the action tree.</li> <li><code>applicationData</code></li> </ol> <p>Including <code>applicationData</code> in the instance requires the following pre-processing:</p> <ol> <li>For each payload type, a new list must be formed by collecting the first entry from each tuple: <code>List (BitString, DeletionCriterion) -&gt; List BitString</code>. Empty payload lists are ignored</li> <li>Merge all resulting lists into a single one</li> <li>Dereference the list and attach the elements to the tail of the instance</li> </ol> <p>The original order of the elements must be preserved at each step.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#witness","title":"Witness","text":"<ol> <li><code>self</code> resource object</li> <li>If <code>isConsumed = True</code>: nullifier key of <code>self</code></li> <li>Resource objects of consumed resources: <code>List (Resource, NullifierKey, ActionTreePath)</code></li> <li>Resource objects of created resources: <code>List (Resource, ActionTreePath)</code></li> <li>Application-specific inputs</li> </ol> <p>Note</p> <p>Instance and witness elements are expected to go in the same order: the first element of the instance corresponds to the first elements of the witness and so on.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#constraints","title":"Constraints","text":"<ol> <li>For created resources: created commitment integrity: <code>r.commitment() = cm</code></li> <li>For consumed resources: <code>r.nullifier(nullifierKey) = nf</code></li> <li>Application-specific constraints</li> </ol> <p>Checks that require access to global <code>CMTree</code> and <code>NullifierSet</code>:</p> <ol> <li>each created resource wasn't created in prior transactions</li> <li>each consumed resource wasn't consumed in prior transactions</li> </ol> <p>Note</p> <p>Actions can be verified as parts of supposedly valid transactions and individually, when building a valid transaction (e.g., in the partial solving case). In case the actions are verified not individually, all global checks can be aggregated and verified at once to reduce the amount of global communication.</p>"},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html","title":"Compliance proof","text":"<pre><code>module arch.system.state.resource_machine.data_structures.compliance_unit.compliance_proof;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#compliance-proof","title":"Compliance proof","text":"<p>Compliance proofs are created by <code>ComplianceProvingSystem</code> and computed over compliance units. Compliance proofs ensure that the provided state transition complies with the resource machine definitions.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#compliance-inputs","title":"Compliance inputs","text":"","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#instance","title":"Instance","text":"Name Type Description <code>consumed</code> <code>List (nf: Nullifier, root: CMTree.Value, logicVKOuter: LogicVKOuterHash)</code> Each entry corresponds to a consumed resource and includes a hash of the resource's <code>logicRef</code> component <code>created</code> <code>List (cm: Commitment, logicVKOuter: LogicVKOuterHash)</code> Each entry corresponds to a created resource <code>unitDelta</code> <code>DeltaHash</code>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#witness","title":"Witness","text":"<ol> <li> <p>for consumed resources:</p> <p>1. resource object <code>r</code></p> <p>2. <code>nullifierKey</code></p> <p>3. <code>CMtree</code> path to the consumed resource commitment</p> <p>4. pre-image of <code>logicVKOuter</code></p> <p>5. <code>deltaExtraInput</code> used to compute resource delta</p> </li> <li> <p>for created resources:</p> <ol> <li> <p>resource object <code>r</code></p> </li> <li> <p>pre-image of <code>logicVKOuter</code></p> </li> <li> <p><code>deltaExtraInput</code> used to compute resource delta</p> </li> </ol> </li> </ol> <p>Note</p> <p>Instance and witness elements are expected to go in the same order: the first element of the instance corresponds to the first (4 for consumed and 2 for created) elements of the witness and so on.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#compliance-constraints","title":"Compliance constraints","text":"<p>Each resource machine compliance proof must check the following:</p> <ol> <li> <p>Merkle path validity: <code>CMTree::Verify(r.commitment(), path, root) = True</code> for each resource associated with a nullifier from the <code>consumed</code>. For ephemeral resources a \"fake\" relation is checked.</p> </li> <li> <p>For each consumed resource <code>r</code>:</p> <ol> <li>Nullifier integrity: <code>r.nullifier(nullifierKey) is in consumed</code></li> <li>Logic integrity: <code>logicVKOuter = logicVKOuterHash(r.logicRef, ...)</code></li> </ol> </li> <li> <p>For each created resource <code>r</code>:</p> <ol> <li>Commitment integrity: <code>r.commitment() is in created</code></li> <li>Logic integrity: <code>logicVKOuter = logicVKOuterHash(r.logicRef, ...)</code></li> </ol> </li> <li> <p>Delta integrity: <code>unitDelta = sum(r.delta(deltaExtraInput(r)) for r in consumed) - sum(r.delta(deltaExtraInput(r)) for r in created)</code> where <code>deltaExtraInput(r)</code> returns <code>deltaExtraInput</code> associated with resource <code>r</code></p> </li> </ol> <p>Note</p> <p>Kind integrity is checked implicitly in delta integrity</p> <p>Note</p> <p>[2.3, 3.2]: Combined with checking the logic proofs, logic integrity checks allow to ensure that the logics associated with the resources are satisfied</p> <p>Note</p> <p>[2.1, 3.1]: To ensure correct binding between the instance and the witness, resource tags have to be recomputed from the witness and compared to what is provided in the instance.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html","title":"Compliance unit","text":"<pre><code>module arch.system.state.resource_machine.data_structures.compliance_unit.compliance_unit;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#compliance-unit","title":"Compliance unit","text":"<p><code>ComplianceUnit</code> is a data structure used to verify compliance proofs. It partitions the action, meaning that:</p> <ol> <li>there might be multiple compliance units for a single action</li> <li>the sets of resource tags validated by any two compliance units don't intersect</li> <li>together the compliance units cover all of the resources in the action</li> </ol> <p>The table below describes the components of a compliance unit:</p> Component Type Description <code>vk</code> <code>ComplianceProvingSystem.VerifyingKey</code> <code>instance</code> <code>ComplianceProvingSystem.Instance</code> The instance required to verify the compliance proof. Includes the tags of the checked resources, compliance unit delta, <code>CMtree</code> roots for consumed resources. <code>proof</code> <code>ComplianceProvingSystem.Proof</code> <p>The number of created and consumed resources in each unit is determined by the resource machine instantiation. The total number of compliance proofs required for an action is determined by the number of compliance units that comprise the action. For example, if the instantiation defines a single compliance proof to include 1 input and 1 output resource, and an action contains 3 input and 2 output resources, the total number of compliance units will be 3 (with a placeholder output resource in the third compliance unit).</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#interface","title":"Interface","text":"<ol> <li><code>create(ComplianceProvingSystem.ProvingKey, ComplianceProvingSystem.VerifyingKey, ComplianceProvingSystem.Instance, ComplianceProvingSystem.Witness) -&gt; ComplianceUnit</code> - computes the compliance unit proof and populates the compliance unit</li> <li><code>created(ComplianceUnit) -&gt; List Commimtent</code> - returns the commitments of the created resources checked in the unit</li> <li><code>consumed(ComplianceUnit) -&gt; List Nullifier</code> - returns the nullifiers of the consumed resources checked in the unit</li> <li><code>verify(ComplianceUnit) -&gt; Bool</code> - returns <code>ComplianceProvingSystem.Verify(vk, instance, proof)</code></li> <li><code>delta(ComplianceUnit) -&gt; DeltaHash</code> - returns the compliance unit delta, which is stored in <code>complianceData</code>: <code>unit.delta() = unit.complianceData.delta</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#create","title":"<code>create</code>","text":"<p>Create is a function that provers use to create a compliance unit.</p> <ol> <li>Compute the compliance proof: <code>ComplianceProvingSystem.Prove(ComplianceProvingSystem.ProvingKey, ComplianceProvingSystem.Instance, ComplianceProvingSystem.Witness) -&gt; ComplianceProvingSystem.Proof</code>. What comprises the instance and witness here is described in Compliance proof.</li> <li>Create the compliance unit given the proof, verifying key, and instance.</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#delta","title":"Delta","text":"<p>Compliance unit delta is used to compute action and transaction deltas and is itself computed from resource deltas: <code>delta = sum(r.delta(deltaExtraInput(r))) for r in outputResources - sum(r.delta(deltaExtraInput(r)) for r in inputResources))</code>. Note that the delta is computed by the prover (who knows the resource objects of resources associated with the unit) and is a part of the instance. The compliance proof must ensure the correct computation of delta from the resource deltas available at the proving time.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#delta-for-computing-balance","title":"Delta for computing balance","text":"<p>From the homomorphic properties of Delta hash, for the resources of the same kind \\(kind\\), adding together the deltas of the resources results in the delta corresponding to the total quantity of that resource kind: \\(\\sum_j{h_\\Delta(kind, q_{r_{i_j}})} - \\sum_j{h_\\Delta(kind, q_{r_{o_j}})} = \\sum_j{\\Delta_{r_{i_j}}} - \\sum_j{\\Delta_{r_{o_j}}} =  h_\\Delta(kind, q_{kind})\\), where \\(q_{kind}\\) is the total quantity of the resources of kind \\(kind\\).</p> <p>The kind-distinctness property of \\(h_\\Delta\\) allows computing \\(\\Delta = \\sum_j{\\Delta_{r_{i_j}}} - \\sum_j{\\Delta_{r_{o_j}}}\\) adding resources of all kinds together without the need to account for distinct resource kinds explicitly: \\(\\sum_j{\\Delta_{r_{i_j}}} - \\sum_j{\\Delta_{r_{o_j}}} = \\sum_j{h_\\Delta(kind_j, q_{kind_j})}\\).</p> <p>Note</p> <p>The delta extra inputs omitted in the formulae above are added/subtracted accordingly.</p> <p>As a result, the properties of <code>DeltaHash</code> allow computing the total balance for a compliance unit, action, or transaction, without having direct access to quantities and kinds of the resources that comprise the data structure.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#verify","title":"<code>verify</code>","text":"<ol> <li><code>ComplianceProvingSystem.Verify(vk, instance, proof) = True</code></li> <li>Global check: <code>CMTree</code> roots used to verify the proof are valid <code>CMTree</code> roots</li> </ol> <p>Note</p> <p>Compliance units can be verified as parts of supposedly valid transactions and individually, when building a valid transaction (e.g., in the partial solving case). In case the compliance units are verified not individually, all global checks can be aggregated and verified at once to reduce the amount of global communication.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.index;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/index.html#resource","title":"Resource","text":"<p>A resource is a composite structure <code>Resource</code> that contains the following components:</p> Component Type Description <code>logicRef</code> <code>LogicVKCompact</code> Resource logic's verifying key <code>labelRef</code> <code>LabelHash</code> Hash of the resource label. Resource label specifies the fungibility domain for the resource. Resources within the same fungibility domain are seen as equivalent kinds of different quantities. Resources from different fungibility domains are seen and treated as non-equivalent kinds. This distinction comes into play in the balance check described later <code>valueRef</code> <code>ValueHash</code> Hash of the resource value. Resource value is the fungible data associated with the resource. It contains extra information but does not affect the resource's fungibility <code>quantity</code> <code>Quantity</code> is a number representing the quantity of the resource <code>isEphemeral</code> <code>Bool</code> is a flag that reflects the resource's ephemerality. Ephemeral resources do not get checked for existence when being consumed <code>nonce</code> <code>Nonce</code> guarantees the uniqueness of the resource computable components <code>nullifierKeyCommitment</code> <code>NullifierKeyCommitment</code> is a nullifier key commitment. Corresponds to the nullifier key \\(nk\\) used to derive the resource nullifier (nullifiers are further described here) <code>randSeed</code> <code>RandSeed</code> randomness seed used to derive whatever randomness needed <p>To distinguish between the resource data structure consisting of the resource components and a resource as a unit of state identified by just one (or some) of the resource computed fields, we sometimes refer to the former as a resource object. Data which is referenced by the resource object - such as the preimage of <code>valueRef</code> - we refer to as resource-linked data.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/delta.html","title":"Delta","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.delta;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/delta.html#resource-delta","title":"Resource Delta","text":"<p>Resource delta is used to reason about the total quantities of different kinds of resources in transactions. For a resource <code>r</code>, its delta is computed as <code>r.delta(deltaExtraInput) = deltaHash(r.kind(), r.quantity, deltaExtraInput)</code>. <code>deltaExtraInput</code> contains the extra data required to derive resource delta, e.g., randomness. It may be empty if no extra data is required.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/delta.html#delta-for-data-structures","title":"Delta for data structures","text":"<p>Delta is a computable component that can be computed for compliance units, actions, and transactions from resource deltas of the resources comprising the data structures.</p> <p>Note that transactions are partitioned into actions, actions are partitioned into compliance units, and compliance units are partitioned into resources. For that reason, the mechanism for computation of the deltas of these data structures is almost the same.</p> <ol> <li>For compliance units, delta is computed by using signed addition over the deltas of the resources that comprise the unit: <code>unit.delta() = sum(r.delta(deltaExtraInput(r))) for r in outputResources - sum(r.delta(deltaExtraInput(r)) for r in inputResources))</code></li> <li>For actions, delta is computed by adding the deltas of the compliance units that comprise the action: <code>action.delta() = sum(unit.delta() for unit in action)</code>. To make sure the action's delta is computed correctly, validate the compliance unit delta and make sure the action's deltas are computed using compliance unit deltas values.</li> <li>For transactions, delta is computed by adding the deltas of the actions that comprise the transaction: <code>transaction.delta() = sum(action.delta() for unit in transaction)</code>. To make sure transaction's delta is computed correctly, make sure it is computed using the validated action deltas.</li> </ol> <p>Note</p> <p>For every data structure, the delta can also be computed directly from resource deltas that comprise it, the way it is done for compliance units.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/introduction.html","title":"Introduction","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.introduction;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/introduction.html#computable-components","title":"Computable components","text":"<p>Resource computable components are the components that are not a resource component but can be derived from the resource components, other computable components, and possibly some extra data.</p> <p>Resources have four computable components:</p> <ol> <li>Resource Commitment</li> <li>Nullifier</li> <li>Kind</li> <li>Delta</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/introduction.html#tag","title":"Tag","text":"<p>The resource tag is used to identify a resource when checking constraints without referring to the resource's plaintext directly: <code>tag(Resource, Bool) -&gt; Commitment or Nullifier</code>.</p> <p>For created resources: <code>r.tag(consumed=False) = r.commitment()</code>; for consumed resources: <code>r.tag(consumed=True) = r.nullifier(nullifierKey)</code></p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/kind.html","title":"Kind","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.kind;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/kind.html#kind","title":"Kind","text":"<p>For a resource <code>r</code>, its kind is computed as: <code>r.kind() = kindHash(r.labelRef, r.logicRef)</code>.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/nullifier.html","title":"Nullifier","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.nullifier;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/nullifier.html#nullifier","title":"Nullifier","text":"<p>A resource nullifier is a computed field, the publishing of which marks the resource associated with the nullifier as consumed.</p> <p>For a resource <code>r</code>, <code>r.nullifier(nullifierKey) = nullifierHash(nullifierKey, r)</code>, where <code>nullifierKey</code> is a key provided externally.</p> <p>A resource can be consumed only once. Nullifiers of consumed resources are stored in a public append-only structure called the resource nullifier set. This structure is external to the resource machine, but the resource machine can read from it and append to it.</p> <p>Note</p> <p>Every time a resource is consumed, it has to be checked that the resource existed before (the resource's commitment is in the commitment tree) and has not been consumed yet (the resource's nullifier is not in the nullifier set).</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/resource_commitment.html","title":"Commitment","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.resource_commitment;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/resource_commitment.html#resource-commitment","title":"Resource Commitment","text":"<p>Resource commitment is a unique identifier of a resource used to prove the resource's existence and address the resource. Using resource commitment allows to decouple resource semantics (contained in the resource object) and the fact of the resource's existence. For a resource <code>r</code>, <code>r.commitment() = commitmentHash(r)</code>.</p> <p>To establish the resource's existence, its commitment is added to a global structure called a commitment tree. This structure is external to the resource machine but the resource machine can read from it.</p> <p>Note</p> <p>The resource commitment is also used as the resource's address \\(r.addr\\) in the content-addressed storage.</p> <p>Note</p> <p>Consumption of the resource does not necessarily affect the resource's status in the storage (e.g., it doesn't get deleted).</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html","title":"Delta proof","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.delta_proof;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#delta-proof","title":"Delta proof","text":"","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#instance","title":"Instance","text":"Name Type Description <code>delta</code> <code>DeltaHash</code> Transaction delta (computed from compliance unit deltas by adding them together) <code>expectedBalance</code> <code>Balance</code> Balanced transactions have delta pre-image 0 for all involved kinds, for unbalanced transactions <code>expectedBalance</code> is a non-zero value","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#witness","title":"Witness","text":"<ol> <li>Resource delta pre-images</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#constraints","title":"Constraints","text":"<ol> <li><code>delta = sum(unit.delta() for unit in action.units for action in tx)</code> - can be checked outside of the circuit since all values are public</li> <li><code>delta</code>'s preimage's quantity component is <code>expectedBalance</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html","title":"Transaction","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.transaction;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#transaction","title":"Transaction","text":"<p>A transaction is a necessary and sufficient collection of fields required to validate and apply a state update to the state. It is a composite structure that contains the following components:</p> Component Type Description <code>actions</code> <code>Set Action</code> A set of actions that comprise the transaction <code>deltaProof</code> <code>DeltaProvingSystem.Proof</code> Balance proof. It makes sure that <code>transactionDelta</code> is correctly derived from the actions' deltas and commits to the expected publicly known value, called a balancing value. There is just one delta proof per transaction <code>delta_vk</code> <code>DeltaProvingSystem.VerifyingKey</code> Used to verify the delta proof. Might be optional in case the key is computable from other components <code>expectedBalance</code> Balanced transactions have delta pre-image 0 for all involved kinds, for unbalanced transactions <code>expectedBalance</code> is a non-zero value.","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#interface","title":"Interface","text":"<ol> <li><code>create(Set Actions, DeltaProvingSystem.ProvingKey, DeltaProvingSystem.Instance, DeltaProvingSystem.Witness) -&gt; Transaction</code></li> <li><code>compose(Transaction, Transaction) -&gt; Transaction</code></li> <li><code>verify(Transaction) -&gt; Bool</code></li> <li><code>delta(Transaction) -&gt; DeltaHash</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#create","title":"<code>create</code>","text":"<p>Given a set of actions alongside delta data, a transaction is formed as follows:</p> <ol> <li><code>tx.actions = actions</code></li> <li><code>tx.deltaProof = DeltaProvingSystem.Prove(DeltaProvingSystem.ProvingKey, DeltaProvingSystem.Instance, DeltaProvingSystem.Witness)</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#compose","title":"<code>compose</code>","text":"<p>Having two transactions <code>tx1</code> and <code>tx2</code>, their composition <code>compose(tx1, tx2)</code> is defined as a transaction <code>tx</code>, where:</p> <ol> <li><code>tx.actions = Set.union(tx1.actions, tx2.actions)</code></li> <li><code>tx.deltaProof, tx.delta_vk = DeltaProvingSystem.aggregate(tx1.deltaProof, tx1.delta_vk, tx2.deltaProof, tx2.delta_vk)</code></li> </ol> <p>Note</p> <p>When composing transactions, action sets are simply united. For example, composing a transaction with two actions and another transaction with three actions will result in a transaction with five actions, given all actions are distinct.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#verify","title":"<code>verify</code>","text":"<p>A transaction is considered valid if the following statements hold:</p> <p>Checks that do not require access to global structures:</p> <ol> <li>all actions in the transaction are valid, as defined per action validity rules</li> <li>actions partition the state change induced by the transaction:<ol> <li>there is no resource created more than once across actions</li> <li>there is no resource consumed more than once across actions</li> </ol> </li> <li><code>deltaProof</code> is valid</li> </ol> <p>A transaction is executable if it is valid and <code>transactionDelta</code> commits to the expected balancing value.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#delta","title":"<code>delta</code>","text":"<p>Transaction delta is a hash of transaction balance - the total quantity change per resource kind induced by the transaction. It isn't computed from the transaction balance directly by applying a hash function to it, but rather by using the homomoprhic properties of <code>deltaHash</code>: adding action deltas together results in transaction delta.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_function.html","title":"Transaction Function","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.transaction_function;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_function.html#transaction-function","title":"Transaction Function","text":"<p>A transaction function <code>TransactionFunction</code> is a function that outputs a transaction: <code>transactionFunction() -&gt; Transaction</code>.</p> <p>Transaction functions take no input but can perform I/O operations to read information about global state either by reading data at the specified global storage address or by fetching data by index. The requirements for transaction functions are further described in Transaction function format.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html","title":"Transaction With Payment","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.transaction_with_payment;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html#transaction-with-payment","title":"Transaction With Payment","text":"<p><code>TransactionWithPayment</code> is a data structure that allows paying for the desired state transitions.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html#definition","title":"Definition","text":"<p><code>TransactionWithPayment</code> contains the following fields:</p> Type <code>stateTransitionFunction</code> <code>TransactionFunction</code> The desired state update. <code>paymentTransaction</code> <code>Transaction</code> The payment transaction. It is unbalanced, contains consumed resources (gas payment sent) but not created (the receiver is not specified). Includes in a special application data field the hash of the transaction function and the gas limit. <code>gasLimit</code> <code>Arithmetic</code> The maximum amount of gas that can be used for execution of the <code>StateTransition</code>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html#execution","title":"Execution","text":"<p>When executing a <code>TransactionFunctionWithPayment</code>, the executor takes the following steps:</p> <ol> <li>Checks that <code>paymentTransaction</code> is \u201csimple\u201d. What exactly this means can be executor-specific, but roughly \u201csimple\u201d means \u201cinexpensive to verify\u201d. A basic (very restrictive) check could be that the payment transaction has exactly one consumed resource and nothing else.</li> <li>Decide whether this gas payment is sufficient. This decision can be controller-specific (maybe there are certain assets and certain prices accepted for gas).</li> <li>Alter <code>paymentTransaction</code>, adding new resources assigned to the executor (or whoever is supposed to receive the gas payments) as necessary to make the payment transaction balanced.</li> <li>Verify <code>paymentTransaction</code>, including in a special application data field the hash of the transaction function and the gas limit.</li> <li>Execute <code>paymentTransaction</code> (apply the state changes).</li> <li>Evaluate <code>stateTransitionFunction</code>, limited by <code>gasLimit</code>.</li> <li>If <code>stateTransitionFunction</code> evaluation finishes within <code>gasLimit</code> (returning a transaction object), check that the transaction object is valid and balanced (gas is charged for these checks as well), and if so apply it to state (as previously in the RM).</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html","title":"Execution flow","text":"<pre><code>module arch.system.state.resource_machine.execution_flow.flow;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#intro","title":"Intro","text":"<p>This section describes the resource machine execution flow and how it is used by various actors.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#resource-machine","title":"Resource machine","text":"<p>A resource machine is a deterministic stateless machine that creates, composes, and verifies transaction functions.</p> <p>It has read-only access to the external global state, which includes the content-addressed storage system (which in particular stores resources), global commitment accumulator, and the global nullifier set, and can produce writes to the external local state that will later be applied to the system state.</p> <p>The resource machine must have the functionality to produce, compose, and evaluate transaction functions and transactions.</p> <p>Actors working with resource machine include users, solvers, and executor nodes.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#users","title":"Users","text":"<p>Users are the initiators of the state change. To initiate the state change, users send the information about the desired state change to solvers. Users own the resources to be consumed/created in the transaction, meaning they are the <code>nullifierKey</code> holders and they control the transaction authorisation mechanism (resource logics).</p> <p>Users are not always online and limited in computational power.</p> <p>Users can create initial actions and transactions that don't require matching, but are assumed to delegate all matching computations to solvers (note that users can take the solver role for themselves as well). To create such transactions, users are expected to be able to do all of the things required to create a transaction, which includes creating all existing data structures, creating all types of proofs, and being able to access the global state.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#solvers","title":"Solvers","text":"<p>Solvers are the parties that have the computational power. Solvers are the parties that see intents and try to match them and output a transaction. Users give solvers the data required to create the future transactions, which may include resource objects, <code>nullifierKey</code>, signed messages, etc. Given the data, solvers create, compose, and verify transactions. Once the transaction is complete and valid, the transaction function is sent for ordering.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#executor","title":"Executor","text":"<p>Executors are the final nodes that receive transaction functions after ordering and produce a state change. After receiving a transaction function, the executor runs it, outputting a transaction that describes a state update. The executor node validates the resulting transaction, by performing the checks described here. In case the transaction is valid, the executor applies the state changes: adds nullifiers to the nullifier set, commitments to the commitment tree, and possibly some other data to the storage.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#post-and-pre-ordering-execution","title":"Post- and pre-ordering execution","text":"<p>Pre-ordering execution implies partial evaluation of the transaction function. In practice pre-ordering execution happens before the transactions are ordered by the ordering component external to the ARM.</p> <p>Post-ordering execution implies full evaluation of the transaction function. As the name suggests, post-ordering execution happens after the ordering component external to the ARM completed the ordering of transaction functions.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html","title":"Applications","text":"<pre><code>module arch.system.state.resource_machine.notes.applications;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#applications","title":"Applications","text":"<p>The ARM applications are characterised by a set of resource logics and associated read and write interfaces.</p> <p>\\(Application = (AppLogic, AppReadInterface, AppWriteInterface)\\), where</p> <ol> <li>\\(AppLogic \\subseteq \\mathbb{F}_l\\) is a set of resource logics.</li> <li>\\(AppWriteInterface = \\{tf: TransactionFunction\\}\\) is a set of functions that represents what kinds of state transitions the application offers.</li> <li>\\(AppReadInterface = \\{pf: ProjectionFunction\\}\\) is a set of functions that interprete the current state. Projection functions are defined as \\(ProjectionFunction: AppState \\rightarrow T\\), where \\(AppState = AppResources \\times AppData\\), with \\(AppResources\\) containing all resources bound to the application\u2019s logic and \\(AppData\\) referring to the non-linear data the application might assume.</li> </ol> <p>As any abstract state transition can be represented as a transaction consuming and creating resources of certain kinds (or a transaction function that evaluates to such a transaction), the transaction functions associated with the application represent the set of actions that the application can provide to its users. Each transaction function would require a subset of the application resource logics to approve the transaction in order to realise the desired action. The transaction function evaluated with the exact resources to be created and consumed forms a transaction.</p> <p>The resources that are bound with the application resource logics are said to belong to the application and, along with some non-linear data the application might assume, constitute the application state. When the application does not have any resources that were created but not consumed yet, the application only exists virtually but not tangibly.</p> <p>The abstraction of an application is virtual - applications are not deployed or tracked in any sort of global registry, and the ARM is unaware of the existence of applications.</p> <p>We define \\(AppKinds \\subseteq \\mathbb{F}_{kind}\\) as a union of all resource kinds that are involved in the transaction functions that comprise the application interface.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#composition","title":"Composition","text":"<p>Applications are composable. The composition of two (or more) applications would be a composition of the corresponding logics and interfaces.</p> <p>\\(App_12 = App_1 \\circ App_2\\):</p> <ol> <li>\\(AppLogic_{12} = AppLogic_1 \\cup AppLogic_2\\)</li> <li>\\(AppWriteInterface_{12} = AppWriteInterface_1 \\cup AppWriteInterface_2\\)</li> <li>\\(AppReadInterface_{12} = AppReadInterface_1 \\cup AppReadInterface_2\\)</li> <li>\\(AppKinds_{12} = AppKinds_1 \\cup AppKinds_2\\)</li> </ol> <p>In this type of composition the order in which the applications are composed doesn't matter.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#application-extension","title":"Application extension","text":"<p>Application extension is a way to generate a new application starting from an existing one by enhancing the application logic and the application interface with operations on more resource kinds. The new application is dependent on the initial one, meaning that the new application logic includes constraints involving the first application resource kinds, and the new interface requires the presence of resources of the first application kinds.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#distributed-application-state-synchronisation","title":"Distributed application state synchronisation","text":"<p>In the controllers report, a controller is defined as a component that orders transactions. The resource machine is designed to work in both single-controller and multi-controller environments, such as Anoma. In the context of multi-controller environments, each resource contains information about its current controller, can only be consumed on its controller, and can be transferred from one controller to another, meaning that a new controller becomes responsible for the correct resource consumption. Transferring a resource can be done by consuming a resource on the old controller and creating a similar resource on the new controller.</p> <p>Applications do not have to exist within the bounds of a single controller, and can maintain a single virtual state while the application resources being distributed among multiple controllers, which forms a distributed application state. To make sure such a distributed state correctly represents the application state, state synchronisation between multiple controllers is required.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#controller-state-synchronisation","title":"Controller state synchronisation","text":"<p>Each controller would have their own commitment tree associated with it. Treated as subtrees of a larger Merkle tree, the controller commitment trees comprise a global commitment tree, where the leaves are the roots of the controller trees.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html","title":"Nockma implementation","text":"Juvix imports <pre><code>module arch.system.state.resource_machine.notes.nockma;\nimport prelude open;\nimport Stdlib.Data.Nat open;\nimport Stdlib.Data.List open;\nimport Stdlib.Trait.Show open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#nockma-implementation","title":"Nockma Implementation","text":"Operation Code Name Description 0 Slash (/) Address/path selection 1 Constant Returns operand unchanged 2 Apply/Ap/S Function application 3 Cell test (?) Tests if noun is cell 4 Increment (+) Add 1 to atom 5 Equality test (=) Compare nouns 6 If-then-else Conditional execution 7 Compose Function composition 8 Extend subject Extends the subject 9 Invoke Call function by arm name 10 Pound (#) Handle operation 11 Match Case split on Cells vs Atoms 12 Scry Read storage","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#core-data-types","title":"Core Data Types","text":"<p>The fundamental data structures for Nockma implementation, including the <code>Noun</code> type that represents all data in Nock, along with equality and display instances.</p> <pre><code>-- Basic Nock types\ntype Noun :=\n  | Atom : Nat -&gt; Noun\n  | Cell : Noun -&gt; Noun -&gt; Noun;\n</code></pre> <pre><code>terminating\nnounEq (n1 n2 : Noun) : Bool :=\n  case mkPair n1 n2 of {\n    | mkPair (Noun.Atom x) (Noun.Atom y) := x == y\n    | mkPair (Noun.Cell a b) (Noun.Cell c d) := nounEq a c &amp;&amp; nounEq b d\n    | _ := false\n  };\n\ninstance EqNoun : Eq Noun := Eq.mk@{ isEqual := nounEq };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#pretty-printer-for-noun","title":"Pretty-printer for Noun","text":"<pre><code>terminating\nshowNoun (n : Noun) : String :=\n  case n of {\n    | Noun.Atom a := natToString a\n    | Noun.Cell l r := \"[\" ++str (showNoun l) ++str \" \" ++str (showNoun r) ++str \"]\"\n  };\n\ninstance ShowNoun : Show Noun := Show.mk@{ show := showNoun };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#storage-system-and-operation-types","title":"Storage System and Operation Types","text":"<p>Storage abstraction for scrying operations and the enumeration of all Nock operations with their corresponding opcodes.</p> <pre><code>-- Helper to convert storage values to Nouns\naxiom convertToNoun : {val : Type} -&gt; val -&gt; Noun;\n-- Helper to convert Nouns to storage values\naxiom convertFromNoun : {val : Type} -&gt; Noun -&gt; Option val;\n</code></pre> <pre><code>type ScryOp :=\n  | Direct\n  | Index;\n</code></pre> <pre><code>type Storage addr val := mkStorage {\n  readDirect : addr -&gt; Option val;\n  readIndex : val -&gt; Option val\n};\n\nemptyStorage {addr val : Type} : Storage addr val :=\n  Storage.mkStorage@{\n    readDirect := \\{_ := none};\n    readIndex := \\{_ := none};\n  };\n\naxiom externalStorage : {addr val : Type} -&gt; Storage addr val;\n</code></pre> <pre><code>type NockOp :=\n  | Slash -- /\n  | Constant -- Returns operand unchanged\n  | Apply\n  | CellTest -- ?\n  | Increment -- +\n  | EqualOp -- =\n  | IfThenElse -- 6\n  | Compose -- 7\n  | Extend -- 8\n  | Invoke -- 9\n  | Pound -- #\n  | Match -- 11\n  | Scry; -- 12\n</code></pre> <pre><code>opOr {A : Type} (n m : Option A) : Option A :=\n  case n of {\n    | none := m\n    | (some n) := some n\n  };\n</code></pre> <pre><code>parseOp (n : Nat) : Option NockOp :=\n  let test := \\{m op :=\n    case (n == m) of {\n      | true := some op\n      | false := none\n    }} in\n  foldr opOr none\n    (zipWith test\n      [0; 1; 2; 3; 4; 5; 6; 7; 8; 9; 10; 11; 12]\n      [NockOp.Slash; NockOp.Constant; NockOp.Apply; NockOp.CellTest; NockOp.Increment;\n      NockOp.EqualOp; NockOp.IfThenElse; NockOp.Compose; NockOp.Extend; NockOp.Invoke;\n      NockOp.Pound; NockOp.Match; NockOp.Scry]);\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#gas-state-monad","title":"Gas State Monad","text":"<p>A monadic framework for tracking gas consumption and handling errors during Nock evaluation. This ensures computations can be bounded and failures can be properly handled.</p> <pre><code>-- Monad to encompass gas consumption and error handling.\ntype GasState A := mk {\n  runGasState : Nat -&gt; Result String (Pair A Nat)\n};\n</code></pre> <pre><code>instance\nGasStateMonad : Monad GasState := Monad.mk@{\n  applicative := Applicative.mk@{\n    functor := Functor.mk@{\n      map := \\{f s := GasState.mk \\{gas :=\n        case GasState.runGasState s gas of {\n          | ok (mkPair x remaining) := ok (mkPair (f x) remaining)\n          | error e := error e\n        }}\n    }};\n    pure := \\{x := GasState.mk \\{gas := ok (mkPair x gas)}};\n    ap := \\{sf sa := GasState.mk \\{gas :=\n      case GasState.runGasState sf gas of {\n        | ok (mkPair f remaining) :=\n          case GasState.runGasState sa remaining of {\n            | ok (mkPair x final) := ok (mkPair (f x) final)\n            | error e := error e\n          }\n        | error e := error e\n      }}\n    }\n  };\n  bind := \\{ma f := GasState.mk \\{gas :=\n    case GasState.runGasState ma gas of {\n      | ok (mkPair a remaining) := GasState.runGasState (f a) remaining\n      | error e := error e\n    }}\n  }\n};\n\nerr {A : Type} (str : String) : GasState A := GasState.mk \\{_ := error str};\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#gas-management-and-storage-operations","title":"Gas Management and Storage Operations","text":"<p>Functions for managing computational costs and implementing storage read operations (scrying) that allow Nock programs to interact with external data.</p> <pre><code>-- Gas cost values for each operation type\n-- These are made up for demo purposes\ngetGasCost (cost : NockOp) : Nat :=\n  case cost of {\n    | NockOp.Slash := 1\n    | NockOp.CellTest := 1\n    | NockOp.Increment := 1\n    | NockOp.EqualOp := 2\n    | NockOp.IfThenElse := 3\n    | NockOp.Compose := 2\n    | NockOp.Extend := 2\n    | NockOp.Invoke := 3\n    | NockOp.Pound := 1\n    | NockOp.Scry := 10\n    | _ := 0\n  };\n</code></pre> <pre><code>consume (op : NockOp) : GasState Unit :=\n  GasState.mk \\{gas :=\n  let cost := getGasCost op in\n  case cost &gt; gas of {\n    | true := error \"Out of gas\"\n    | false := ok (mkPair unit (sub gas cost))\n  }};\n</code></pre> <pre><code>-- Implementation of storage read operations (scrying)\nscry {val : Type} (stor : Storage Nat val) (op : ScryOp) (addr : Nat) : Result String Noun :=\n  case op of {\n    | ScryOp.Direct := case Storage.readDirect stor addr of {\n      | some val := ok (convertToNoun val)\n      | none := error \"Direct storage read failed\"\n    }\n    | ScryOp.Index := case Storage.readDirect stor addr of {\n      | some indexFn := case Storage.readIndex stor indexFn of {\n        | some val := ok (convertToNoun val)\n        | none := error \"Index computation failed\"\n      }\n      | none := error \"Index function not found\"\n    }\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#helper-operations","title":"Helper Operations","text":"<p>Implementation of the fundamental slash (<code>/</code>) and pound (<code>#</code>) operations that provide tree navigation and editing capabilities respectively.</p> <pre><code>-- Helper for slash (/) operations\nterminating\nslash {val : Type} (stor : Storage Nat val) (n : Noun) (subject : Noun) : GasState Noun :=\n  case n of {\n    | Noun.Atom x := case x == 1 of {\n      | true := pure subject -- Rule: /[1 a] -&gt; a\n      | false := case x == 2 of {\n        | true := case subject of { -- Rule: /[2 a b] -&gt; a\n          | Noun.Cell a _ := pure a\n          | _ := err (\"Cannot take slash (/2) of atom: \" ++str (showNoun subject))\n        }\n        | false := case x == 3 of {\n          | true := case subject of { -- Rule: /[3 a b] -&gt; b\n            | Noun.Cell _ b := pure b\n            | _ := err (\"Cannot take slash (/3) of atom: \" ++str (showNoun subject))\n          }\n          | false := case (mod x 2) == 0 of {\n            | true :=  -- Rule: /[(a + a) b] -&gt; /[2 /[a b]]\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom (div x 2)) subject &gt;&gt;= \\{res :=\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom 2) res\n                }}}\n            | false := -- Rule: /[(a + a + 1) b] -&gt; /[3 /[a b]]\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom (div x 2)) subject &gt;&gt;= \\{res :=\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom 3) res\n                }}}\n          }\n        }\n      }\n    }\n    | _ := err (\"Slash axis must be atom, got: \" ++str (showNoun n))\n  };\n</code></pre> <pre><code>-- Helper for pound (#) operations\nterminating\npound {val : Type} (stor : Storage Nat val) (n : Noun) (b : Noun) (c : Noun) : GasState Noun :=\n  case n of {\n    | Noun.Atom x := case x == 1 of {\n      | true := pure b  -- Rule: #[1 a b] -&gt; a\n      | false := case mod x 2 == 0 of {\n        | true := case c of { -- Rule: #[(a + a) b c] -&gt; #[a [b /[(a + a + 1) c]] c]\n          | Noun.Cell _ _ :=\n            consume NockOp.Slash &gt;&gt;= \\{_ :=\n            slash stor (Noun.Atom ((2 * div x 2) + 1)) c &gt;&gt;= \\{slashResult :=\n            consume NockOp.Pound &gt;&gt;= \\{_ :=\n            pound stor (Noun.Atom (div x 2)) (Noun.Cell b slashResult) c\n            }}}\n          | _ := err (\"Invalid pound target (must be cell): \" ++str (showNoun c))\n        }\n        | false := case c of { -- Rule: #[(a + a + 1) b c] -&gt; #[a [/[(a + a) c] b] c]\n          | Noun.Cell _ _ :=\n            consume NockOp.Slash &gt;&gt;= \\{_ :=\n            slash stor (Noun.Atom (2 * div x 2)) c &gt;&gt;= \\{slashResult :=\n            consume NockOp.Pound &gt;&gt;= \\{_ :=\n            pound stor (Noun.Atom (div x 2)) (Noun.Cell slashResult b) c\n            }}}\n          | _ := err (\"Invalid pound target (must be cell): \" ++str (showNoun c))\n        }\n      }\n    }\n    | _ := err (\"Pound axis must be atom, got: \" ++str (showNoun n))\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#operation-evaluator","title":"Operation Evaluator","text":"<p>The main dispatcher that handles evaluation of each Nock operation according to the Nock specification. Each case implements one of the 13 fundamental Nock operations.</p> <pre><code>terminating\nevalOp\n  {val : Type} (stor : Storage Nat val) (op : NockOp) (a : Noun) (args : Noun) : GasState Noun :=\n  case op of {\n    -- *[a 0 b] -&gt; /[b a]\n    | NockOp.Slash := slash stor args a\n\n    -- *[a 1 b] -&gt; b\n    | NockOp.Constant := pure args\n\n    -- *[a 2 b c] -&gt; *[*[a b] *[a c]]\n    | NockOp.Apply := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r2 :=\n        nock stor (Noun.Cell r1 r2)\n        }}\n      | _ := err (\"Invalid apply (2) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 3 b] -&gt; ?*[a b]\n    -- ?[a b] -&gt; 0\n    -- ?a -&gt; 1\n    | NockOp.CellTest := case args of {\n      | Noun.Cell b _ :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{res :=\n        case res of {\n          | Noun.Cell _ _ := pure (Noun.Atom 0)\n          | _ := pure (Noun.Atom 1)\n        }\n        }\n      | _ := err (\"Invalid cell test (3) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 4 b] -&gt; +*[a b]\n    -- +[a b] -&gt; error (specs say this should loop infinitely?)\n    -- +a -&gt; 1 + a\n    | NockOp.Increment :=\n        -- First, evaluate the argument expression *[subject args]\n        nock stor (Noun.Cell a args) &gt;&gt;= \\{res :=\n          -- Then, check if the result is an atom and increment it\n          case res of {\n            | (Noun.Atom n) := pure (Noun.Atom (suc n))\n            | x := err (\"Increment (4) target must be atom, got: \" ++str (showNoun x))\n          }\n        }\n\n    -- *[a 5 b c] -&gt; =*[a b] *[a c]\n    -- =[a a] -&gt; 0\n    -- =[a b] -&gt; 1\n    | NockOp.EqualOp := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r2 :=\n        pure (Noun.Atom (case nounEq r1 r2 of {\n              | true := 0\n              | false := 1\n            }))\n        }}\n      | _ := err (\"Invalid equality (5) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 6 b c d] -&gt; *[a *[[c d] 0 *[[2 3] 0 *[a 4 4 b]]]]\n    | NockOp.IfThenElse := case args of {\n      | Noun.Cell b (Noun.Cell c d) :=\n        nock stor (Noun.Cell a (Noun.Cell (Noun.Atom 4) (Noun.Cell (Noun.Atom 4) b))) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell (Noun.Cell (Noun.Atom 2) (Noun.Atom 3)) (Noun.Cell (Noun.Atom 0) r1)) &gt;&gt;= \\{r2 :=\n        nock stor (Noun.Cell (Noun.Cell c d) (Noun.Cell (Noun.Atom 0) r2)) &gt;&gt;= \\{r3 :=\n        nock stor (Noun.Cell a r3)\n        }}}\n      | _ := err (\"Invalid if-then-else (6) args (must be [b [c d]]): \" ++str (showNoun args))\n    }\n\n    -- *[a 7 b c] -&gt; *[*[a b] c]\n    | NockOp.Compose := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r :=\n        nock stor (Noun.Cell r c)\n        }\n      | _ := err (\"Invalid compose (7) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 8 b c] -&gt; *[[*[a b] a] c]\n    | NockOp.Extend := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r :=\n        nock stor (Noun.Cell (Noun.Cell r a) c)\n        }\n      | _ := err (\"Invalid extend (8) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 9 b c] -&gt; *[*[a c] 2 [0 1] 0 b]\n    | NockOp.Invoke := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{core :=\n        let formula := Noun.Cell (Noun.Atom 2) (Noun.Cell (Noun.Cell (Noun.Atom 0) (Noun.Atom 1)) (Noun.Cell (Noun.Atom 0) b)) in\n        nock stor (Noun.Cell core formula)\n        }\n      | _ := err (\"Invalid invoke (9) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 10 [b c] d] -&gt; #[b *[a c] *[a d]]\n    | NockOp.Pound := case args of {\n      | Noun.Cell (Noun.Cell b c) d :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a d) &gt;&gt;= \\{r2 :=\n        pound stor b r1 r2\n        }}\n      | _ := err (\"Invalid pound (10) args (must be [[b c] d]): \" ++str (showNoun args))\n    }\n\n    -- *[a 11 [b c] d] -&gt; *[[*[a c] *[a d]] 0 3]\n    -- *[a 11 b c] -&gt; *[a c]\n    | NockOp.Match := case args of {\n      | Noun.Cell (Noun.Cell b c) d :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a d) &gt;&gt;= \\{r2 :=\n        nock stor (Noun.Cell (Noun.Cell r1 r2) (Noun.Cell (Noun.Atom 0) (Noun.Atom 3)))\n        }}\n      | Noun.Cell b c := nock stor (Noun.Cell a c) -- Corrected to take 'a' as subject\n      | _ := err (\"Invalid match (11) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 12 b c d] -&gt; result &lt;- SCRY b c; *[a result d]\n    | Scry := case args of {\n      | Noun.Cell b (Noun.Cell c d) :=\n          -- First evaluate b to get the opcode\n          nock stor b &gt;&gt;= \\{opcode :=\n            case opcode of {\n              | Noun.Atom opval :=\n                  -- Then evaluate c to get the address\n                  nock stor c &gt;&gt;= \\{addr :=\n                    case addr of {\n                      | Noun.Atom addrVal :=\n                          -- Convert opcode to ScryOp\n                          let scryType := case opval == 0 of {\n                            | true := ScryOp.Direct\n                            | false := ScryOp.Index\n                          } in\n                          -- Perform the scry operation and wrap result in GasState\n                          GasState.mk \\{gas :=\n                            scry stor scryType addrVal &gt;&gt;= \\{scryResult :=\n                            -- Continue evaluation with the scry result\n                            GasState.runGasState (nock stor (Noun.Cell a (Noun.Cell scryResult d))) gas\n                            }\n                          }\n                      | _ := err (\"Scry address must be atom, got: \" ++str (showNoun addr))\n                    }\n                  }\n              | _ := err (\"Scry type must be atom, got: \" ++str (showNoun opcode))\n            }\n          }\n      | _ := err (\"Invalid scry (12) args (must be [b [c d]]): \" ++str (showNoun args))\n    }\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#core-nockma-evaluator","title":"Core Nockma Evaluator","text":"<p>The main entry point for Nock evaluation. This function handles the parsing of Nock expressions and dispatches to the appropriate operation evaluators.</p> <pre><code>-- Core Nockma evaluator\nterminating\nnock {val : Type} (stor : Storage Nat val) (input : Noun) : GasState Noun :=\n  case input of {\n    -- Rule: *a -&gt; *a\n    | Noun.Atom n := err (\"Cannot evaluate atom as program: \" ++str (showNoun (Noun.Atom n)))\n\n    | Noun.Cell a b := case b of {\n\n      | Noun.Cell first rest := case first of {\n        -- Rule: *[a [b c] d] -&gt; [*[a b c] *[a d]]\n        | Noun.Cell b c :=\n          nock stor (Noun.Cell a (Noun.Cell b c)) &gt;&gt;= \\{r1 :=\n          nock stor (Noun.Cell a rest) &gt;&gt;= \\{r2 :=\n          pure (Noun.Cell r1 r2)\n          }}\n\n        | Noun.Atom n := case parseOp n of {\n          | some opcode := consume opcode &gt;&gt;= \\{_ :=\n              evalOp stor opcode a rest -- Evaluate [subject rest] with opcode n\n            }\n          | none := err (\"Invalid operation code: \" ++str (natToString n) ++str \" in formula: \" ++str (showNoun b))\n        }\n      }\n      -- Rule: *[a b] where b is an atom is an error\n      | Noun.Atom bn := err (\"Formula cannot be an atom: \" ++str (showNoun (Noun.Atom bn)) ++str \" in input: \" ++str (showNoun input))\n    }\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html","title":"Nockma runnable","text":"Juvix imports <pre><code>module arch.system.state.resource_machine.notes.nockma_runnable;\nimport prelude open;\nimport arch.system.state.resource_machine.notes.nockma open;\nimport arch.system.state.resource_machine.notes.runnable open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html#nockma-runnable-implementation","title":"Nockma Runnable Implementation","text":"<p>This module implements the <code>Runnable</code> trait for Nockma, allowing it to be used as an executor in the Anoma system.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html#types","title":"Types","text":"<pre><code>-- The program state for Nockma is just the current Noun being evaluated\ntype NockmaProgramState := mk {\n  current_noun : Noun;\n  storage : Storage Nat Noun;\n  gas_limit : Nat;\n};\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html#runnable-instance","title":"Runnable Instance","text":"<pre><code>instance nockmaRunnable : Runnable Nat Nat Noun NockmaProgramState :=\n  Runnable.mkRunnable@{\n    -- Execute one step of Nockma evaluation\n    executeStep := \\{executable state input :=\n      let\n        -- Convert input key-value pair to a Noun for evaluation\n        -- The input value is already a Noun since KVSDatum is Nat\n        input_noun := Noun.Cell (Noun.Atom (fst input)) (Noun.Atom (snd input));\n        -- Construct the Nock subject: [state [key val]]\n        subject := Noun.Cell (NockmaProgramState.current_noun state) input_noun;\n        -- Construct the full input for Nock evaluation: [subject formula]\n        full_input := Noun.Cell subject executable;\n        -- Run Nockma evaluation with current gas limit\n        result := GasState.runGasState (nock (NockmaProgramState.storage state) full_input) (NockmaProgramState.gas_limit state);\n      in case result of {\n        | error err := error err\n        | ok (mkPair result_noun remaining_gas) :=\n          -- Parse the result noun which should be of the form (Noun.Atom new_state output_requests)\n          -- where output_requests is a list encoded as (Noun.Atom req1 (Noun.Atom req2 (Noun.Atom ... (Noun.Atom last_req 0))))\n          -- A request is either:\n          -- - (Noun.Atom key value) for write requests\n          -- - (Noun.Atom key) for read requests\n          case result_noun of {\n            | Noun.Cell (Noun.Atom new_state) requests :=\n              let\n                -- Helper to parse a single request\n                parseRequest (req : Noun) : Option (Either Nat (Pair Nat Nat)) :=\n                  case req of {\n                    | Noun.Atom key := some (left key)  -- Read request\n                    | Noun.Cell (Noun.Atom key) (Noun.Atom value) := some (right (mkPair key value))  -- Write request\n                    | _ := none  -- Invalid request format, ignore it\n                  };\n                -- Helper to parse the linked list of requests\n                terminating\n                parseRequests (reqs : Noun) : List (Either Nat (Pair Nat Nat)) :=\n                  case reqs of {\n                    | Noun.Atom zero := nil  -- End of list\n                    | Noun.Cell (Noun.Atom req) rest :=\n                      case parseRequest (Noun.Atom req) of {\n                        | none := parseRequests rest\n                        | some parsed := parsed :: parseRequests rest\n                      }\n                    | _ := nil  -- Invalid request list format, return empty list\n                  };\n                -- Parse all requests\n                parsed_requests := parseRequests requests;\n                -- Update program state with new state and remaining gas\n                new_state := state@NockmaProgramState{\n                  current_noun := Noun.Atom new_state;\n                  gas_limit := remaining_gas\n                };\n              in ok (mkPair new_state parsed_requests)\n            | _ := error \"Invalid result format\"\n          }\n      }\n    };\n\n    -- Check if program has halted (out of gas or reached final value)\n    halted := \\{state :=\n      -- Program halts if out of gas or reaches specific state value\n      NockmaProgramState.gas_limit state == zero ||\n      case NockmaProgramState.current_noun state of {\n        | Noun.Atom n := n == 1702390132\n        | _ := false\n      }\n    };\n\n    -- Initial program state\n    startingState := NockmaProgramState.mk@{\n      current_noun := Noun.Atom zero;  -- Start with empty noun\n      storage := emptyStorage;  -- Use external storage\n      gas_limit := 1000  -- Start with 1000 gas units\n    }\n  };\n</code></pre> <p>This implementation:</p> <ol> <li> <p>Defines a <code>NockmaProgramState</code> type that tracks:</p> <ul> <li>The current Noun being evaluated</li> <li>The storage interface for reading/writing Nouns</li> <li>The remaining gas limit</li> </ul> </li> <li> <p>Implements <code>executeStep</code> to:</p> <ul> <li>Convert input key-value pair to a Noun (using direct Noun.Atom construction since KVSDatum is Nat)</li> <li>Construct the Nock subject: [state [key val]]</li> <li>Construct the full input for Nock evaluation: [subject formula]</li> <li>Run one step of Nockma evaluation</li> <li>Parse the result which should be of the form (Noun.Atom new_state output_requests)</li> <li>Parse the output_requests which is a linked list of requests</li> <li>Each request is either:<ul> <li>(Noun.Atom key) for read requests</li> <li>(Noun.Atom key value) for write requests</li> </ul> </li> <li>Update program state with new state and remaining gas</li> <li>Return new state and parsed requests</li> </ul> </li> <li> <p>Implements <code>halted</code> to check if program has run out of gas or is in designated halting state</p> </li> <li> <p>Provides <code>startingState</code> with initial values</p> </li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html","title":"Roles and requirements","text":"<pre><code>module arch.system.state.resource_machine.notes.roles_and_requirements;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html#roles-and-requirements","title":"Roles and requirements","text":"<p>The table below contains a list of resource-related roles. In the Anoma protocol, the role of the resource creator will often be taken by a solver, which creates additional security requirements compared to the case when protocol users solve their own intents. Because of that, extra measures are required to ensure reliable distribution of the information about the created resource to the resource receiver.</p> Role Description Authorizer approves the resource consumption on the application level. The resource logic encodes the mechanism that connects the authorizer's external identity (public key) to the decision-making process Annuler knows the data required to nullify a resource Creator creates the resource and shares the data with the receiver Owner can both authorize and annul a resource Sender owns the resources that were consumed to create the created resource Receiver owns the created resource","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html#reliable-resource-object-distribution","title":"Reliable resource object distribution","text":"<p>In the case of in-band distribution of created resources in contexts with higher security requirements, the resource creator is responsible for encrypting the resource object. Verifiable encryption must be used to ensure the correctness of the encrypted data: the encrypted object must be proven to correspond to the resource object, which is passed as a private input.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html#reliable-nullifier-key-distribution","title":"Reliable nullifier key distribution","text":"<p>Knowing the resource\u2019s nullifier reveals information about when the resource is consumed, as the nullifier will be published when it happens, which might be undesirable in the contexts with higher security requirements. For that reason, it is advised to keep the number of parties who can compute the resource\u2019s nullifier as low as possible in such contexts.</p> <p>In particular, the resource creator should not be able to compute the resource nullifier, and as the nullifier key allows to compute the resource's nullifier, it shouldn't be known to the resource creator. At the same time, the resource object must contain some information about the nullifier key. One way to fulfil both requirements is, instead of sharing the nullifier key itself with the resource creator, to share some parameter derived from the nullifier key, but that does not allow computing the nullifier key or any meaningful information about it. This parameter is called a nullifier key commitment and is computed as \\(cnk = h_{cnk}(nk)\\).</p> <p>These concerns are not meaningful in the contexts with lower security requirements.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/runnable.html","title":"Runnable trait","text":"<p>icon: octicons/container-24 search:   exclude: false tags:   - resource-machine</p> Juvix imports <pre><code>module arch.system.state.resource_machine.notes.runnable;\nimport prelude open;\n</code></pre> <pre><code>trait\ntype Runnable KVSKey KVSDatum Executable ProgramState :=\n  mkRunnable@{\n    executeStep : Executable -&gt; ProgramState -&gt; Pair KVSKey KVSDatum -&gt; Result String (Pair ProgramState (List (Either KVSKey (Pair KVSKey KVSDatum))));\n    halted : ProgramState -&gt; Bool;\n    startingState : ProgramState;\n  };\n</code></pre> <code>executeStep</code>: Takes the executable code, current program state, and read key-value pair and returns either:   - Error string on failure   - New program state and list of either:     - Left key for read requests     - Right (key, value) for write requests"},{"location":"arch/system/state/resource_machine/notes/storage.html","title":"Stored data format","text":"<pre><code>module arch.system.state.resource_machine.notes.storage;\n</code></pre> <p>Warning</p> <p>Will be updated soon</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#stored-data-format","title":"Stored data format","text":"<p>The ARM state that needs to be stored includes resource objects, the commitment accumulator and the nullifier set. The table below defines the format of that data assumed by the ARM.</p> Name Structure Key Type Value Type Commitment accumulator (node) Cryptographic accumulator timestamp \\(\\mathbb{F}\\) Commitment accumulator (leaf) - (<code>timestamp</code>, \\(\\mathbb{F}\\)) \\(\\mathbb{F}\\) Nullifier set Set \\(\\mathbb{F}\\) \\(\\mathbb{F}\\) Hierarchical index Chained Hash sets Tree path \\(\\mathbb{F}\\) Data blob storage Key-value store with deletion criterion \\(\\mathbb{F}\\) (<code>variable length byte array</code>, <code>deletion criterion</code>)","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#cmtree","title":"\\(CMtree\\)","text":"<p>Each commitment tree node has a timestamp associated with it, such that a lower depth (closer to the root) tree node corresponds to a less specified timestamp: a parent node timestamp is a prefix of the child node timestamp, and only the leaves of the tree have fully specified timestamps (i.e. they are only prefixes of themselves). For a commitment tree of depth \\(d\\), a timestamp for a commitment \\(cm\\) would look like \\(t_{cm} =t_1:t_2:..:t_d\\), with the parent node corresponding to it having a timestamp \\(t_1:t_2:..:*\\). The timestamps are used as keys for the key-value store. For the tree leaves, \\(&lt;cm, t_{cm}&gt;\\) pairs are used as keys. Merkle paths to resource commitments can be computed from the hierarchy of the timestamps.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#nfset","title":"\\(NFset\\)","text":"<p>Nullifiers are used as keys in the key-value store. In future versions, a more complex structure that supports efficient non-membership proofs might be used for storing the nullifier set.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#hierarchical-index","title":"Hierarchical index","text":"<p>The hierarchical index is organised as a tree where the leaves refer to the resources, and the intermediate nodes refer to resource subkinds that form a hierarchy. The label of a resource \\(r\\) stored in the hierarchical index tree is interpreted as an array of sublabels: \\(r.label = [label_1, label_2, label_3, ...]\\), and the i-th subkind is computed as \\(r.subkind_i = H_{kind}(r.l, r.label_i)\\).</p> <p>In the current version, only the subkinds derived from the same resource logic can be organized in the same hierarchical index path.</p> <p>The interface of the tree enables efficient querying of all children of a specific path and verifying that the returned children are the requested nodes. Permissions to add data to the hierarchical index are enforced by the resource logics and do not require additional checks.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#data-blob-storage","title":"Data blob storage","text":"<p>Data blob storage stores data without preserving any specific structure. The data is represented as a variable length byte array and comes with a deletion criterion that determines for how long the data will be stored. The deletion criterion, in principle, is an arbitrary predicate, which in practice currently is assumed to be instantiated by one of the following options:</p> <ol> <li>delete immediately</li> <li>delete after \\(block\\)</li> <li>delete after \\(timestamp\\)</li> <li>delete after \\(sig\\) over \\(data\\)</li> <li>delete after either predicate \\(p_1\\) or \\(p_2\\) is true; the predicates are instantiated by options from this list</li> <li>store forever</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/notes/function_formats/transaction_function_format.html","title":"Transaction function format","text":"<pre><code>module arch.system.state.resource_machine.notes.function_formats.transaction_function_format;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/function_formats/transaction_function_format.html#transaction-function-format","title":"Transaction function format","text":"<p>The system used to represent and interpret transaction functions must have a deterministic computation model; each operation should have a fixed cost of space and time (for total cost computation). To support content addressing, it must have memory and support memory operations (specifically <code>read</code>, <code>write</code>, <code>allocate</code>).</p> <p>The system must support the following I/O operations:</p> <ol> <li><code>readStorage</code>(<code>address</code>: <code>Commitment</code>): read the global content-addressed storage at the specified address and return the value stored at the address. If the value is not found, the operation should return an error. Storage not accessible to the machine should be treated as non-existent.</li> <li><code>dataByIndex</code>(<code>indexFunction)</code>: read data from the storage (either resources or arbitrary data kept in the storage requested by the transaction function) at the execution time by the specified index function. If the index function output is invalid or uncomputable, or the data cannot be located, the operation should return an error. Typically, the index functions allowed will be very restricted, e.g. an index function returning current unspent resources of a particular kind.</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/notes/function_formats/transaction_function_format.html#gas-model","title":"Gas model","text":"<p>To compute and bound the total cost of computation, the transaction function system must support a gas model. Each evaluation would have a gas limit \\(g_{limit}\\), and the evaluation would start with \\(g_{count} = 0\\). Evaluating an operation, the system would add the cost of the operation to the counter \\(g_{count}\\) and compare it to \\(g_{limit}\\). When making recursive calls, \\(g_{count}\\) is incremented before the recursion occurs. If the value of \\(g_{count}\\) is greater than \\(g_{limit}\\), the execution is terminated with an error message indicating that the gas limit has been surpassed.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html","title":"Commitment accumulator","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.commitment_accumulator;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#commitment-accumulator","title":"Commitment accumulator","text":"<p>All resource commitments are stored in an append-only data structure called a commitment accumulator. Every time a resource is created, its commitment is added to the commitment accumulator. The resource commitment accumulator is external to the resource machine, but the resource machine can read from it. A commitment accumulator is a cryptographic accumulator that allows to prove membership for elements accumulated in it, provided a witness and the accumulated value.</p> <p>Each time a commitment is added to the accumulator, the accumulator and all witnesses of the already accumulated commitments are updated. For a commitment that existed in the accumulator before a new one was added, both the old witness and the new witness (with the corresponding accumulated value parameter) can be used to prove membership. However, the older the witness (and, consequently, the accumulator) that is used in the proof, the more information about the resource it reveals (an older accumulator gives more concrete boundaries on the resource's creation time). For that reason, it is recommended to use fresher parameters when proving membership.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#accumulator-functionality","title":"Accumulator functionality","text":"<p>Note</p> <p>The witness we are talking about here is not related to proving system witness. It is a distinct concept of cryptographic accumulators.</p> <p>The commitment accumulator has type <code>Accumulator</code> and is parametrised over the types <code>AccumulatorWitness</code>,<code>CommitmentIdentifier</code>, and <code>AccumulatedValue</code>. The commitment accumulator interface must support the following functionality:</p> <ol> <li><code>add(Accumulator, CommitmentIdentifier) -&gt; AccumulatorWitness</code> adds an element to the accumulator, returning the accumulator witness used to prove membership.</li> <li><code>witness(Accumulator, CommitmentIdentifier) -&gt; Maybe AccumulatorWitness</code> for a given element, returns the accumulator witness used to prove membership if the element is present, otherwise returns nothing.</li> <li><code>verify(CommitmentIdentifier, AccumulatorWitness, AccumulatedValue) -&gt; Bool</code> verifies the membership proof for a commitment identified with <code>CommitmentIdentifier</code> element with a membership witness <code>AccumulatorWitness</code> for the accumulated value <code>AccumulatedValue</code>.</li> <li><code>value(Accumulator) -&gt; AccumulatedValue</code> returns the accumulator value.</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#merkle-tree","title":"Merkle tree","text":"<p>Currently, the commitment accumulator is assumed to be a Merkle tree <code>CMTree</code> of depth \\(depth_{CMtree}\\), where the leaves contain the resource commitments and the intermediate nodes' values are of type <code>MerkleTreeNodeHash</code>.</p> <p>Note</p> <p>The type <code>MerkleTreeNodeHash</code> of the <code>CMTree</code> nodes and the type of the leafs <code>Commitment</code> are distinct types.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#interface","title":"Interface","text":"<p>For a Merkle tree:</p> <ol> <li><code>CommitmentIdentifier</code> type corresponds to the identifier of the resource commitment used to locate the commitment's position in the tree</li> <li><code>AccumulatorWitness</code> element is a path to the stored commitment</li> <li><code>AccumulatedValue</code> corresponds to the Merkle tree root</li> </ol> <p>and the functions:</p> <ol> <li><code>add</code> adds the resource commitment to the tree, returning the path to the commitment</li> <li><code>witness</code> finds the resource commitment in the tree and returns the path to it</li> <li><code>verify</code> uses the resource commitment and the path to reconstruct the root. Returns <code>True</code> if the constructed value is equal to the provided value</li> <li><code>value</code> returns the tree root</li> </ol> <p>Todo</p> <p>shielded notes: To support the systems with stronger privacy requirements, the witness for such a proof must be a private input when proving membership.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.index;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/index.html#primitive-interfaces","title":"Primitive interfaces","text":"<p>This section defines the hierarchy of primitives used in resource machine design and describes interfaces for each primitive.</p> <p>The diagram below illustrates the primitive types required for resource machine. Red nodes correspond to primitive interfaces, green nodes correspond to instantiations of the interfaces. Each primitive instantiation has an associated type, e.g. delta hash instantiation of <code>Hash</code> interface has an associated type <code>DeltaHash</code>. Primitive instantiations' names are derived from the type name but written in lower camel case, e.g., for <code>DeltaHash</code> the corresponding function would be <code>deltaHash(..)</code>.</p> <pre><code>flowchart LR\n    ProvingSystem\n    Map --&gt; MapInstance\n    CommitmentAccumulator --&gt; CommitmentAccumulatorInstance\n    NullifierSet --&gt; NullifierSetInstance\n\n    List --&gt; ListInstance\n    Set --&gt; SetInstance\n\n    style SetInstance fill:transparent\n    style ListInstance fill:transparent\n    style MapInstance fill:transparent\n    style CommitmentAccumulatorInstance fill:transparent\n    style NullifierSetInstance fill:transparent\n\n\n    ProvingSystem --&gt; ComplianceProvingSystem\n    ProvingSystem --&gt; ResourceLogicProvingSystem\n    ProvingSystem --&gt; IDeltaProvingSystem\n    IDeltaProvingSystem --&gt; DeltaProvingSystem\n    style ComplianceProvingSystem fill:transparent\n    style ResourceLogicProvingSystem fill:transparent\n    style DeltaProvingSystem fill:transparent</code></pre> Primitive interfaces <pre><code>flowchart LR\n\n    FixedSize --&gt; Arithmetic\n    FixedSize --&gt; Hash\n\n\n    FixedSize --&gt; Nonce\n    FixedSize --&gt; RandSeed\n    FixedSize --&gt; NullifierKeyCommitment\n    FixedSize --&gt; NullifierKey\n\n    style Nonce fill:transparent\n    style RandSeed fill:transparent\n    style NullifierKey fill:transparent\n    style NullifierKeyCommitment fill:transparent\n\n\n    Arithmetic --&gt; Quantity\n    Arithmetic --&gt; Balance\n\n    Arithmetic --&gt; DeltaHash\n\n    style Quantity fill:transparent\n    style Balance fill:transparent\n    style DeltaHash fill:transparent\n\n\n    Hash --&gt; PS\\.VerifyingKey\n    Hash --&gt; LabelHash\n    Hash --&gt; ValueHash\n    Hash --&gt; DeltaHash\n\n    Hash --&gt; Commitment\n    Hash --&gt; Nullifier\n    Hash --&gt; Kind\n    Hash --&gt; LogicVKOuterHash\n    Hash --&gt; MerkleTreeNodeHash\n\n    style LogicVKCompact fill:transparent\n    style LabelHash fill:transparent\n    style ValueHash fill:transparent\n    style DeltaHash fill:transparent\n    style Commitment fill:transparent\n    style Nullifier fill:transparent\n    style Kind fill:transparent\n    style LogicVKOuterHash fill:transparent\n    style MerkleTreeNodeHash fill:transparent\n\n\n    Hash --&gt; AppDataValueHash\n    style AppDataValueHash fill:transparent</code></pre> Primitive types","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/list.html","title":"List","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.ordered_set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/list.html#list","title":"List","text":"<ol> <li><code>new() -&gt; List</code> - creates an empty list</li> <li><code>size(Set) -&gt; Nat</code> - returns the number of elements in the list</li> <li><code>elem(List, Nat) -&gt; Maybe T</code> - returns an element from the list at the given position</li> <li><code>append(List, T) -&gt; List</code> - appends an element to the list</li> <li><code>delete(List, Nat) -&gt; List</code> - removes an element at the given position from the list</li> <li><code>contains(List, T) -&gt; Bool</code> - checks if an element is in the list</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/list.html#used-in","title":"Used in","text":"<ol> <li>Action</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html","title":"Map","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.map;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html#map","title":"Map","text":"<p>Map is a structure that contains pairs (key: value), where key is of type <code>K</code> and value is of type <code>V</code>.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html#interface","title":"Interface","text":"<ol> <li><code>new() -&gt; Map</code></li> <li><code>add(Map, K, V) -&gt; Map</code></li> <li><code>size(Map) -&gt; Nat</code></li> <li><code>get(Map, K) -&gt; V</code></li> <li><code>keys(Map) -&gt; List K</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html#used-in","title":"Used in","text":"<ol> <li>Action</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/nullifier_set.html","title":"Nullifier set","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.nullifier_set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/nullifier_set.html#nullifier-set","title":"Nullifier set","text":"<p>The nullifier set interface requires two main operations:</p> <ol> <li><code>insert(NFSet, T) -&gt; NFSet</code> - adds the nullifier of type T to the nullifier set.</li> <li><code>contains(NFSet, T) -&gt; Bool</code> - searchers for the given element and returns <code>True</code> if the element was found.</li> </ol> <p>At this point, this interface seems to be fully covered by the set interface.</p> <p>Note</p> <p>For the future versions of the nullifier set:</p> <pre><code>1.`Contains` should perform the check in O(1)\n2. The data structure should support proofs of non-existence\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/ordered_set.html","title":"Ordered set","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.ordered_set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/ordered_set.html#ordered-set","title":"Ordered set","text":"<p>Ordered set is a set that preserves order</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/ordered_set.html#used-in","title":"Used in","text":"<ol> <li>Action (commitments, nullifiers)</li> <li>Compliance unit</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html","title":"Set interface","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html#set-primitive-interface","title":"Set primitive interface","text":"<p>A set is an unordered data structure that contains only distinct elements.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html#the-interface","title":"The interface","text":"<p>For a set parametrised over the element type <code>T</code>:</p> <ol> <li><code>new() -&gt; Set</code> - creates an empty set.</li> <li><code>new(List) -&gt; Set</code> - creates a set from the given list of elements. If the list contains duplicating elements, ignores them.</li> <li><code>size(Set) -&gt; Nat</code> - returns the number of elements in the set.</li> <li><code>insert(Set, T) -&gt; Set</code> - adds an element of type <code>T</code> to the set.</li> <li><code>union(Set, Set) -&gt; Set</code> - computes the union of two sets.</li> <li><code>intersection(Set, Set) -&gt; Set</code> - computes the intersection of two sets.</li> <li><code>difference(Set, Set) -&gt; Set</code> - computes the difference of two sets. Note that this operation is not commutative.</li> <li><code>disjointUnion(Set, Set) -&gt; Set</code> - computes the union of two sets. If the sets intersect, returns an error.</li> <li><code>contains(Set, T) -&gt; Bool</code> - checks if an element is in the set.</li> </ol> <pre><code>\nclassDiagram\n\n    class ISet~T~ {\n         &lt;&lt;Interface&gt;&gt;\n         new() Set\n         new(List) Set\n         size(Set) Nat\n         insert(Set, T) Set\n         union(Set, Set) Set\n         intersection(Set, Set) Set\n         difference(Set, Set) Set\n         disjointUnion(Set, Set) Set\n         contains(Set, T) Bool\n    }\n\n    class IList~T~ {\n         &lt;&lt;Interface&gt;&gt;\n    }\n\n    ISet &lt;|-- IList\n\n    ISet &lt;-- Set\n\n    IList &lt;-- List\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html#used-in","title":"Used in","text":"<ol> <li>Transaction</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/transaction_function_vm.html","title":"Transaction function vm","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.transaction_function_vm;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/transaction_function_vm.html#transaction-function-vm","title":"Transaction function VM","text":"<p>Transaction function VM is used to interpret transaction functions.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/transaction_function_vm.html#interface","title":"Interface","text":"<ul> <li><code>eval(TransactionFunction, GasLimit) -&gt; Transaction</code></li> </ul> <p>Examples: - nock (transparent-only; transaction function) - (?) cairo, risc0 (circuits)</p> <p>Todo</p> <p>are nock and cairo/risc0 on the same level? What exactly transaction functions look like in cairo/risk0 case? What about the relationship with proving systems?</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/arithmetic.html","title":"Arithmetic","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.arithmetic;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/arithmetic.html#arithmetic","title":"Arithmetic","text":"<p>Arithmetic fixed size type is a type of fixed size that additionally supports addition and subtraction.</p> <pre><code>\nclassDiagram\n    class FixedSize~T, Arg~ {\n         &lt;&lt;Interface&gt;&gt;\n         +bit_size: Int\n         +new(Arg) T\n         +equal(T, T) Bool\n    }\n\n    FixedSize &lt;|-- Arithmetic\n\n    class Arithmetic~T, Arg~ {\n        &lt;&lt;Interface&gt;&gt;\n        +add(T, T) T\n        +sub(T, T) T\n    }\n\n    Arithmetic &lt;|-- Quantity\n    Arithmetic &lt;|-- Balance\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/arithmetic.html#used-in","title":"Used in","text":"<ol> <li>Resource component: <code>quantity</code></li> <li><code>DeltaHash</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/delta_hash.html","title":"Delta hash","text":"<pre><code>module\narch.system.state.resource_machine.primitive_interfaces.fixed_size_type.delta_hash;\n\nimport prelude open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/delta_hash.html#delta-hash","title":"Delta hash","text":"<p>Delta hash is an interface that implements both <code>Hash</code> type and <code>Arithmetic</code> type. It is also required to be additively homomorphic and kind-distinct:</p> <ol> <li>For resources of the same kind \\(kind\\), \\(h_{\\Delta}\\) should be additively homomorphic: \\(\\Delta_1 + \\Delta_2 = h_{\\Delta}(kind, q_1) + h_{\\Delta}(kind, q_2) = h_{\\Delta}(kind, q_1 + q_2)\\)</li> </ol> <pre><code>--- A trait describing additive homomorphicity.\ntrait\ntype AdditivelyHomomorphic T :=\n  mkAdditivelyHomomorphic@{\n    --- Adds two types implementing the ;AdditivelyHomomorphic; trait.\n    add : (v1 v2 : T) -&gt; T;\n  };\n</code></pre> <pre><code>--- Implements the trait ;Eq; for ;AdditivelyHomomorphic; types.\nProperty-AdditivelyHomomorphic\n  {T} {{Eq T}} {{AdditivelyHomomorphic T}} (f : T -&gt; T) (v1 v2 : T) : Bool :=\n  f (AdditivelyHomomorphic.add v1 v2)\n    == AdditivelyHomomorphic.add (f v1) (f v2);\n</code></pre> <ol> <li>For resources of different kinds, \\(h_\\Delta\\) has to be computationally kind-distinct: if there exists \\(kind\\) and \\(q\\) s.t. \\(h_\\Delta(kind_1, q_1) + h_\\Delta(kind_2, q_2) = h_\\Delta(kind, q)\\), it is computationally infeasible to compute \\(kind\\) and \\(q\\).</li> </ol> <pre><code>--- A trait describing kind distinctness.\ntrait\ntype KindDistinct T :=\n  mkKindDistinct@{\n    --- Adds two types implementing the ;KindDistinct; trait.\n    add : (v1 v2 : T) -&gt; T;\n  };\n</code></pre> <p>Note</p> <p>An example of a function that satisfies these properties is the Pedersen commitment scheme: it is additively homomorphic, and its kind-distinctness property comes from the discrete logarithm assumption.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/delta_hash.html#used-in","title":"Used in","text":"<ol> <li>Resource delta</li> <li>Compliance unit delta</li> <li>Action delta</li> <li>Transaction delta</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html","title":"Interface","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.fixed_size_type;\nimport prelude open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html#fixed-size-type","title":"Fixed Size Type","text":"<pre><code>type FixedSize T :=\n  mkFixedSize@{\n    -- bit_size : Nat;\n    -- new : Arg -&gt; T;\n    -- equal : (T, T) Bool;\n  };\n</code></pre> <p>Fixed size type is a type, as the name suggests, of a fixed size. An example of such a type could be a prime field, unit32, or a string of a fixed size. An example of a type of not fixed size would be a list. All resource components and computable components are elements of a fixed size type. <p>The two child interfaces are arithmetic fixed size type - the fixed size type that supports addition and subtraction, and hash - the fixed size type for which the type derivation function <code>new(Arg)</code> is binding.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html#fixed-size-type-hierarchy-diagram","title":"Fixed size type hierarchy diagram","text":"<pre><code>\nclassDiagram\n    class FixedSize~T, Arg~ {\n         &lt;&lt;Interface&gt;&gt;\n         +bit_size: Int\n         +new(Arg) T\n         +equal(T, T) Bool\n    }\n\n    FixedSize &lt;|-- Nonce\n    FixedSize &lt;|-- RandSeed\n    FixedSize &lt;|-- NullifierKeyCommitment\n    FixedSize &lt;|-- NullifierKey\n\n    FixedSize &lt;|-- Arithmetic\n    FixedSize &lt;|-- Hash\n\n\n    note for Hash \"fixed size types that are binding (to Arg) and collision resistant\"\n    class Hash~T, Arg~ {\n        &lt;&lt;Interface&gt;&gt;\n    }\n\n    class Arithmetic~T, Arg~ {\n        &lt;&lt;Interface&gt;&gt;\n        +add(T, T) T\n        +sub(T, T) T\n    }\n\n    Hash &lt;|-- DeltaHash\n    Arithmetic &lt;|-- DeltaHash\n\n    note for DeltaHash \"additively homomorphic and kind-distnict\"\n    class DeltaHash {\n        &lt;&lt;Interface&gt;&gt;\n    }\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html#used-in-raw","title":"Used in (raw)","text":"<ol> <li> <p>Resource components:</p> <ol> <li><code>randSeed</code></li> <li><code>nonce</code></li> <li><code>nullifierKeyCommitment</code></li> </ol> </li> <li> <p><code>nullifierKey</code></p> </li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html","title":"Hash","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.hash;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html#hash","title":"Hash","text":"<p>Hash type is defined as a fixed size type that is binding, meaning that if the input value of type <code>Arg</code> changed, the output value would change as well.</p> <p>In the context of hashes, we say <code>a</code> is an opening of a hash <code>h: Hash</code> if <code>h = hash(a)</code>.</p> <p>Todo</p> <ol> <li>for shielded: cryptographic hash, hiding</li> <li>do we want a separate interface for the logic hash, given it is a verifier key? UPD in Taiga we had the verifier key hashed. Is it fixed size? If not, what was the reason for tripple hashing? vk + hash + function privacy commitment</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html#hash-interface-diagram","title":"Hash interface diagram","text":"<pre><code>\nclassDiagram\n\n    class Hash~T, Arg~ {\n         &lt;&lt;Interface&gt;&gt;\n    }\n\n    Hash &lt;|-- LogicVKCompact\n    Hash &lt;|-- LabelHash\n    Hash &lt;|-- ValueHash\n\n    Hash &lt;|-- Commitment\n    Hash &lt;|-- Nullifier\n    Hash &lt;|-- Kind\n    Hash &lt;|-- DeltaHash\n    Hash &lt;|-- LogicVKOuterHash\n    Hash &lt;|-- MerkleTreeNodeHash\n\n    Hash &lt;|-- AppDataValueHash\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html#used-in","title":"Used in","text":"<ol> <li> <p>Resource components:</p> <ol> <li><code>logicRef</code></li> <li><code>labelRef</code></li> <li><code>valueRef</code></li> </ol> </li> <li> <p>Resource computable components:</p> <ol> <li><code>commitment</code></li> <li><code>nullifier</code></li> <li><code>kind</code></li> <li><code>delta</code></li> </ol> </li> <li> <p>Computing Merkle tree nodes and roots</p> </li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#proving-system","title":"Proving system","text":"<p>Todo</p> <p>add efficiency expectations (what to prioritise)</p> <p>The resource machine differentiates between three kinds of proofs, each of which can have a distinct proving system used to produce that sort of proofs:</p> <ol> <li>resource logic proofs</li> <li>compliance proofs</li> <li>delta proofs</li> </ol> Execution context Constraints defined by Are the constraints public by default? Meaning Resource logic proof Action Application No Action is compliant with the application constraints Compliance proof Compliance unit RM instance Yes Action (partitioned into compliance units) is compliant with the RM rules Delta proof Transaction RM interface Yes Transaction is balanced <p>Every proof has three types of inputs and constraints:</p> <ol> <li>Architecture-level inputs and constraints. This type of inputs and constraints allow to enforce certain resource machine properties and have to be present in each resource logic, no matter in the context of which instantiation and application the resource logic was produced. These contraints ensure basic resource machine properties.</li> <li>Instantiation-level inputs and constraints. These inputs and constraints must be present in every resource logic compatible with a concrete resource machine instantiation but might not be required by other instantiations. These constraints ensure additional resource machine properties desired by the instantiation.</li> <li>Application-level (custom) inputs and constraints that are present in every resource logic specified by a concrete application. These constraints define how the application works.</li> </ol> <p>This specification explicitly defines only the architecture-level inputs and constraints. Only application-level constraints are referred to as custom.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#proving-system-requirements","title":"Proving system requirements","text":"<p>The first two kinds of proofs, resource logic proofs and compliance proofs, follow the standard proving system interface defined here. The delta proof has an additional functionality required and is further described here.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#resource-logic-proving-system-choice","title":"Resource logic proving system choice","text":"<p>Resource logic proof is the most common proof type. Each action that modifies the state of <code>n</code> resources (creates or consumes) has at least <code>n</code> resource logic proofs attached to it. In principle, the predicate checked with each proof can be different for all <code>n</code> proofs. For that reason, the proving system of choice should support easy proof instantiation process for new predicates (e.g., a SNARK that requires a trusted setup ceremony initiated for every predicate is probably not the most efficient choice for this proving system).</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#compliance-proving-system-choice","title":"Compliance proving system choice","text":"<p>Compliance constraints are fixed per RM instantiation, meaning that the predicate being checked is the same for each compliance unit, with only the instance and witness being different each time. For that reason, a proving system that prioritises efficiency for a single predicate over the ease of creating proofs for new predicates might be more suitable.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#proving-system-hierarchy","title":"Proving system hierarchy","text":"<p>The diagram below describes the relationships between the proving system and delta proof interfaces and their instantiations that correspond to the proving system for each proof type.</p> <pre><code>---\ntitle: Proving System hierarchy\n---\nclassDiagram\n    class IProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n         +prove(ProvingKey, Instance, Witness) Proof\n         +verify(VerifyingKey, Instance, Proof) Bool\n    }\n\n    IProvingSystem &lt;|-- ResourceLogicProvingSystem\n    IProvingSystem &lt;|-- ComplianceProvingSystem\n    IProvingSystem &lt;|-- IDeltaProvingSystem\n\n    class ResourceLogicProvingSystem\n    class ComplianceProvingSystem\n\n    class IDeltaProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n        +aggregate(Proof, Proof) Proof\n    }\n    IDeltaProvingSystem &lt;|-- DeltaProvingSystem\n\n    class DeltaProvingSystem\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_delta.html","title":"Delta proving system","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_delta;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_delta.html#delta-proving-system","title":"Delta Proving System","text":"<p>Delta proving system is used to prove that the transaction delta is equal to a certain value. To support transaction composition that results in a new transaction being produced, the delta proving system must, in addition to the standard proving system interface, provide a proof aggregation function:</p> <p><code>DeltaProvingSystem</code>:</p> <ol> <li><code>prove(PS.ProvingKey, PS.Instance, PS.Witness) -&gt; PS.Proof</code></li> <li><code>verify(PS.VerifyingKey, PS.Instance, PS.Proof) -&gt; Bool</code></li> <li><code>aggregate(PS.Proof, PS.Proof) -&gt; PS.Proof</code></li> </ol> <p>The aggregation function allows to aggregate proofs in a way that if \\(\\pi_1\\) proves that the first transaction's balance is \\(b_1\\) and the second proof \\(\\pi_2\\) proves the second transaction's balance is \\(b_2\\), then the proof \\(Aggregate(\\pi_1, \\pi_2)\\) proves that the composed transaction's balance is \\(b_1 + b_2\\).</p> <pre><code>---\ntitle: Proving System hierarchy\n---\nclassDiagram\n    class IProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n         +prove(ProvingKey, Instance, Witness) Proof\n         +verify(VerifyingKey, Instance, Proof) Bool\n    }\n\n    IProvingSystem &lt;|-- IDeltaProvingSystem\n\n    class IDeltaProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n        +aggregate(Proof, Proof) Proof\n    }\n    IDeltaProvingSystem &lt;|-- DeltaProvingSystem\n\n    class DeltaProvingSystem\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html","title":"Definitions","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_types;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html#proving-system-definition","title":"Proving system definition","text":"<p>We define a set of structures required to define a proving system \\(PS\\) as follows:</p> <ul> <li>Proof \\(\\pi: PS.Proof\\) - proves that a specific statement <code>f</code> with the inputs <code>x</code> and <code>w</code> evaluates to <code>True</code>.</li> <li>Instance \\(x: PS.Instance\\) is the ordered input data structure used to produce and verify a proof.</li> <li>Witness \\(w: PS.Witness\\) is the ordered input data structure used to produce (but not verify) a proof.</li> <li>Proving key \\(pk: PS.ProvingKey\\) contains the data required to produce a proof for a pair \\((x, w)\\). Specific to a particular statement (different statements <code>f</code> and <code>f'</code> imply different proving keys) being proven, but doesn't depend on the inputs.</li> <li>Verifying key \\(vk: PS.VerifyingKey\\) contains the data required, along with the instance \\(x\\), to verify a proof \\(\\pi\\). Specific to a particular statement being proven (different statements <code>f</code> and <code>f'</code> imply different verifying keys), but doesn't depend on the inputs. The verifying key is assumed to be of fixed size.</li> </ul> <p>A proving system \\(PS\\) consists of a pair of algorithms, \\((Prove, Verify)\\):</p> <ul> <li>\\(Prove(pk, x, w): PS.ProvingKey \\times PS.Instance \\times PS.Witness \\rightarrow PS.Proof\\)</li> <li>\\(Verify(vk, x, \\pi): PS.VerifyingKey \\times PS.Instance \\times PS.Proof \\rightarrow Bool\\).</li> </ul> <p>Note</p> <p>To verify a proof created for instance <code>x</code>, the same instance <code>x</code> must be used. For instances that contain elements of the same type, the order of the elements must be preserved.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html#properties","title":"Properties","text":"<p>A proving system must have the following properties:</p> <ul> <li>Completeness: it must be possible to make a proof for a statement which is true.</li> <li>Soundness: it must not be possible to make a proof for a statement which is false.</li> </ul> <p>For a statement <code>f</code>, <code>Verify(vk, x, proof) = True</code> implies that <code>f x w = True</code> and <code>Verify(vk, x, proof) = False</code> implies that <code>f x w = False</code>.</p> <p>Certain proving systems may also be zero-knowledge, meaning that the produced proofs reveal no information other than their own validity.</p> <p>A proof \\(\\pi\\) for which \\(Verify(pr) = True\\) is considered valid.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html#common-proving-scheme-types","title":"Common proving scheme types","text":"<ul> <li>The trivial scheme is one where computation is simply replicated. The   trivial scheme is defined as <code>verify(predicate, x, _) = predicate x</code>. It has no extra security assumptions but is not succinct. In this case, all of the data is used for both proving and verifying and witness and proof has unit type <code>()</code>.</li> </ul> <ul> <li>The trusted delegation scheme is one where computation is delegated to a   known, trusted party whose work is not checked. The trusted delegation scheme   is defined as <code>verify((predicate, pk), x, sig) = checkSignature pk (predicate, x) sig</code>, where the trusted party is assumed to produce such a   signature only if <code>predicate x = True</code>. This scheme is succinct but requires a   trusted party assumption (which could be generalised to a threshold quorum in   the obvious way). Note that since the computation is still verifiable, a   signer of <code>(predicate, x)</code> where <code>predicate x = False</code> could be held   accountable by anyone else who later evaluated the predicate. In this case witness also has unit type and the proof has the type <code>Signature</code>.</li> </ul> <ul> <li>The succinct proof-of-knowledge scheme is one where the result of computation is attested to with a cryptographic proof (of the sort commonly instantiated by modern-day SNARKs &amp; STARKs). Succinct proof-of-knowledge schemes provide succinctness as well as verifiability subject to the scheme-specific cryptographic assumptions. They may also possibly be zero-knowledge, in which the verifier learns nothing other than <code>predicate x w = True</code> (in this case, and in others, <code>w</code> will be \"hidden\" with hash functions and <code>x</code> will remain public (and include the hiding representations of <code>w</code>), such that the verifier knows only <code>hash w</code> and <code>x</code> but the substance of the relation obtains over the preimages).</li> </ul> <p>Assuming the proving system is used to verify that a predicate evaluated on its inputs returns <code>True</code>, the table below describes what each parameter will be for each of the three common proving system instantiations:</p> Proving key Verifying key Instance (x) Witness (w) Proof Properties Trivial scheme hash of the predicate hash of the predicate predicate's arguments, predicate () () transparent, not succinct Trusted delegation hash of the predicate + signing key hash of the predicate + signature verifying key predicate's arguments, predicate () signature succinct, trusted, verifiable Succinct PoK defined by the scheme (incl. predicate representation) defined by the scheme public input private input defined by the scheme succinct, verifiable, possibly zero knowledge <p>Note</p> <p>In the trivial scheme, verification requires the pre-images of the verifying key / instance hashes. In the trusted delegation case, the pre-images are not required if the signature is produced over the hashed values.</p> <p>Note</p> <p>Proving-related data structures described further are written with a PoK proving system in mind. For a transparent system, all values that are marked as witness in the specification shouldn't be discarded but rather moved to instance.</p> <p>Note</p> <p>For application developers: writing applications that can work with all types of proving systems can be challenging since different proof types require different argument split between instance and witness (e.g., trivial scheme, unlike succinct PoK, expects no witness). The current solution is to write applications with succinct PoK types of proving systems in mind, which then can be translated to other proving systems by moving witness arguments to instance.</p>","boost":2},{"location":"arch/system/state/shielded_resource_machine/index.html","title":"Shielded resource machine","text":"<p>This section of the Anoma specification describes the design of the shielded resource machine (SRM). Shielded resource machine as a class of resource machines is designed to offer privacy properties to its users.</p> <p>This specification contains both the description of the design enabling the privacy properties and the concrete primitives used to instantiate a shielded resource machine. In principle, different primitives can be used to implement the same design. When more versions of SRM exist, we might separate the two parts: general SRM considerations and concrete instantiation primitives.</p>"},{"location":"arch/system/state/shielded_resource_machine/index.html#risc0-shielded-resource-machine","title":"Risc0 shielded resource machine","text":"<p>Out first implementation of the shielded resource machine is referred to as risc0 RM. It is called that because we use RISC Zero zkVM to represent the compliance and logic circuits. More about RISC Zero and how we use it can be found here</p>"},{"location":"arch/system/state/shielded_resource_machine/index.html#general-rm-spec-divergence","title":"General RM spec divergence","text":"<p>All resource machines must comply with the general resource machine specification. However, certain properties of the current abstract design might be less practical or realistic for concrete designs. Developing the abstraction and concrete instantiations that have various properties at the same time allows us to discover the flaws in the abstraction. Our long-term goal is to develop an abstraction s.t. different resource machine flavours can interoperate seamlessly. Until then, this section contains an explicit list of discrepancies with the abstract resource machine specification:</p> Context Description Proving Instance is not a part of the input arguments to the <code>prove()</code> function. It is the output of it Balance Only balanced transactions can have valid delta proofs, i.e. <code>expectedBalance = 0</code>. Delta We do not have explicit proving and verifying keys for delta proofs Logic private inputs Not all resources from the same action must be passed as private input to logics. Only relevant resource objects are passed. Note that the action tree contains all resources in the action and the root of the tree is passed as public input. Compliance proof Compliance proving and verifying keys are hardcoded in the library and are not passed explicitly as input Variable size parameters This field is not present. This is currently irrelevant."},{"location":"arch/system/state/shielded_resource_machine/index.html#intended-privacy-properties","title":"Intended privacy properties","text":"<p>This instantiation is designed to offer privacy properties to its users. In particular, the current design offers data privacy and is accommodated to offer function privacy. Data privacy refers to the privacy of the user identity and the encrypted transaction content. Function privacy means privacy of asset types involved in the transaction. Zero-knowledge proofs and encryption are used to provide data privacy: users prove correctness of the state transition in zk. Nullifier and commitment of the same resource must not be linkable: given a nullifier, it is impossible to figure out which commitment corresponds to the same resource having access only to public global state.</p>"},{"location":"arch/system/state/shielded_resource_machine/action.html","title":"Action","text":""},{"location":"arch/system/state/shielded_resource_machine/action.html#action-trees","title":"Action trees","text":"<p>The tags of all resources in the action are organized in an action tree. The root of the tree is passed as a part of an instance to each logic associated with the action, and when a resource object is passed in the witness, we verify inclusion of the corresponding tag in the tree.</p> <p>The depth of the action tree depends on the number of resources in the action. The tree parameters are the same as for the commitment tree.</p>"},{"location":"arch/system/state/shielded_resource_machine/action.html#resource-logic-constraints","title":"Resource logic constraints","text":"<p>Currently there is no way to enforce the presence of any constraints in a resource logic since resource logics are designed by application developers. The constraints that nevertheless have to be present in resource logics for safety reasons are:</p> <ol> <li>Ensuring the correspondence of the instance and witness. Specifically, the corresponsence of resource tags and examined resource objects.</li> <li>If in-band encryption is used, verifying the correctness of the encryption.</li> <li>Verifying the tag existence in the action tree.</li> </ol> <p>Since this cannot be included automatically, users must make sure the applications they use have these checks present.</p>"},{"location":"arch/system/state/shielded_resource_machine/compliance.html","title":"Compliance","text":"<p>Each compliance unit contains one consumed and one created resource. The resources in the compliance unit are bound to each other: the nonce of the created resource is the nullifier of the consumed resource. This allows to ensure uniqueness of the created resource commitment.</p>"},{"location":"arch/system/state/shielded_resource_machine/global_state.html","title":"Global state","text":"<p>The global replicated state includes the commitment accumulator that contains commitments of all created resources and a nullifier set that contains nullifiers of all consumed resources. The commitment tree is currently instantiated as a Merkle tree of variable depth.</p>"},{"location":"arch/system/state/shielded_resource_machine/global_state.html#commitment-tree-parameters","title":"Commitment tree parameters","text":"Parameter Instantiation Intermediate node <code>SHA256</code> Leaf <code>SHA256</code> (resource commitment) Depth Variable"},{"location":"arch/system/state/shielded_resource_machine/global_state.html#variable-depth-merkle-tree","title":"Variable depth Merkle tree","text":"<p>RISC Zero zkVM allows to pass arguments of variable size (vectors) as private or public input to the circuit without changing the proving and verifying keys of the circuit. Changing proving and verifying keys of circuits is equivalent to changing the circuit and is undesirable (unless there is a good reason for it).</p> <p>Therefore, this feature of RISC Zero zkVM is particularly useful for passing Merkle paths of variable length to the circuits. It allows having Merkle trees of variable size, which can be helpful to decrease the cost of the computation (the tree size is minimal necessary to accommodate the elements stored) and, in principle, to grow unbounded.</p> <p>We also utilise this feature to have variable depth action trees.</p>"},{"location":"arch/system/state/shielded_resource_machine/resource.html","title":"Resource","text":""},{"location":"arch/system/state/shielded_resource_machine/resource.html#resource-structure","title":"Resource Structure","text":"Component Description Formula <code>logicRef</code> Logic reference is a verifying key of the logic circuit. Risc0 verifying keys are SHA256 hashes. <code>labelRef</code> Fixed size binding commitment to the label. \\(SHA256(label)\\) <code>valueRef</code> Fixed size binding commitment to the value. \\(SHA256(value)\\) <code>quantity</code> <code>u128</code> <code>isEphemeral</code> <code>Bool</code> <code>nonce</code> Guarantees the uniqueness of the commitment and nullifier. Computed from the nullifier of the resource consumed in the same compliance unit. \\(nonce_{created} = nf_{consumed}\\) <code>nullifierKeyCommitment</code> More details can be found here \\(cnk = SHA256(nk)\\) <code>randSeed</code> Generated randomly when the resource is created <code>kind</code> \\(kind = SHA256(logicRef \\|\\| labelRef)\\) <code>psi</code> A parameter used to compute the resource nullifier \\(psi = SHA256(\"RISC0\\_ExpandSeed\" \\|\\| 0 \\|\\| randSeed \\|\\| nonce)\\) Resource commitment randomness <code>rcm</code> Ensures hiding properties of the resource commitment \\(rcm = SHA256(\"RISC0\\_ExpandSeed\" \\|\\| 1 \\|\\| randSeed \\|\\| nonce)\\) Resource commitment <code>cm</code> Unique identifier of a created resource \\(cm = SHA256(logicRef, labelRef, valueRef,\\) \\(quantity, isEphemeral, nonce\\)\\(, nullifierKeyCommitment, rcm)\\) Resource nullifier <code>nf</code> Unique identifier of a consumed resource \\(nf = SHA256(nk, nonce, psi, cm)\\) <code>tag</code> <code>cm</code> for created resources, <code>nf</code> for consumed resources"},{"location":"arch/system/state/shielded_resource_machine/resource.html#ephemeral-resources","title":"Ephemeral resources","text":"<p>Ephemeral resources are different from the persistent ones in that we don't verify the Merkle path for their existence. Therefore, ephemeral resources can be consumed even if they were not created.</p> <p>In every other aspect they are treated the same: the commitment is added to the commitment accumulator, the nullifier is added to the nullifier set.</p> <p>Ephemeral resources of 0 value can be used to include additional constraints in the transaction. Ephemeral resources of non-zero value can be used to carry intents. Ephemeral resources are also used as padding resources when needed. They can be used for other purposes intended by the application.</p>"},{"location":"arch/system/state/shielded_resource_machine/features/function_privacy.html","title":"Function privacy","text":"<p>Shielded resource machines may provide function privacy as a feature. When enabled, it allows to replace the RL verifying key by a fixed value. This allows to hide the RL verifying key and therefore the application it is associated with. Function privacy can be enabled for each resource in the transaction individually.</p> <p>The idea is to verify the RL proof recursively in another circuit with a fixed verifying key. The outer circuit calls <code>verify(..)</code> function for the RL proof and checks that it returns <code>True</code>. It takes as input RL proof, RL instance, and other fields.</p> <p>Enabling function privacy requires a couple more constraints to be verified. The relevant fields, functions, and constraints are described below.</p>"},{"location":"arch/system/state/shielded_resource_machine/features/function_privacy.html#relevant-fields","title":"Relevant fields","text":"Context Field Description Resource object <code>logicRef</code> Contains the hash of the verifying key of the logic the resource is associated with. Action <code>verifyingKey</code> Contains the key used to verify the resource logic of the corresponding resource. Action <code>logicVKOuterHash</code> Contains the commitment to the <code>logicRef</code>"},{"location":"arch/system/state/shielded_resource_machine/features/function_privacy.html#relevant-functions","title":"Relevant functions","text":"Function Description <code>logicRefHash</code> used to compute <code>logicRef</code> from <code>logicVK</code>. It is used for compression. For the systems where <code>logicVK</code> is already a hash, <code>logicRefHash</code> can be an identity function <code>logicVKOuterHash</code> commitment scheme used to produce the corresponding instance field. In the data privacy case, it is identity function. In the function privacy case, it has to be hiding and binding"},{"location":"arch/system/state/shielded_resource_machine/features/function_privacy.html#relevant-constraints","title":"Relevant constraints","text":"<ol> <li>Compliance proof: <code>logicVKOuterHash</code> is correctly computed from <code>logicRef</code>.</li> <li>Out-of-compliance checks:<p>1. <code>logicVKOuterHash</code> commits to <code>logicVK</code></p> <p>2. <code>verify(verifyingKey, logicInstance, proof) = True</code> (here <code>logicInstance</code> is assembled from the relevant <code>applicationData</code> and other action fields, such as commitments and nullifiers)</p> </li> </ol>"},{"location":"arch/system/state/shielded_resource_machine/features/function_privacy.html#comparing-data-and-function-privacy","title":"Comparing data and function privacy","text":"Data Privacy Function Privacy Action <code>verifyingKey</code> <code>logicVK</code>(variable) <code>outerVK</code> (fixed) outer hash instantiation identity function hiding and binding commitment scheme <code>logicRef</code> check out of circuit in the outer circuit <code>verify(logicVK,...)</code> out of circuit in the outer circuit verifier calls <code>verify(logicVK, logicInstance, proof)</code> <code>verify(outerVK, outerInstance, proof)</code>"},{"location":"arch/system/state/shielded_resource_machine/keys/index.html","title":"Keys","text":"<p>Resource machine assumes various keys used by the user for different purposes. The table below lists all of these keys.</p> Name Derivation Description Lifetime Identity key pair \\((idsk, idpk)\\) \\(idsk \\xleftarrow{R} \\mathbb{F}_p, idpk = [idsk] * G\\) This static key pair serves as the user's identity. It is used to authorise actions. Forever Nullifier key, nullifier key commitment \\((nk, cnk)\\) \\(nk \\xleftarrow{R} \\mathbb{F}_p, cnk = PRF(nk)\\) These keys are used to reflect the right to nullify Forever, but can be periodically rotated in the identity lifetime Static encryption key pair \\((sesk, sepk)\\) \\(sesk \\xleftarrow{R} \\mathbb{F}_p, sepk = [sesk] * G\\) This static key pair is used to produce resource encryption keys Forever, but should be periodically rotated for forward secrecy Static discovery key pair \\((sdsk, sdpk)\\) \\(sdsk \\xleftarrow{R} \\mathbb{F}_p, sdpk = [sdsk] * G\\) This static key pair is used to produce discovery encryption keys Forever, but should be periodically rotated for forward secrecy Ephemeral encryption key pair \\((eesk, eepk)\\) \\(eesk \\xleftarrow{R} \\mathbb{F}_p, eepk = [eesk]*P\\) Ephemeral encryption key pair generated by the sender. Used to derive the resource encryption key Transaction \\(rek\\) \\(rek = KDF(DH(sepk, eesk), eepk)\\) \\(= KDF(DH(sesk, eepk), eepk)\\) Resource symmetric encryption key. Used to encrypt the transmitted resource object Transaction Ephemeral discovery key pair \\((edsk, edpk)\\) \\(edsk \\xleftarrow{R} \\mathbb{F}_p, edpk = [edsk]*P\\) Ephemeral discovery key pair generated by the sender. Used to derive the discovery encryption key Transaction Discovery encryption key \\(dek\\) \\(dek = KDF(DH(sdpk, edsk), edpk)\\) \\(= KDF(DH(sdsk, edpk), edpk)\\) Discovery symmetric encryption key. Used to encrypt the discovery message Transaction <p>Encryption keys are used for in-band distribution of resources. Discovery keys are used for faster discovery of the distributed resources.</p>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html","title":"Resource discovery","text":"<p>Resources that are distributed in-band have to be discovered by the receiver. The simplest way to do that is to trial decrypt every transaction, which can be computationally expensive for the user. The user can delegate this task to a more computationally powerful entity, which makes it more efficient, but less secure for the user. One way to improve the security properties of delegated discovery is to introduce a discovery plaintext that can be used to discover transactions without decrypting the resource plaintext.</p>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html#simple-discovery","title":"Simple discovery","text":"<p>A simple discovery mechanism duplicates the resource encryption mechanism but encrypts a fixed string. The discovery server knows that a message is sent to the user if the decrypted message is equal to the expected string.</p>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html#discovery-mechanism","title":"Discovery mechanism","text":"<p>Each potential receiver has a static discovery key pair. To enable faster discovery for the message, the sender:</p> <ol> <li>generates an ephemeral discovery key pair \\((edsk, edpk)\\)</li> <li>using the receiver's static discovery public key, generates the discovery encryption key \\(dek = KDF(DH(sdpk_{R}, edsk_{S}), edpk_{S})\\)</li> <li>encrypts a fixed string <code>ds</code> \\(cd = Encrypt(dek, ds)\\) and includes the discovery message in the transaction payload: <code>discoveryPayload = [(cd, edpk_{S})]</code></li> </ol>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html#discovery","title":"Discovery","text":"<p>Given the relevant key \\(sdsk\\) by the potential receiver, the discovery server tries to decrypt each discovery message for each published transaction:</p> <ol> <li>using an ephemeral key attached to the payload, they generate the discovery encryption key \\(dek = KDF(DH(sdsk_{R}, edpk_{S}), edpk{S})\\)</li> <li>they decrypt a discovery string \\(ds = Decrypt(dek, cd)\\)</li> <li>if <code>ds</code> is equal to the expected value, the transaction is sent to the user. The user can decrypt the resource payload to get the resource sent to them.</li> </ol>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html#resource-decryption","title":"Resource decryption","text":"<p>To decrypt a resource, the user:</p> <ol> <li>using an ephemeral key attached to the payload, they generate the resource encryption key \\(rek = KDF(DH(sesk_{R}, eepk_{S}), eepk{S})\\)</li> <li>they decrypt the resource object \\(resource = Decrypt(rek, ce)\\)</li> </ol>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html#verifiable-discovery","title":"Verifiable discovery","text":"<p>In principle, discovery mechanism is vulnerable to the same issue as the verifiable encryption mechanism and should be verified, but we do not verify discovery payload for efficiency. The only consequence of a malicious action would be that the intended receiver will receive the message later (after the full discovery process discovers the message).</p>"},{"location":"arch/system/state/shielded_resource_machine/keys/discovery.html#instantiations","title":"Instantiations","text":"<p>Same as for resource encryption.</p> Function Instantiation Encryption algorithm AES256-GCM KDF SHA256"},{"location":"arch/system/state/shielded_resource_machine/keys/encryption.html","title":"Verifiable encryption","text":"<p>Resource objects are encrypted and included in the transaction to enable in-band distribution of resources. Encrypted resources are stored on the blockchain, the receiver can scan the blockchain, trying to decrypt the transactions, to find the resources that were sent to them.</p> <p>We want the encryption to be verifiable to make sure the receiver of the resources can decrypt them. In systems like Zcash the sender and the creator of the resource are usually the same entity, and it doesn't make sense for the sender to send a corrupted message to the receiver (essentially burning the resource), therefore, no need to verify correctness of the encryption. In our case, the resources are sent by users, but often created by solvers, and we need to make sure that the solvers correctly encrypt the resources.</p> <p>Not all of the resource-related fields have to be encrypted (e.g. the resource commitment), and the encrypted fields may vary depending on the application. To make sure it is flexible enough, the encryption check is performed in RL circuits (as opposed to verifying the encryption in the compliance circuit).</p>"},{"location":"arch/system/state/shielded_resource_machine/keys/encryption.html#encryption-algorithm","title":"Encryption algorithm","text":"<p>Each potential receiver has a static encryption key pair. To send a resource to a user, the sender:</p> <ol> <li>generates an ephemeral encryption key pair \\((eesk, eepk)\\)</li> <li>using the receiver's static encrypion public key, generates the resource encryption key \\(rek = KDF(DH(sepk_{R}, eesk_{S}), eepk_{S})\\)</li> <li>encrypts the resource \\(ce = Encrypt(rek, resource)\\) and includes the encrypted message in the transaction payload: <code>resourcePayload = [(ce, eepk_{S})]</code></li> </ol> <p>The receiver has to discover the message sent to them and then decrypt it, inverting the process above.</p>"},{"location":"arch/system/state/shielded_resource_machine/keys/encryption.html#instantiations","title":"Instantiations","text":"Function Instantiation Encryption algorithm AES256-GCM KDF SHA256"},{"location":"arch/system/state/shielded_resource_machine/proving/index.html","title":"Proving systems","text":"<p>The table below describes what proving system we use to instantiate which proof type.</p> RM Statement Representation Proof type Compliance [Risc0 circuit] STARK/Groth16 Logic [Risc0 circuit] STARK/Groth16 Delta [Binding signature] ECDSA <p>We differentiate between two kinds of proofs depending on how closely they interact with sensitive data:</p> <ol> <li>Raw RM proofs - the proofs produced directly by RM for each transaction. Include compliance proofs, logic proofs, and delta proofs.</li> <li>Aggregated proof - combines the raw RM proofs into a fixed number of proofs per transaction. Currently, aggregation results in two proofs per transaction: aggregated SNARK proofs and a delta proof (untouched).</li> </ol> Proof stage Scope Raw proofs Action (logic), compliance unit (compliance), transaction (delta) Aggregated proofs Single transaction"},{"location":"arch/system/state/shielded_resource_machine/proving/delta.html","title":"Delta Proving System","text":"<p>Delta proving system is instantiated with a binding signature. The design of it is based on Zcash binding signature (Zcash Specification, section 4.13), but we extend it to support multiple resource kinds. In binding signature design, the correctness of the balance is proven by the ability to generate the correct signing and verifying keys, the signed message itself plays a secondary role.</p>"},{"location":"arch/system/state/shielded_resource_machine/proving/delta.html#binding-signature","title":"Binding signature","text":""},{"location":"arch/system/state/shielded_resource_machine/proving/delta.html#computing-delta-in-compliance-units","title":"Computing delta in compliance units","text":"<p>Each compliance unit takes one input and one output resource, the compliance unit delta is computed as: <code>complianceDelta = inputResource.delta() - outputResource.delta()</code>. Resource delta is computed as\u00a0<code>r.delta() = PedersenCommit(r.quantity, r.kind(), rcv) = r.quantity * r.kind() + rcv * blindBase</code> where:</p> <ol> <li><code>*</code> is a scalar multiplication EC operation</li> <li><code>r.quantity</code> and <code>rcv</code> are scalars</li> <li><code>r.kind()</code> and <code>blindBase</code> are EC points</li> <li><code>rcv</code> is random, <code>blindBase</code> is fixed</li> </ol> <p>Computing compliance delta from resource deltas is equivalent to computing compliance delta from resource object components directly (i.e., skipping the individual resource delta computation). In practice, we do not compute individual resource deltas. Instead, we compute compliance delta as:  <code>complianceDelta = inputResource.quantity * inputResource.kind() - outputResource.quantity * outputResource.kind() + rcv * blindBase</code></p>"},{"location":"arch/system/state/shielded_resource_machine/proving/delta.html#the-mechanism-single-kind","title":"The mechanism (single kind)","text":"<ol> <li>Binding signature signing key is computed by adding commitment randomness <code>rcv</code> from all compliance units in the transaction: \\(bsk = \\sum{rcv}\\). Note that <code>rcv</code> are secret values. - Verifying key is computed by adding compliance unit deltas together: \\(bvk=\\sum{\\delta_{compliance}}\\). Note that \\(\\delta_{compliance}\\) are public values - anyone can compute binding signature verifying key.</li> <li> <p>For correctly computed <code>bvk</code> and <code>bsk</code> , <code>bvk = bsk * blindBase</code> since individual balances add to 0, which proves that:</p> <ol> <li>the signer knows <code>rcv</code> used to compute compliance deltas</li> <li>the transaction balances to 0 - otherwise, <code>bvk = bsk * blindBase</code> wouldn\u2019t be true and the signature wouldn\u2019t verify</li> </ol> </li> </ol>"},{"location":"arch/system/state/shielded_resource_machine/proving/delta.html#extending-to-multiple-kinds","title":"Extending to multiple kinds","text":"<p>Because of how elliptic curves work (kind distinctness holds), having multiple kinds in the same binding signature is equivalent to having multiple binding signatures per each kind. Note that it is all possible because we expect everything balance to 0.</p>"},{"location":"arch/system/state/shielded_resource_machine/proving/delta.html#instantiation","title":"Instantiation","text":"Parameter Instantiation Signature scheme ECDSA Elliptic curve k256 Hash function Keccak256 Signed message Tags of resources included in the transaction Prove() ECDSA.sign(pk, keccak256(message)) Verify() ECDSA.verify(vk, proof)"},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html","title":"Proof aggregation","text":"<p>An aggregation proof attests to the validity of all compliance and logic proofs of an RM transaction. With aggregation, the raw RM proofs (except the delta proof) do not need to be stored in the transaction structure. Reducing thereby verification time and transaction size.</p>"},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html#aggregation-inputs","title":"Aggregation inputs","text":""},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html#witness","title":"Witness","text":"<ul> <li>the list of compliance proofs of the RM transaction,</li> <li>the list of logic proofs of the RM transaction.</li> </ul>"},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html#instance","title":"Instance","text":"<ul> <li>the compliance verifying key,</li> <li>The list of logic verifying keys of the RM transaction,</li> <li>The list of compliance instances of the RM transaction,</li> <li>The list of logic instances of the RM transaction.</li> </ul> <p>Note</p> <p>Passing the raw proofs as witnesses means they are not needed to verify the aggregation proof. This is what allows to remove them from the RM transaction.</p> <p>Note</p> <p>The verifier must be aware of what has been verified by the prover during aggregation. That is why we include the raw verifying keys and raw instances. However, they do not need to appear explicitly. A binding (and possibly short) commitment suffices.</p>"},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html#aggregation-constraints","title":"Aggregation constraints","text":"<p>An aggregation circuit must check the following: 1. Verify each compliance proof against its corresponding compliance instance using the compliance verifying key. 2. Verify each logic proof against its corresponding logic instance using the corresponding logic verifying key. 3. Possibly, other aggregation-specific constraints (which depends on the aggregation strategy implemented).</p>"},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html#aggregation-strategies","title":"Aggregation strategies","text":"<p>Batch aggregation. All compliance and logic proofs of an RM transaction are verified in a single run of the aggregation program. The batch aggregation instance is exactly the list of compliance and logic verifying keys and instances present in the RM transaction.</p> <p>Sequential aggregation. The aggregation is an incrementally verified computation (IVC). At each step, a single raw proof (either compliance or logic proof) is verified against a passed instance and verifying key. To keep track of the instances and keys verified at previous steps, they are accumulated in a chained hash. Correct accumulation is also enforced. The sequential aggregation instance is the hash of all compliance and logic verifying keys and instances of the RM transaction.</p> <p>Note</p> <p>The sequential aggregation is an example of proof-carrying data (PCD) computation. PCD-based aggregation can be distributed across mutually untrusted nodes, and proofs to be aggregated arbitrarily grouped and arranged in different transcripts. Parallel proving at the ARM level would be possible with a tree-like transcript.</p>"},{"location":"arch/system/state/shielded_resource_machine/proving/proof_aggregation.html#verifying-transactions","title":"Verifying transactions","text":"<p>Aggregation is an optional feature. Transactions may or may not come with an aggregation proof.</p> <ul> <li>If there is an aggregation proof, verify it using the aggregation verifying key. The aggregation instance must be derived appropriately from the raw instances and raw verifying keys.</li> <li>Otherwise, the raw proofs must be present. Verify them all against the raw instances using the raw verifying keys.</li> <li>In either case, verify the delta proof.</li> </ul>"},{"location":"arch/system/state/shielded_resource_machine/proving/risc0.html","title":"RISC Zero proving system","text":"<p>Compliance and logic constraints are represented as RISC Zero programs. RISC Zero is a zkVM based on STARK proofs. Each program in RISC Zero (called session) is split into segments of equal length (determined by the cycle count) and proven separately (segment proofs) which are then aggregated (succinct proof). That implies that:</p> <ol> <li>the bigger the program is, the more segment proofs are required and the longer it takes to prove the whole session</li> <li>memory requirements are bound (segment memory upper bound)</li> <li>the final proof size is fixed</li> <li>verification time is fixed</li> </ol>"},{"location":"arch/system/state/shielded_resource_machine/proving/risc0.html#groth16-recursive-proofs-for-faster-on-chain-verification","title":"Groth16 recursive proofs for faster on-chain verification","text":"<p>RISC Zero zkVM also supports creating Groth16 proofs for faster verification. Groth16 proofs have minimal proof size (3 field elements) but require trusted setup for each circuit. Therefore Groth16 isn't suitable for creating proofs of various programs but allows efficient verification of a fixed program. RISC Zero zkVM provides a groth16 circuit that verifies recursively an aggregated segment proof.</p> <p>Raw RM proofs (compliance and logic) are STARK proofs. For efficient on-chain verification, they can be wrapped in Groth16, either via proof aggregation or directly.</p>"},{"location":"indexes/modules.html","title":"Modules","text":"<p>All the Juvix modules for the Anoma Specification are listed below.</p>","tags":["index"]},{"location":"indexes/modules.html#juvix-package-version","title":"Juvix Package version","text":"<pre><code>package : Package :=\n  defaultPackage@{\n    name := \"nspec\";\n    version := mkVersion 1 0 0;\n    dependencies :=\n      [github \"anoma\" \"juvix-stdlib\" \"v0.11.0\"]\n  };\n</code></pre>","tags":["index"]},{"location":"indexes/modules.html#modules-by-letter","title":"Modules by letter","text":"","tags":["index"]},{"location":"indexes/tags.html","title":"List of tags","text":"","tags":["index"]},{"location":"indexes/tags.html#tag:accumulator","title":"accumulator","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:commitment","title":"commitment","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:evm","title":"evm","text":"<ul> <li>            Ethereum Virtual Machine          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:identity","title":"identity","text":"<ul> <li>            Identity Architecture Types          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:nullifier","title":"nullifier","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:protocol","title":"protocol","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:protocol-adapter","title":"protocol-adapter","text":"<ul> <li>            Ethereum Virtual Machine          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:resource-logic","title":"resource logic","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:resource-machine","title":"resource-machine","text":"<ul> <li>            Ethereum Virtual Machine          </li> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:system-architecture","title":"system-architecture","text":"<ul> <li>            Identity Architecture Types          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:work-in-progress","title":"work-in-progress","text":"<ul> <li>            Ethereum Virtual Machine          </li> </ul>","tags":["index"]},{"location":"tutorial/branch.html","title":"Git branching strategy","text":"<p>The general workflow is to branch off from the latest version's branch, perform your changes, open a pull request, and merge your updates.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#branching-strategy","title":"Branching strategy","text":"","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#for-changes-to-the-latest-version","title":"For changes to the latest version","text":"<p>For changes to the latest version, branch off from <code>main</code>. Name your branch by prefixing your name and an issue identifier, like <code>your-name/issue-identifier</code>.</p> <pre><code>git fetch\ngit checkout -b your-name/issue-identifier origin/main\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#for-changes-to-older-published-versions","title":"For changes to older published versions","text":"<p>For patching older versions, branch off from the specific version branch. Published versions follow the pattern <code>vX</code>, where <code>X</code> is the version number. For example, say the latest version is <code>v0.1.0</code>.</p> <p>Name your branch by prefixing your name and a patch topic, like <code>your-name/patch-topic</code>.</p> <pre><code>git checkout -b your-name/patch-topic v0.1.0\n</code></pre> <p>The git graph will look like:</p> <pre><code>%%{init: { 'theme': 'neutral' } }%%\ngitGraph:\n    commit\n    branch vX\n    checkout vX\n    commit\n    branch your-name/issue-identifier\n    checkout your-name/issue-identifier\n    commit\n    checkout vX\n    merge your-name/issue-identifier</code></pre> <p>So, if your PR is merged, the changes will be incorporated into the version branch and on the website.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#pushing-changes","title":"Pushing changes","text":"<p>When pushing changes for the first time in a new branch, set the upstream tracking branch:</p> <pre><code>git push -u origin some-branch:some-branch\n</code></pre> <p>Afterwards, for subsequent pushes the following is sufficient: <pre><code>git push\n</code></pre></p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#rebasing-your-work","title":"Rebasing your work","text":"<p>Every once in a while, you should rebase your branch onto the base branch, if the current version has been updated. This will incorporate the latest changes from the base branch into your branch. The steps to rebase are usually the following.</p> <ul> <li>Switch to your working branch:<pre><code>git checkout your-name/issue-identifier\n</code></pre> </li> </ul> <ul> <li>Initiate the rebase onto the target branch:<pre><code>git pull origin main --rebase\n</code></pre> <p>Or merge the changes from the base branch which is convenient most of the   time:</p> <pre><code>git merge main\n</code></pre> </li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#resolve-conflicts","title":"Resolve conflicts","text":"<ul> <li>Git will pause for conflict resolution.</li> <li> <p>After resolving each conflict:</p> <pre><code>git rebase --continue\n</code></pre> </li> </ul> <ul> <li> <p>To stop the rebase process:</p> <pre><code>git rebase --abort\n</code></pre> </li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#push-your-changes","title":"Push your changes","text":"<ul> <li>Once rebase is complete, push changes:<pre><code>git push origin your-name/issue-identifier\n</code></pre> </li> </ul> <ul> <li>A force push may be required:<pre><code>git push origin your-name/issue-identifier --force-with-lease\n</code></pre> </li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#important-notes","title":"Important notes","text":"<ul> <li>Ensure you are on the correct branch before making changes.</li> <li>Regularly update your branch to minimise conflicts.</li> <li>Ask for help if you encounter any issues to the maintainers.</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#merging-prs","title":"Merging PRs","text":"<p>Before a PR can be merged into the <code>main</code> branch, it must be able to build the whole codebase. The CI checks this automatically, and can be also verified manually:</p> <p>First, we must check the Juvix codebase, running the following command:</p> <pre><code>juvix typecheck docs/everything.juvix.md\n</code></pre> <p>Next, we must verify the MkDocs site build by running the following command:</p> <pre><code>uv run mkdocs build\n</code></pre> <p>or with <code>just</code></p> <pre><code>just build\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#integration-branches-for-complex-changes","title":"Integration branches for complex changes","text":"<p>When making complex changes that consist of a set of interdependent changes, it's best to split them up into smaller PRs that each address a single topic.</p> <p>For example, making a change to a type can be in one PR, a change to a different type in a second PR, and applying the type changes in the rest of the code base in a third one. In this case, branch 3 needs to merge branch 1 &amp; 2 first.</p> <p>We also need to create an integration branch, which becomes the base branch for all the interdependent PRs, and a corresponding integration PR to be merged into the <code>main</code> branch.</p> <p>On GitHub, make sure to include the list of auxiliary PRs as part of the description of the integration PR.</p> <p>This way the topic branches need not be able to build the whole codebase, while the integration branch must be able to build it once all the topic branches are merged into it.</p> <p>A possible diagram of the integration branch and topic branches is the following, assuming the integration branch is <code>example/integration</code> against <code>main</code>, and the topic branches are <code>example/topic-1</code> against <code>main</code>, <code>example/topic-2</code> against <code>main</code>, and <code>example/topic-3</code> against <code>main</code>. The topic branches are squashed-and-merged into the integration branch.</p> <pre><code>%%{init: { 'theme': 'neutral' } }%%\ngitGraph:\n    commit\n    branch example/topic-1\n    checkout example/topic-1\n    commit\n    checkout main\n    branch example/topic-2\n    checkout example/topic-2\n    commit\n    checkout main\n    branch example/integration\n    checkout example/integration\n    merge example/topic-1\n    merge example/topic-2\n    commit \"Fix merge conflicts\"\n    checkout main\n    merge example/integration</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#fetch-the-latest-updates","title":"Fetch the latest updates","text":"<pre><code>git fetch\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-integration-branch","title":"Create integration branch","text":"<pre><code>git branch example/integration origin/main\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-topic-branches","title":"Create topic branches","text":"<pre><code>git branch example/topic-1 example/integration\ngit branch example/topic-2 example/integration\ngit branch example/topic-3 example/integration\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#merge-dependencies","title":"Merge dependencies","text":"<pre><code>git checkout example/topic-3\ngit merge example/topic-1\ngit merge example/topic-2\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#using-git-worktrees","title":"Using Git Worktrees","text":"<p>When working on multiple branches simultaneously, git worktrees come handy. Here's how to use them.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#fetch-the-latest-updates_1","title":"Fetch the latest updates","text":"<pre><code>git fetch\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-a-branch","title":"Create a branch","text":"<pre><code>git branch some-branch origin/main\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-a-worktree-for-the-branch","title":"Create a Worktree for the branch","text":"<p>Either inside the repo starting with a dot (to avoid build issues):</p> <pre><code>git worktree add /path/to/repo/.tree/some-branch some-branch\n</code></pre> <p>Or outside the repo:</p> <pre><code>git worktree add /path/to/repo-some-branch some-branch\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/changelog.html","title":"Managing the Changelog","text":"<p>We now use <code>Commitizen</code> to manage our changelog entries. This simplifies the process and ensures consistent formatting. The <code>Commitizen</code> binary should be available after installation.</p>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#adding-a-new-unreleased-entry","title":"Adding a New Unreleased Entry","text":"<p>To add a new changelog entry, use the <code>cz</code> command provided by <code>Commitizen</code>. This will guide you through the process interactively.</p>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#using-commitizen","title":"Using Commitizen","text":"","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#available-types","title":"Available Types","text":"<p>When prompted, choose one of these types for your commit message:</p> <ul> <li><code>feat</code> - For new features</li> <li><code>fix</code> - For bug fixes</li> <li><code>docs</code> - For documentation changes</li> <li><code>style</code> - For code style changes (formatting, missing semi-colons, etc.)</li> <li><code>refactor</code> - For code changes that neither fix a bug nor add a feature</li> <li><code>perf</code> - For performance improvements</li> <li><code>test</code> - For adding or correcting tests</li> <li><code>chore</code> - For changes to the build process or auxiliary tools</li> </ul>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#recommended-commit-message-format","title":"Recommended Commit Message Format","text":"<p>For consistency, follow the prompts to:</p> <ul> <li>Specify the type of change</li> <li>Provide a concise description of the change</li> <li>Optionally, include the issue number if the change is related to an issue</li> </ul> <p>More information about the command syntax can be found in the Commitizen documentation.</p>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/commit_checks.html","title":"Run pre-commit checks","text":"<p>Pre-commit hooks are scripts that run before each commit to ensure code quality by checking for common issues.</p>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/commit_checks.html#running-pre-commit-checks","title":"Running pre-commit checks","text":"<p>After installing the development tools, you can, for example, invoke all checks, by running the following command:</p> <pre><code>uv run pre-commit -- run --all-files\n</code></pre> <p>Or shorter:</p> <pre><code>just check\n</code></pre>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html","title":"<code>snake_case</code> convention for naming files and folders","text":"<p>The Anoma Specification uses the <code>snake_case</code> convention for naming files and folders.</p>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html#guidelines","title":"Guidelines","text":"<ul> <li>Use lowercase letters.</li> <li>Separate words with underscores <code>_</code>, instead of dashes <code>-</code> or camel case.</li> <li>No special characters or spaces.</li> </ul>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html#pros","title":"Pros","text":"<ul> <li>Readability: Improves readability by clearly separating words in names, making   code more understandable.</li> <li>Consistency: Creates a uniform naming style throughout the codebase.</li> <li>Compatibility: Widely supported across different programming languages and   platforms, no issues with case sensitivity.</li> </ul>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html#cons","title":"Cons","text":"<ul> <li>Length: Can make names longer.</li> <li>Visual Clutter: The underscores can create visual clutter, especially in   longer names. We suffer from this, specially in engine's description files.</li> </ul> <p>Info</p> <p>If you find any file or folder that does not follow this convention, please create an issue or a pull request to fix it. Thank you for your help!</p>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/juvix.html","title":"Render Juvix code","text":"<p>Another feature of the Anoma documentation is the inclusion of Juvix code throughout its Markdown support. Here we assume you have Juvix already installed.</p> <p>A Juvix Markdown file is a file with extension <code>.juvix.md</code>. These files are preprocesses by the Juvix compiler to generate the final Markdown file. For this website, we are using <code>mkdocs-juvix-plugin</code>.</p>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#juvix-markdown-file-structure","title":"Juvix Markdown file structure","text":"<p>Very important to note is that the first Juvix code block must declare a module with the name of the file, and each block should be a sequence of well-defined expressions. This means submodules cannot be split across blocks. The name of  module must follow the folder structure of the file is in. For example, the  file <code>tutorial/basics.juvix.md</code> must declare the module <code>tutorial.basics</code>.</p> <pre><code>```juvix\nmodule tutorial.basics;\n-- ...\n```</code></pre> <p>Refer to the <code>everything.juvix.md</code> file located in the <code>docs</code> folder to see an example.</p>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#hide-juvix-code-blocks","title":"Hide Juvix code blocks","text":"<p>Juvix code blocks come with a few extra features, such as the ability to hide the code block from the final output. This is done by adding the <code>hide</code> attribute to the code block. For example:</p> <pre><code>```juvix hide\nmodule tutorial.basics;\n-- ...\n```</code></pre>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#extract-inner-module-statements","title":"Extract inner module statements","text":"<p>Another feature is the ability to extract inner module statements from the code block. This is done by adding the <code>extract-module-statements</code> attribute to the code block. This option can be accompanied by a number to indicate the number of statements to extract. For example, the following would only display the content inside the module <code>B</code>, that is, the module <code>C</code>.</p> <pre><code>```juvix extract-module-statements\nmodule B;\nmodule C;\n-- ...\n```</code></pre>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#snippets-of-juvix-code","title":"Snippets of Juvix code","text":"<p>You can also include snippets of Juvix code in your Markdown files. This is done by adding the <code>--8&lt;--</code> comment followed by the path to the file, and optionally a snippet identifier.</p> <p>Note</p> <p>If the path of the file ends with <code>!</code>, the raw content of the file will be included. Otherwise, for Juvix Markdown files, the content will be preprocessed by the Juvix compiler and then the generated HTML will be included.</p> <p>Snippet identifier</p> <p>To use a snippet identifier, you must wrap the Juvix code block with the syntax <code>&lt;!-- --8&lt;-- [start:snippet_identifier] --&gt;</code> and <code>&lt;!-- --8&lt;-- [end:snippet_identifier] --&gt;</code>. This technique is useful for including specific sections of a file. Alternatively, you use the standard <code>--8&lt;--</code> markers within the code and extract the snippet by appending a ! at the end of the path.</p>","tags":["tutorial","juvix"]},{"location":"tutorial/principles_and_guidelines.html","title":"Global principles and guidelines for writing Anoma Specification documentation","text":"","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#principles","title":"Principles","text":"","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#clarity","title":"Clarity","text":"<p>Make every page clear and concise. Footnotes may be used to add context. Additional notes that exceed a paragraph may deserve to be put into a separate file (and thus will appear in the navigation bar).</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#dont-repeat-yourself","title":"Don't repeat yourself!","text":"<p>Do not paste any copied material. Instead, include the material, e.g., via snippeting. The only exception is material for which there is no established method for inclusion; in this case, include the material inside a todo note <code>!!! todo \"unrepeat this\"</code>, paired with a reference to its source.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#consistency","title":"Consistency","text":"<p>Terms from the glossary must be used consistently throughout the specification. Where applicable, adhere to naming schemes.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#style","title":"Style","text":"<p>Conform to style guides, unless this would lead to inconsistency.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#citations","title":"Citations","text":"<p>Use citations to refer to articles, books, and similar publications.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#guidelines","title":"Guidelines","text":"","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#accessibility","title":"Accessibility","text":"<p>The specification should be accessible to its intended readership, which should encompass at least the members of the Anoma engineering team.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#internal-and-external-linking","title":"Internal and external linking","text":"<p>If you have a link for something, please use it. Chances are that it improves accessibility and moreover it helps discover inconsistencies. Use wikilinks for internal links and URL links (<code>[target](URL)</code>) only for external material (or if wikilinks do not work as expected).</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#implementability","title":"Implementability","text":"<p>The specification should keep design decisions to a minimum, but design decisions that are left to the potential implementer on purpose should be discussed in footnotes or notes.</p>","tags":["tutorial"]},{"location":"tutorial/versioning.html","title":"Versioning","text":"<p>The Anoma Specification follows semantic versioning.</p> <pre><code>MAJOR.MINOR.PATCH\n</code></pre> <ul> <li>MAJOR version when you make incompatible API changes</li> <li>MINOR version when you add functionality in a backward compatible manner</li> <li>PATCH version when you make backward compatible bug fixes</li> </ul>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#more-on-versioning-criteria","title":"More on versioning criteria","text":"<ul> <li>Major version (X.0.0): Incremented for backwards-incompatible changes, like:<p>- Breaking changes to core interfaces or types   - Removal of deprecated functionality   - Major architectural changes</p> </li> </ul> <ul> <li>Minor version (0.X.0): Incremented for backwards-compatible feature additions:<p>- New engines, message types, or behaviours   - New functionality that doesn't break existing code   - Deprecation notices for future breaking changes</p> </li> </ul> <ul> <li>Patch version (0.0.X): Incremented for backwards-compatible bug fixes:<p>- Documentation improvements   - Bug fixes that don't change interfaces   - Minor code clean-up and refactoring</p> </li> </ul>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#preparing-a-new-version","title":"Preparing a new version","text":"<ul> <li> Update <code>mkdocs.yml</code></li> <li> Update <code>docs/Package.juvix</code></li> <li> Update <code>docs/references/ref.bib</code></li> <li> Make sure to run <code>just sync</code> to update the dependencies and <code>just build</code> to check that the code is still typechecking.</li> <li> Git tag the new version</li> <li> Release a new changelog entry</li> </ul>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-mkdocsyml","title":"Update <code>mkdocs.yml</code>","text":"<p>Update the <code>site_version</code> to the new version.</p> mkdocs.yml<pre><code>- site_version: !ENV [SITE_VERSION, \"v0.1.0\"]\n+ site_version: !ENV [SITE_VERSION, \"v0.1.1\"]\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-nspec-juvix-package-version","title":"Update <code>nspec</code> Juvix package version","text":"docs/Package.juvix<pre><code>package : Package :=\n  defaultPackage@{\n    name := \"nspec\";\n-    version := mkVersion 0 1 0;\n+    version := mkVersion 0 1 1;\n    dependencies :=\n      [github \"anoma\" \"juvix-stdlib\" \"v0.6.0\"; github \"anoma\" \"juvix-containers\" \"v0.14.1\"]\n  };\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-docsrefbib","title":"Update <code>docs/ref.bib</code>","text":"<p>Update the version of the <code>nspec</code> package in the <code>ref.bib</code> file.</p> docs/ref.bib<pre><code>@software{nspec,\n  author = {Anoma},\n  title = {Anoma Specification},\n-  version = {0.1.0},\n+  version = {0.1.1},\n  url = {https://github.com/anoma/nspec}\n}\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-version","title":"Update <code>VERSION</code>","text":"VERSION<pre><code>-0.1.0\n+0.1.1\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-pyprojecttoml","title":"Update <code>pyproject.toml</code>","text":"pyproject.toml<pre><code>- version = \"0.1.0\"\n+ version = \"0.1.1\"\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#git-tag-the-new-version","title":"Git tag the new version","text":"<pre><code>git tag v0.1.1\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#release-a-new-changelog-entry","title":"Release a new changelog entry","text":"<p>Follow the Updating the changelog tutorial for more information on how to release a new changelog entry. This tutorial uses <code>unclog</code> to create a new changelog entry.</p> <p>The package started at version 0.1.0 as the initial release.</p>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/install/index.html","title":"Preparing the local environment for writing documentation","text":"","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#getting-started","title":"Getting Started","text":"<p>Welcome to the Anoma Specs repository! This project uses Material for MkDocs for documentation and is designed for easy contribution and local development.</p> <ul> <li>Latest Specs: https://specs.anoma.net/latest/</li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#quick-start","title":"Quick Start","text":"","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#1-prerequisites","title":"1. Prerequisites","text":"<p>Make sure you have the following tools installed:</p> <ul> <li>uv (Python package/dependency manager)<ul> <li>macOS/Linux:   <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></li> <li>Windows:   <pre><code>powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre></li> <li>Or via Homebrew:   <pre><code>brew install uv\n</code></pre></li> </ul> </li> </ul> <ul> <li>graphviz (for local documentation deployment)</li> </ul> <ul> <li>juvix (for typechecking and specs development)   <pre><code>curl --proto '=https' --tlsv1.2 -sSfL https://get.juvix.org | sh\n</code></pre></li> </ul> <ul> <li>just (a simple command runner, replacement for Make)<ul> <li>Install via your package manager.</li> </ul> </li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#2-installation","title":"2. Installation","text":"<p>Choose one of the following:</p> <ul> <li>With uv:   <pre><code>uv sync\n</code></pre></li> <li>With just:   <pre><code>just sync\n</code></pre></li> <li>With pip:   <pre><code>pip install -r requirements.txt\n</code></pre></li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#3-common-commands","title":"3. Common Commands","text":"<p>You can use either <code>just</code> or <code>uv run</code> for most tasks. Below are the most common commands:</p>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#dependency-management","title":"Dependency Management","text":"Task Command Command (just) Synchronize dependencies <code>uv sync</code> <code>just sync</code> Run all pre-commit checks <code>uv run pre-commit -- run --all-files</code> <code>just check</code> Typecheck the code <code>juvix typecheck docs/everything.juvix.md</code> <code>just juvix-check</code>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#development-tools","title":"Development Tools","text":"<ul> <li>Install pre-commit hooks (for specs writers only):   <pre><code>uv run pre-commit -- install --install-hooks\n</code></pre>   or   <pre><code>just install-hooks\n</code></pre></li> </ul> <ul> <li>Install development tools:   <pre><code>uv tool install pre-commit\nuv tool install commitizen\n</code></pre>   or   <pre><code>just install-tools\n</code></pre></li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#documentation","title":"Documentation","text":"Task Command Command (just) Build documentation <code>uv run mkdocs build --config-file mkdocs.yml</code> <code>just build</code> Serve documentation locally <code>uv run mkdocs serve --config-file mkdocs.yml</code> <code>just serve</code>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#git-operations","title":"Git Operations","text":"Task Command Command (just) Commit using commitizen <code>uv run cz commit</code> <code>just commit</code> Commit skipping hooks <code>git commit --no-verify -m \"&lt;msg&gt;\"</code> <code>just commit-skip</code> Amend commit (skip hooks) <code>git commit --amend --no-verify</code> <code>just commit-amend</code> Amend using commitizen <code>uv run cz commit --amend</code> <code>just cz-amend</code> <p>If you have installed the pre-commit hooks (which is recommended), but need to make a commit or push changes without running the hooks (for example, when working on a branch or PR), you can use the <code>--no-verify</code> flag as shown in the table above. The Commitizen is a tool to help you write better commit messages.</p>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#4-short-reference","title":"4. Short Reference","text":"<ul> <li>Install: <code>uv sync</code> or <code>pip install -r requirements.txt</code></li> <li>Build: <code>just build</code> or <code>uv run mkdocs build</code></li> <li>Serve Locally: <code>just serve</code> or <code>uv run mkdocs serve</code></li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#development-with-nix","title":"Development with Nix","text":"<p>If you use Nix:</p> <ol> <li>Install Nix: Download</li> <li>Enable Flakes: Guide</li> <li>Enter Development Shell:    <pre><code>nix develop\n</code></pre></li> </ol>","tags":["tutorial","install"]},{"location":"tutorial/md/index.html","title":"Markdown Basics for Anoma Documentation","text":"<p>Our theme and main Markdown reference is Material for MkDocs. You may use anything found in this reference, including all possible Markdown extensions.</p> <p>This guide provides an overview of the key markdown features we use in the documentation. Please note that this guide is a work-in-progress.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/index.html#front-matter","title":"Front Matter","text":"<p>Each markdown file should begin with a front matter section. It typically includes metadata such as <code>icon</code>, <code>tags</code>, <code>categories</code>. For more examples, refer to other files within the documentation. For example, the icons name can be found here.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/index.html#example-front-matter","title":"Example Front Matter","text":"<pre><code>---\nicon: material/auto-download\nsearch:\n  exclude: false\n  boost: 3\ntags:\n  - harware-subsystem\n  - logging\n---\n</code></pre> <p>Warning</p> <p>Any new markdown file added to the <code>docs</code> directory must, in principle, have an entry in the <code>mkdocs.yml</code> file, specifically in the <code>nav</code> section.</p> <p>The filename may be relevant depending on where it is placed in the navigation. For example, any file intended to be the landing page of a section, say Section X, must be named <code>index.md</code> and placed right below the <code>Section X</code> item. Children of <code>Section X</code> do not need to follow any specific naming convention.</p> <pre><code>...\n- Section X:\n    - ./path-to/index.md\n    - NameRef Child1 : ./path-to/child1.md\n    - NameRef Child2 : ./path-to/child2.md\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/citations.html","title":"Bibliography","text":"<p>Place your <code>.bib</code> files within the <code>docs/references</code> directory. For convenience, we have included all the ART published papers in the <code>docs/references/art.bib</code> file.</p> <p>Any new <code>.bib</code> file added to this folder will automatically be processed.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/citations.html#citing-in-markdown","title":"Citing in Markdown","text":"<p>Use the citation key from your <code>.bib</code> files to cite references in your markdown files. The syntax is as follows:</p> <pre><code>This statement requires a citation .\n</code></pre> <p>Info</p> <p>We have <code>docs/references/update_repo_bibtexs.py</code> script that can be used to update the <code>docs/references/anoma_repos.bib</code> file to cite Anoma repositories in the documentation.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/citations.html#references-available","title":"References available","text":"Anoma Research Topics (ART) papers <pre><code>% https://art.anoma.net\n\n\n@article{ art-2025-optimising-shielded-state-synchronization,\n    author    = { Larraia, Enrique and Khalniyazova, Yulia },\n    title     = { {Optimising Shielded State Synchronization with FMD and TEEs} },\n    journal   = { Anoma Research Topics },\n    month     = { Apr },\n    year      = { 2025 },\n    publisher = { Zenodo },\n    version   = { April 10, 2025 },\n    doi       = { 10.5281/zenodo.15186457 },\n    url       = { https://doi.org/10.5281/zenodo.15186456 }\n}\n\n\n@article{ art-2025-dynamic-effective-timed-communication-systems,\n    author    = { Heindel, Tobias and Prieto-Cubides, Jonathan and Hart, Anthony },\n    title     = { {Dynamic Effective Timed Communication Systems} },\n    journal   = { Anoma Research Topics },\n    month     = { Mar },\n    year      = { 2025 },\n    publisher = { Zenodo },\n    version   = { March 06, 2025 },\n    doi       = { 10.5281/zenodo.14984148 },\n    url       = { https://doi.org/10.5281/zenodo.14984147 }\n}\n\n\n@article{ art-2024-nock-functional-programmers,\n    author    = { Czajka, Lukasz },\n    title     = { {Nock for Functional Programmers} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 18, 2024 },\n    doi       = { 10.5281/zenodo.14511714 },\n    url       = { https://doi.org/10.5281/zenodo.14511713 }\n}\n\n\n@article{ art-2024-message-logic,\n    author    = { Gabbay, Murdoch J. and Zarin, Naqib },\n    title     = { {Message Logic} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 04, 2024 },\n    doi       = { 10.5281/zenodo.14251398 },\n    url       = { https://doi.org/10.5281/zenodo.14251397 }\n}\n\n\n@article{ art-2024-anoma-state-architecture,\n    author    = { Sheff, Isaac },\n    title     = { {Anoma State Architecture} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 04, 2024 },\n    doi       = { 10.5281/zenodo.14265827 },\n    url       = { https://doi.org/10.5281/zenodo.14265826 }\n}\n\n\n@article{ art-2024-heterogeneous-paxos-20-specs,\n    author    = { Karbyshev, Aleksandr and Sheff, Isaac },\n    title     = { {Heterogeneous Paxos 2.0: the Specs} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 04, 2024 },\n    doi       = { 10.5281/zenodo.14276903 },\n    url       = { https://doi.org/10.5281/zenodo.12572557 }\n}\n\n\n@article{ art-2024-slow-games-policy-enforcement-under,\n    author    = { Reusche, D and Goes, Christopher and Della Penna, Nicolas },\n    title     = { {Slow Games: Policy Enforcement under Uncertainty} },\n    journal   = { Anoma Research Topics },\n    month     = { Sep },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { September 15, 2024 },\n    doi       = { 10.5281/zenodo.13765214 },\n    url       = { https://doi.org/10.5281/zenodo.13765213 }\n}\n\n\n@article{ art-2024-compiling-juvix-cairo-assembly,\n    author    = { Czajka, \u0141ukasz },\n    title     = { {Compiling Juvix to Cairo Assembly} },\n    journal   = { Anoma Research Topics },\n    month     = { Sep },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { September 10, 2024 },\n    doi       = { 10.5281/zenodo.13739344 },\n    url       = { https://doi.org/10.5281/zenodo.13739343 }\n}\n\n\n@article{ art-2024-comparing-two-hash-functions,\n    author    = { Y\u0131ld\u0131z, Burcu and Maller, Mary },\n    title     = { {Comparing Two Hash Functions for Multi-Party Computation and Zero-Knowledge} },\n    journal   = { Anoma Research Topics },\n    month     = { Sep },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { September 10, 2024 },\n    doi       = { 10.5281/zenodo.13739511 },\n    url       = { https://doi.org/10.5281/zenodo.13739510 }\n}\n\n\n@article{ art-2024-intentcentric-applications-anoma,\n    author    = { Heuer, Michael and Reusche, D },\n    title     = { {Intent-centric Applications for the Anoma Resource Machine} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { August 26, 2024 },\n    doi       = { 10.5281/zenodo.13340448 },\n    url       = { https://doi.org/10.5281/zenodo.13340447 }\n}\n\n\n@article{ art-2024-heterogeneous-narwhal-paxos,\n    author    = { Heindel, Tobias and Karbyshev, Aleksandr and Sheff, Isaac },\n    title     = { {Heterogeneous Narwhal and Paxos} },\n    journal   = { Anoma Research Topics },\n    month     = { Jun },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { June 27, 2024 },\n    doi       = { 10.5281/zenodo.10498999 },\n    url       = { https://doi.org/10.5281/zenodo.10498998 }\n}\n\n\n@article{ art-2024-crosschain-integrity-controller-labels,\n    author    = { Isaac, Sheff },\n    title     = { {Cross-Chain Integrity with Controller Labels and Endorsement} },\n    journal   = { Anoma Research Topics },\n    month     = { Jun },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { June 25, 2024 },\n    doi       = { 10.5281/zenodo.10498997 },\n    url       = { https://doi.org/10.5281/zenodo.10498996 }\n}\n\n\n@article{ art-2024-anoma-resource-machine-specification,\n    author    = { Khalniyazova, Yulia and Goes, Christopher },\n    title     = { {Anoma Resource Machine Specification} },\n    journal   = { Anoma Research Topics },\n    month     = { Jun },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { June 25, 2024 },\n    doi       = { 10.5281/zenodo.10689620 },\n    url       = { https://doi.org/10.5281/zenodo.10498990 }\n}\n\n\n@article{ art-2024-compiling-zkvms,\n    author    = { Centelles, Alberto },\n    title     = { {Compiling to ZKVMs} },\n    journal   = { Anoma Research Topics },\n    month     = { Apr },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { April 19, 2024 },\n    doi       = { 10.5281/zenodo.10998758 },\n    url       = { https://doi.org/10.5281/zenodo.10498994 }\n}\n\n\n@article{ art-2024-intent-machines,\n    author    = { Hart, Anthony and Reusche, D },\n    title     = { {Intent Machines} },\n    journal   = { Anoma Research Topics },\n    month     = { Feb },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { February 21, 2024 },\n    doi       = { 10.5281/zenodo.10654543 },\n    url       = { https://doi.org/10.5281/zenodo.10498992 }\n}\n\n\n@article{ art-2023-vampir-bestiary,\n    author    = { Fitzgerald, Joshua and Centelles, Alberto },\n    title     = { {VampIR Bestiary} },\n    journal   = { Anoma Research Topics },\n    month     = { Nov },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { November 13, 2023 },\n    doi       = { 10.5281/zenodo.10118865 },\n    url       = { https://doi.org/10.5281/zenodo.10118864 }\n}\n\n\n@article{ art-2023-constraint-satisfaction-problems-survey,\n    author    = { Hart, Anthony },\n    title     = { {Constraint Satisfaction Problems: A Survey for Anoma} },\n    journal   = { Anoma Research Topics },\n    month     = { Oct },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { October 18, 2023 },\n    doi       = { 10.5281/zenodo.10019113 },\n    url       = { https://doi.org/10.5281/zenodo.10019112 }\n}\n\n\n@article{ art-2023-exploring-cryptographic-approaches-enhance,\n    author    = { Khalniyazova, Yulia },\n    title     = { {Exploring Cryptographic Approaches to Enhance Privacy in Intent Solving} },\n    journal   = { Anoma Research Topics },\n    month     = { Oct },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { October 02, 2023 },\n    doi       = { 10.5281/zenodo.8321167 },\n    url       = { https://doi.org/10.5281/zenodo.8321166 }\n}\n\n\n@article{ art-2023-core-language-juvix,\n    author    = { Lukasz Czajka },\n    title     = { {The Core language of Juvix} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 29, 2023 },\n    doi       = { 10.5281/zenodo.8268850 },\n    url       = { https://doi.org/10.5281/zenodo.8268849 }\n}\n\n\n@article{ art-2023-rethinking-vampir,\n    author    = { Anthony Hart },\n    title     = { {Rethinking VampIR} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 29, 2023 },\n    doi       = { 10.5281/zenodo.8262815 },\n    url       = { https://doi.org/10.5281/zenodo.8262814 }\n}\n\n\n@article{ art-2023-anoma-unified-architecture,\n    author    = { Christopher Goes and Awa Sun Yin and Adrian Brink },\n    title     = { {Anoma: a unified architecture for full-stack decentralised applications} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 24, 2023 },\n    doi       = { 10.5281/zenodo.8279842 },\n    url       = { https://doi.org/10.5281/zenodo.8279841 }\n}\n\n\n@article{ art-2023-geb-pipeline,\n    author    = { Artem Gureev and Jonathan Prieto-Cubides },\n    title     = { {Geb Pipeline} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 21, 2023 },\n    doi       = { 10.5281/zenodo.8262747 },\n    url       = { https://doi.org/10.5281/zenodo.8262746 }\n}\n\n\n@article{ art-2023-juvix-vampir-pipeline,\n    author    = { Lukasz Czajka },\n    title     = { {Juvix to VampIR Pipeline} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 14, 2023 },\n    doi       = { 10.5281/zenodo.8252903 },\n    url       = { https://doi.org/10.5281/zenodo.8246535 }\n}\n</code></pre> Anoma Public GitHub repositories <pre><code>  author = {anoma},\n  title = {juvix},\n  year = {2017},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/juvix}\n}\n\n@misc{github-masp-mpc,\n  author = {anoma},\n  title = {masp-mpc},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/masp-mpc}\n}\n\n@misc{github-masp,\n  author = {anoma},\n  title = {masp},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/masp}\n}\n\n@misc{github-ferveo,\n  author = {anoma},\n  title = {ferveo},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/ferveo}\n}\n\n@misc{github-anoma,\n  author = {anoma},\n  title = {anoma},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/anoma}\n}\n\n@misc{github-group-threshold-crypto,\n  author = {anoma},\n  title = {group-threshold-crypto},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/group-threshold-crypto}\n}\n\n@misc{github-research,\n  author = {anoma},\n  title = {research},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/research}\n}\n\n@misc{github-plonkup-hash,\n  author = {anoma},\n  title = {plonkup-hash},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/plonkup-hash}\n}\n\n@misc{github-plonkup,\n  author = {anoma},\n  title = {plonkup},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/plonkup}\n}\n\n@misc{github-typhon,\n  author = {anoma},\n  title = {typhon},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/typhon}\n}\n\n@misc{github-exhibit_plonkup,\n  author = {anoma},\n  title = {exhibit_plonkup},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/exhibit_plonkup}\n}\n\n@misc{github-taiga,\n  author = {anoma},\n  title = {taiga},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/taiga}\n}\n\n@misc{github-juvix-stdlib,\n  author = {anoma},\n  title = {juvix-stdlib},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/juvix-stdlib}\n}\n\n@misc{github-namada-trusted-setup,\n  author = {anoma},\n  title = {namada-trusted-setup},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada-trusted-setup}\n}\n\n@misc{github-alucard,\n  author = {anoma},\n  title = {alucard},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/alucard}\n}\n\n@misc{github-masp-phase2,\n  author = {anoma},\n  title = {masp-phase2},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/masp-phase2}\n}\n\n@misc{github-vamp-ir,\n  author = {anoma},\n  title = {vamp-ir},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/vamp-ir}\n}\n\n@misc{github-namada-testnets,\n  author = {anoma},\n  title = {namada-testnets},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada-testnets}\n}\n\n@misc{github-ethereum-bridge,\n  author = {anoma},\n  title = {ethereum-bridge},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/ethereum-bridge}\n}\n\n@misc{github-vscode-juvix,\n  author = {anoma},\n  title = {vscode-juvix},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/vscode-juvix}\n}\n\n@misc{github-whitepaper,\n  author = {anoma},\n  title = {whitepaper},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/whitepaper}\n}\n\n@misc{github-devchain-container,\n  author = {anoma},\n  title = {devchain-container},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/devchain-container}\n}\n\n@misc{github-wasm-workspace,\n  author = {anoma},\n  title = {wasm-workspace},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/wasm-workspace}\n}\n\n@misc{github-devtool,\n  author = {anoma},\n  title = {devtool},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/devtool}\n}\n\n@misc{github-anoma-wasm-multitoken,\n  author = {anoma},\n  title = {anoma-wasm-multitoken},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/anoma-wasm-multitoken}\n}\n\n@misc{github-dev-utils,\n  author = {anoma},\n  title = {dev-utils},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/dev-utils}\n}\n\n@misc{github-namada,\n  author = {anoma},\n  title = {namada},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada}\n}\n\n@misc{github-namada-interface,\n  author = {anoma},\n  title = {namada-interface},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada-interface}\n}\n\n@misc{github-zkp-compiler-shootout,\n  author = {anoma},\n  title = {zkp-compiler-shootout},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/zkp-compiler-shootout}\n}\n\n@misc{github-homebrew-juvix,\n  author = {anoma},\n  title = {homebrew-juvix},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/homebrew-juvix}\n}\n</code></pre> Other literature <pre><code>  title={Heterogeneous Paxos: Technical Report},\n  author={Isaac Sheff and Xinwen Wang and Robbert van Renesse and Andrew C. Myers},\n  year={2020},\n  eprint={2011.08253},\n  archivePrefix={arXiv},\n  primaryClass={cs.DC}\n}\n\n@misc{karbyshevsheff2024heterogeneous,\n  title={Heterogeneous Paxos 2.0: the Specs},\n  author={Aleksandr Karbyshev and Isaac Sheff},\n  year={2024},\n  url={https://pomf2.lain.la/f/owqf7ws.pdf},\n}\n\n@misc{goes2024anoma,\n  author = {Christopher Goes},\n  title = {Anoma as the Universal Intent Machine for Ethereum},\n  year = {2024},\n  howpublished = {{Ethereum Research}},\n  note = {Draft},\n  url = {https://ethresear.ch/t/rfc-draft-anoma-as-the-universal-intent-machine-for-ethereum/19109},\n  urldate = {2024-06-17}\n}\n\n@inproceedings{Hewitt2006,\n  title     = {What Is Commitment? Physical, Organizational, and Social (Revised)},\n  author    = {Hewitt, Carl},\n  year      = 2007,\n  publisher = {Springer Berlin Heidelberg},\n  address   = {Berlin, Heidelberg},\n  pages     = {293--307}\n}\n\n@phdthesis{clinger1981,\n  title     = {Foundations of Actor Semantics},\n  author    = {William Douglas Clinger},\n  year      = 1981,\n  url       = {https://dspace.mit.edu/handle/1721.1/6935},\n  school    = {Massachusetts Institute of Technology (MIT)}\n}\n\n@inproceedings{Hewitt1973,\n  title     = {A Universal Modular Actor Formalism for Artificial Intelligence},\n  author    = {Carl Hewitt and Peter Bishop and Richard Steiger},\n  year      = 1973,\n  location  = {San Francisco, CA, USA},\n  publisher = {Morgan Kaufmann Publishers Inc.},\n  pages     = {235--245}\n}\n\n@book{Scott1976,\n  title     = {Toward a Mathematical Semantics for Computer Languages},\n  author    = {Dana Scott and Christopher Strachey},\n  year      = 1976,\n  publisher = {Prentice-Hall}\n}\n\n@book{Agha1986,\n  title     = {Actors: A Model of Concurrent Computation in Distributed Systems},\n  author    = {Gul A. Agha},\n  year      = 1986,\n  publisher = {MIT Press}\n}\n\n@article{agha-overview-actor-languages,\n  title     = {An overview of actor languages},\n  author    = {Agha, Gul},\n  year      = 1986,\n  month     = {jun},\n  journal   = {SIGPLAN Not.},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 21,\n  number    = 10,\n  pages     = {58\u201367},\n  doi       = {10.1145/323648.323743},\n  url       = {https://doi.org/10.1145/323648.323743},\n}\n\n@article{erlang,\n  title     = {The development of Erlang},\n  author    = {Armstrong, Joe},\n  year      = 1997,\n  month     = {aug},\n  journal   = {SIGPLAN Not.},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 32,\n  number    = 8,\n  pages     = {196\u2013203},\n  doi       = {10.1145/258949.258967},\n  url       = {https://doi.org/10.1145/258949.258967}\n}\n\n@book{milner-concurrency,\n  title     = {Communication and Concurrency},\n  author    = {Milner, R.},\n  year      = 1989,\n  publisher = {Prentice-Hall, Inc.},\n  address   = {USA}\n}\n\n@article{behavioural-timed-systems,\n  title     = {{Behavioural equivalences for timed systems}},\n  author    = {Tomasz Brengos and Marco Peressotti},\n  year      = 2019,\n  month     = Feb,\n  journal   = {{Logical Methods in Computer Science}},\n  volume    = {{Volume 15, Issue 1}},\n  doi       = {10.23638/LMCS-15(1:17)2019},\n  url       = {https://lmcs.episciences.org/5220}\n}\n\n@inproceedings{actario,\n  title     = {Actario: A framework for reasoning about actor systems},\n  author    = {Yasutake, Shohei and Watanabe, Takuo},\n  year      = 2015\n}\n\n@article{Talcott1998,\n  title     = {Composable Semantic Models for Actor Theories},\n  author    = {Talcott,  Carolyn L.},\n  year      = 1998,\n  journal   = {Higher Order Symbolic Computation},\n  publisher = {Springer Science and Business Media LLC},\n  volume    = 11,\n  number    = 3,\n  pages     = {281\u2013343},\n  doi       = {10.1023/a:1010042915896},\n  url       = {http://dx.doi.org/10.1023/A:1010042915896}\n}\n\n@article{lamport-global-states,\n  title     = {Distributed snapshots: determining global states of distributed systems},\n  author    = {Chandy, K. Mani and Lamport, Leslie},\n  year      = 1985,\n  month     = {feb},\n  journal   = {ACM Transactions on Computer Systems},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 3,\n  number    = 1,\n  pages     = {63\u201375},\n  doi       = {10.1145/214451.214456},\n  url       = {https://doi.org/10.1145/214451.214456},\n}\n\n@article{selectors-actors-2014,\n  title     = {Selectors: Actors with Multiple Guarded Mailboxes},\n  author    = {Imam,  Shams M. and Sarkar,  Vivek},\n  year      = 2014,\n  month     = oct,\n  publisher = {ACM},\n  journal   = {AGERE! '14: Proceedings of the 4th International Workshop on Programming based on Actors Agents and Decentralized Control},\n  series    = {SPLASH '14},\n  doi       = {10.1145/2687357.2687360},\n  url       = {http://dx.doi.org/10.1145/2687357.2687360},\n  collection = {SPLASH '14}\n}\n\n@article{special-delivery-mailbox-types-2023,\n  title     = {Special Delivery: Programming with Mailbox Types},\n  author    = {Fowler,  Simon and Attard,  Duncan Paul and Sowul,  Franciszek and Gay,  Simon J. and Trinder,  Phil},\n  year      = 2023,\n  month     = aug,\n  journal   = {Proceedings of the ACM on Programming Languages},\n  publisher = {Association for Computing Machinery (ACM)},\n  volume    = 7,\n  number    = {ICFP},\n  pages     = {78\u2013107},\n  doi       = {10.1145/3607832},\n  url       = {http://dx.doi.org/10.1145/3607832}\n}\n\n@article{there-is-no-now-2015,\n  title     = {There is No Now: Problems with simultaneity in distributed systems},\n  author    = {Sheehy, Justin},\n  year      = 2015,\n  month     = {mar},\n  journal   = {Queue},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 13,\n  number    = 3,\n  pages     = {20\u201327},\n  doi       = {10.1145/2742694.2745385},\n  url       = {https://doi.org/10.1145/2742694.2745385}\n}\n\n@article{why-local-clocks-are-easy-2016,\n  title     = {Why Logical Clocks are Easy: Sometimes all you need is the right language.},\n  author    = {Baquero, Carlos and Pregui\\c{c}a, Nuno},\n  year      = 2016,\n  month     = {feb},\n  journal   = {Queue},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 14,\n  number    = 1,\n  pages     = {53\u201369},\n  doi       = {10.1145/2898442.2917756},\n  url       = {https://doi.org/10.1145/2898442.2917756}\n}\n\n@article{lamport-time-clocks-1978,\n  title     = {Time, clocks, and the ordering of events in a distributed system},\n  author    = {Lamport, Leslie},\n  year      = 1978,\n  month     = {jul},\n  journal   = {Commun. ACM},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 21,\n  number    = 7,\n  pages     = {558\u2013565},\n  doi       = {10.1145/359545.359563},\n  url       = {https://doi.org/10.1145/359545.359563},\n}\n\n@inproceedings{taxonomy-of-actor-models-2016,\n  title     = {43 years of actors: a taxonomy of actor models and their key properties},\n  author    = {De Koster, Joeri and Van Cutsem, Tom and De Meuter, Wolfgang},\n  year      = 2016,\n  location  = {Amsterdam, Netherlands},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  series    = {AGERE 2016},\n  pages     = {31\u201340},\n  doi       = {10.1145/3001886.3001890},\n  url       = {https://doi.org/10.1145/3001886.3001890},\n  booktitle = {Proceedings of the 6th International Workshop on Programming Based on Actors, Agents, and Decentralized Control}\n}\n\n@book{Nissanke1999,\n  title = {Formal Specification},\n  ISBN = {9781447107910},\n  url = {http://dx.doi.org/10.1007/978-1-4471-0791-0},\n  DOI = {10.1007/978-1-4471-0791-0},\n  publisher = {Springer London},\n  author = {Nissanke,  Nimal},\n  year = {1999}\n}\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/headers_and_other_conventions.html","title":"Headers and other Markdown conventions","text":"<ul> <li> <p>Use semantic headers to structure your content.</p> <ul> <li>Use <code>#</code> for the main title, <code>##</code> for the first-level header, <code>###</code> for the   second-level header.</li> <li>Only use up to the third level of headers. If you need more levels, consider   restructuring your content.</li> </ul> </li> </ul> <ul> <li> <p>Use sentence case for headers. For example,</p> <ul> <li>use \"How to use this glossary\" instead of \"How to Use This Glossary\", or,</li> <li>use \"Anoma protocol\" instead of  \"Anoma Protocol\", or</li> <li>use \"On engine systems for the Anoma Specification\" instead of \"On Engine   Systems For The Anoma Specification\".</li> </ul> </li> </ul> <ul> <li>Always add a front matter as described in Write using Markdown.</li> </ul> <ul> <li>The (Juvix) Markdown filenames should follow the convention as described in File naming conventions.</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/images.html","title":"Support for including images","text":"<p>Images should be stored in the <code>docs/images</code> folder. Use the File Naming Conventions also for naming images.</p> <p>Image handling in Markdown</p> <p>Use standard Markdown image syntax (<code>![Alt text](image.png)</code>) rather than HTML image tags. HTML image tags are not processed by MkDocs, are not validated, and may not work as expected. In particular, their <code>src</code> attribute is not processed by our image processing script.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/images.html#syntax","title":"Syntax","text":"<p>To add an image, apply the following syntax:</p> <pre><code>![Alt Text](logo.svg){: width=\"200\"}\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/images.html#displayed-image-example","title":"Displayed Image Example","text":"<p>The syntax above will render the image in your document like so:</p> <p></p> <p>Enhanced Image Display</p> <p>Use an HTML <code>&lt;figure&gt;</code> element with a <code>&lt;figcaption&gt;</code> for a refined presentation with captions. Markdown can also be used within the caption:</p> <pre><code>&lt;figure markdown=\"1\"&gt;\n\n  ![Alt Text](image-name.png)\n\n  &lt;figcaption markdown=\"span\"&gt;Image caption text can include *Markdown*!&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html","title":"Support for Wiki Links","text":"<p>Wiki links offer a simple method for citing and referencing other pages in the documentation without lengthy URLs. Wiki links are the preferred method for linking to other pages in the documentation, so please use them whenever possible.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#basic-syntax","title":"Basic Syntax","text":"<p>The basic syntax for a wiki link is:</p> <pre><code>page\n</code></pre> <p>Where:</p> <ul> <li><code>page</code> is the title of the target page</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#full-syntax","title":"Full Syntax","text":"<p>The full syntax for a wiki link is: Wiki Link Syntax<pre><code>  Custom caption\n</code></pre></p> <p>When resolving a wiki link, the system follows these rules:</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#page-title","title":"Page Title","text":"<p>(Mandatory) The 'page' in a wiki link refers to the title specified in the <code>nav</code> attribute of the <code>mkdocs.yml</code> file. For example,</p> mkdocs.yml<pre><code>nav:\n  - Home: index.md\n  - MyRef X: reference.md\n</code></pre> <p>provides the following wiki link:</p> <pre><code>MyRef X\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#path-hints","title":"Path Hints","text":"<p>(Optional) You can use path hints to specify the location of the file. The syntax is:</p> Path Hints<pre><code>page\n</code></pre> <p>Where:</p> <ul> <li><code>hintpath/to</code> is the path (or prefix) to the file</li> <li><code>page</code> is the title of the target page</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#anchors","title":"Anchors","text":"<p>(Optional) Use anchors to link to specific sections within a page. If the page does not have an anchor, the link would render as the caption provided, and you'll find a warning in the build process.</p> Anchors<pre><code>page\n</code></pre> <p>Where:</p> <ul> <li><code>page</code> is the title of the target page</li> <li><code>anchor</code> is a specific section within the page</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#custom-captions","title":"Custom captions","text":"<p>(Optional) Provide custom text to display for the link instead of the page title.</p> Custom Captions<pre><code>Custom caption\n</code></pre> <p>Where:</p> <ul> <li><code>page</code> is the title of the target page</li> <li><code>anchor</code> is a specific section within the page</li> </ul> <p>Captions can include icons, for example:</p> MarkdownPreview <pre><code>[:material-link: this is a caption with an icon](https://specs.anoma.net/pr-391/index.html)\n</code></pre> <p> this is a caption with an icon</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html","title":"Include code snippets","text":"","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html#code-snippets","title":"Code Snippets","text":"<p>Include excerpts from other files using the Snippet extension detailed here: PyMdown Extensions - Snippets.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html#excerpt-wrapping-syntax","title":"Excerpt Wrapping Syntax","text":"<p>Enclose the excerpt with the following tags:</p> <pre><code>&lt;!-- Start snippet --&gt;\n;--8&lt;-- [start:TAG]\n...\n;--8&lt;-- [end:TAG]\n&lt;!-- End snippet --&gt;\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html#snippet-inclusion-syntax","title":"Snippet Inclusion Syntax","text":"<p>To incorporate the excerpt elsewhere, specify its path and tag:</p> <pre><code>;--8&lt;-- \"path/to/file.ext:TAG\"\n</code></pre> <p>Following these practices ensures consistency, navigability, and professionalism in the Anoma documentation.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/todos.html","title":"Add pending tasks with Todos admonition","text":"","tags":["tutorial","conventions"]},{"location":"tutorial/md/todos.html#todos","title":"Todos","text":"<p>Incorporate todos with the following syntax:</p> <pre><code>!!! todo\n\n    Content of the todo\n</code></pre> <p>The above renders as:</p> <p>Todo</p> <p>Content of the todo</p> <p>Info</p> <p>Be aware that todos are automatically removed from the online version. If you want to keep them, set <code>todos: True</code> in the front matter.</p>","tags":["tutorial","conventions"]}]}