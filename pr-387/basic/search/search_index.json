{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"changelog.html","title":"Change Log","text":"","tags":["changelog"]},{"location":"changelog.html#v100","title":"v1.0.0","text":"<p>This release introduces significant new features and improvements to the Anoma specification, focusing on:</p> <ul> <li>protocol adapter integration</li> <li>resource machine specifications</li> <li>application-specific documentation</li> </ul> <p>The node architecture has been removed from this (latest) release, but can be found in the v0.2.0 release. We plan to integrate it back in the future, when v2.0.0 comes in.</p>","tags":["changelog"]},{"location":"changelog.html#v020","title":"v0.2.0","text":"<p>This release introduces significant new features and improvements to the Anoma specification, including protocol adapter integration, engine simulation capabilities, and major updates to the Resource Machine specifications. Key highlights include:</p> <ul> <li>Added comprehensive protocol adapter integration documentation</li> <li>Introduced interactive engine simulator with message passing support</li> <li>Updated Resource Machine specifications (post-HHH edition)</li> <li>Reorganized documentation structure and navigation</li> <li>Updated to Juvix stdlib v0.11.0</li> <li>Various CI/CD improvements and tooling updates</li> </ul>","tags":["changelog"]},{"location":"changelog.html#features","title":"Features","text":"<ul> <li>System architecture<ul> <li>#356: Add protocol adapter integration pages</li> <li>#359: Update RM specs (post-HHH edition)</li> <li>#369: Rename <code>resourceLogicProofs</code> to <code>logicVerifierInputs</code></li> </ul> </li> <li>Node architecture<ul> <li>#347: Implement interactive engine simulator with message passing support</li> <li>#355: Add engine simulator with message passing and pretty printing</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#358: Deploy pages to another repo</li> <li>#367: Remove redundant deployment</li> <li>#374: EVM-PA: use permalinks and small improvements</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#fixes","title":"Fixes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#343: Fix mkdocs nav</li> <li>#351: Fix/update github actions</li> <li>#363: Enforce pre-commit checks and remove auto-fix</li> <li>#364: Remove pull request template</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#381: Reorganize navigation in mkdocs.yml</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#changes","title":"Changes","text":"<ul> <li>Juvix types and updates<ul> <li>#361: Bump to stdlib 0.11.0 and name convention used for user-defined data types</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#365: Update project configuration and tooling</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v014","title":"v0.1.4","text":"<p>This release focuses on improving the prose, layout, and documentation structure. Key changes include:</p> <ul> <li>Reorganized node architecture documentation for better clarity</li> <li>Reorganized the navigation bar to be more consistent and easier to use</li> <li>Added a new tutorial: Anomian</li> <li>Several prose improvements on engines, e.g: Mempool Worker Engine,   Executor Engine, Shard Engine</li> <li>CSS changes to improve the layout and readability of the website, like   better separation for headers and footers that improve, for example, the   readability of message interfaces</li> <li>Updated Juvix type definitions to match latest standards</li> <li>Added new definitions for Prelude</li> <li>Improved template engine documentation for easier engine creation</li> </ul>","tags":["changelog"]},{"location":"changelog.html#features_1","title":"Features","text":"<ul> <li>System architecture<ul> <li>#334: Add deletion criterion to delete blobs immediately</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#fixes_1","title":"Fixes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#297: Fixes for issues seen in v0.1.3</li> <li>#306: Add data structures and interfaces used by RM</li> <li>#307: Prose improvements for commitment, decryption, and identity   management engines</li> <li>#308: The Little Anomian</li> <li>#309: Heindel has written up their two cents on the Anomian</li> <li>#310: Heindel/Anomian review v0.2 some ideas for improvements</li> <li>#311: Prose improvements for   Mempool Worker Engine, Executor Engine, and Shard Engine's descriptions.</li> <li>#312: nix flake update to   support Juvix v0.6.9</li> <li>#313: Revision of all message interfaces but not for networking's   engines</li> <li>#314: Add more fixes for message interfaces for consistency</li> <li>#315: Add a few corrections to the Anomian doc</li> <li>#320: Update Network subsystems' engine to comply standard</li> <li>#328: Move string comparison to prelude</li> <li>#331: RM type fixes</li> <li>#332: Improve layout, documentation structure, navigation and   readability with indexes, tags and descriptions</li> <li>#336: some changes, proposed as a result of specs overall review   (revamped)</li> <li>#337: Heindel/anthony/prose 3 suggestions for fixing the markdown</li> </ul> </li> <li>System architecture<ul> <li>#334: Add missing deletion criterion to delete blobs after the   transaction</li> </ul> </li> <li>Juvix types and updates<ul> <li>#298: Update juvix v0.6.9</li> <li>#302: Prelude improvements</li> <li>#305: Add most of the types for RM specs</li> <li>#321: Add Runnable trait and make ordering engines parametric</li> <li>#329: Refactor type definitions to use simplified syntax</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v013","title":"v0.1.3","text":"<p>The major change in this release is the gas payment system introduced in #286, and the description of messages in the Networking subsystem introduced in #294.</p>","tags":["changelog"]},{"location":"changelog.html#fixes_2","title":"Fixes","text":"<ul> <li>Node architecture<ul> <li>#290: Fix english   description for guards to match the Juvix types in Engine Behaviour.</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#288: Improve primitive interfaces diagrams. Use LR mermaid option.</li> </ul> </li> <li>System architecture<ul> <li>#293: Fix formatting issues,   typos, warnings, and broken links related to Proving   system definitions.</li> </ul> </li> </ul> <ul> <li>Tutorial and documentation<ul> <li>#280: Guides: Add hard and soft   requirements for writing pages in the Anoma Specification.</li> <li>#284: Add minimal version of   the template (not visible in the website) and related refactors.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#changes_1","title":"Changes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#296: Add next/prev buttons,   fix footer, change font, add buttons to view/edit source code, and links to   the GitHub repository.</li> </ul> </li> <li>Juvix types and updates<ul> <li>#294: Bump up Juvix version   to v0.6.9 , reorder <code>MailboxID</code> alias, and update Stdlib to v0.9.0</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#features_2","title":"Features","text":"<ul> <li>Python-related changes<ul> <li>#291: Add new command tool   <code>nspec</code> to create new engines based on the minimal version of the Template     Engine files.</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#286: Incorporated gas   payments description. Additionally, made several improvements such as   switching to wiki-style links, adding icons, clarifying proof inputs, fixing   rendering issues, and various other enhancements.</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#292: Move template/template_minimum engines to   docs/tutorial/engines folder. Update imports accordingly.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v012","title":"v0.1.2","text":"<p>Progress on translating the old specification to the new Juvix codebase, fixing typechecking errors. Removed unsupported documents from the codebase. Building specs no longer requires Juvix by default - use <code>PROCESS_JUVIX=true</code> flag with mkdocs to process Juvix Markdown.</p>","tags":["changelog"]},{"location":"changelog.html#fixes_3","title":"Fixes","text":"<ul> <li>Node architecture<ul> <li>#235: Revisit Decryption Engine. Changes to the messages,   environment, and behaviour types to conform the recent template changes.</li> <li>#236: Revisit Encryption Engine and Reads Engine. These are   bundled since they rely on eachother's messages. Changes to the messages, environment, and behavior types to conform   to the recent template changes</li> <li>#262: Updatewriting conventions, Fix template   behaviour diagrams and update Mkdocs Na</li> <li>#263: To the Hardware     Subsystem section, add Local Key Value Store Engine , Logging     Engine and Local Time Series Storage Engine, Wall Clock Engine.</li> <li>#268: Add to Anoma Configuration section, the Identity Subsystem.</li> <li>#269: Fix type error due to   not making configs when spawning engines in Identity Management Engine.</li> <li>#273: Replace X Machine by X   Subsystem in the Node Architecture section.</li> </ul> </li> <li>Python-related changes<ul> <li>#271: update mkdocs juvix plugin v0.4.8</li> <li>#272: Update mkdocs juvix plugin v0.4.9</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#195: Optimize documentation build process and upgrade dependencies</li> <li>#262: Template fixes: diagrams, nav</li> <li>#266: Remove old   documentation and update table of contents: Remove basic-abstractions,   scope, applications, implementations, and several other files that were   decided not to be included in this version of the specification.</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#257: Add description of our   Git workflow and new integration   branches strategy.</li> <li>#265: Rename <code>TemplateCfg</code>   to <code>TemplateLocalCfg</code>, add <code>TemplateCfg</code> similar to <code>TemplateEnv</code>, apply   the same to <code>Ticker</code>.</li> <li>#274: Update engine writing   conventions: #update-the-table-of-contents   and Table of Contents.</li> </ul> </li> <li>Juvix types and updates<ul> <li>#267: Fix all the type   checking errors in engine definitions.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v011","title":"v0.1.1","text":"<p>Major revision of the engine definitions, the template, and the ticker engine.</p>","tags":["changelog"]},{"location":"changelog.html#features_3","title":"Features","text":"<ul> <li>Repository maintenance and CI<ul> <li>#217: Update template engine   files to be more consistent, use backticks for Juvix terms/types in   headlines, uncollapsed sections for type constructors arguments in template   engine files, and auxiliary sections of Juvix code are always collapsed.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#fixes_4","title":"Fixes","text":"<ul> <li>Node architecture<ul> <li>#219: Revisit Commitment Engine. Changes to the messages, environment, and behaviour types to conform the recent template changes.</li> <li>#253: Integration PR that   combines multiple engine-related changes: Engines: Use <code>ByteString</code> in   crypto types #242, Engines:   ByteString type definition #255,   Engines: <code>EngineMsg</code> revision #241,   EngineID: make <code>EngineName</code> compulsory #256, Engines: Engine type revision #244,  <code>EngineMsg</code>: add type param #258, Engines: add <code>GuardEval</code> and <code>ActionExec</code> #260, and Engines: Behaviour template revision #226.</li> <li>#256: Make <code>EngineName</code>   compulsory in <code>EngineID</code>.</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#218: Rename <code>EngineMessage</code>    type to <code>EngineMsg</code> and <code>mkEngineMessage</code> to <code>mkEngineMsg</code>.</li> <li>#220: Fix the deployment of    the latest version by deploying the website if the branch name is <code>main</code> or    matches the semver pattern, and add information about the version and the    commit hash to the title for reference.</li> <li>#222: Remove SML codebase as   not used any more and any other reference in the markdown files</li> <li>#225: Fix navigation table    for the identity component</li> <li>#227: Update Juvix version in Nix flake due to breaking changes, and   also the input packages while at it.</li> <li>#250: Update policy on Juvix typechecking. The whole codebase in a   PR should typecheck before merging</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#257: Refactor the Git strategy: introduce integration PRs for   better overview of complex changes</li> </ul> </li> <li>Juvix types and updates<ul> <li>#221: Update the prelude to   incorporate the latest changes in the <code>Stdlib</code>, including the addition of   applicative and monad traits, and the integration of the <code>containers</code> library.   This update also includes changes to data type definitions, with the <code>@</code>   syntax now used for declaration, creation, and matching on records, and other   removals like <code>: Type</code> for implicit arguments and function-style declarations.</li> <li>#226: Update Template &amp; Ticker Behaviour according to the engine &amp; message type changes. The examples have been improved with better clarity. The documentation now uses headlines instead of collapsible boxes and definition lists instead of tables. A new diagram template has been added that illustrates conditions and effects of actions.</li> <li>#241: <code>EngineMsg</code>-related changes: rename <code>MessageID</code> to <code>EngineMsgID</code>, add <code>getEngineMsgFrom(Timestamped)Trigger</code>, and rename <code>getMessageFrom(Timestamped)Trigger</code> to <code>getMsgFrom(Timestamped)Trigger</code>.</li> <li>#242: Use <code>ByteString</code> in crypto types.</li> <li>#244: Major refactoring of   engine-related types. The <code>Engine</code> type now includes a <code>cfg</code> field of type   <code>EngineConfig</code> containing static configuration (engine name and local node   ID). For consistency, <code>EngineEnvironment</code> has been renamed to <code>EngineEnv</code>. The   <code>EngineBehaviour</code> type has undergone several changes: the conflict solver has   been removed (to be replaced by new mechanism in   #246), precomputation results are   now passed directly as action arguments, and the <code>action</code> field has been   replaced with action labels defined by label type.</li> <li>#249: Remove <code>name</code> field in Engine instances due to PR 242</li> <li>#255: Make ByteString <code>String</code> instead of <code>Nat</code></li> <li>#258: Engine-related changes: add type parameter to parameterized the type of message and rename <code>EngineConfig</code> to <code>EngineCfg</code></li> <li>#260: Revise engine behaviour type: add <code>GuardEval (Seq)</code> and <code>ActionExec (First &amp; Any)</code>, <code>EngineCfg</code>: add <code>getEngineIDFromEngineCfg</code>. Partially addresses #246.</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#v010","title":"v0.1.0","text":"<p>This is the first release of Anoma's Spec project, following the semantic-versioning scheme. This version includes all the changes from the creation of this repository. From here on, we will keep a changelog of all the changes that are made to the project per version, with better documentation and descriptions of the changes.</p>","tags":["changelog"]},{"location":"changelog.html#breaking-changes","title":"Breaking changes","text":"<ul> <li>Node architecture<ul> <li>#179: Reorganize node architecture   documentation structure</li> <li>#192: Port identity engines to v2 template</li> </ul> </li> <li>System architecture<ul> <li>#210: Fix engine message, environment and   behavior layout</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#29: Remove unused libraries</li> <li>#30: Remove juvix hook in pro of mkdos Juvix   plugin</li> <li>#53: Setup: require only python 3.9</li> <li>#60: Restructure for v2</li> <li>#64: Change KV Storage Deletion Documentation</li> <li>#65: Delete Compute and Randomness Engines</li> <li>#69: Remove outdates files from arch1 and fix   formatting</li> <li>#104: Refactor scope, basic types, and   application architecture sections</li> <li>#115: Refactor file and folder names: add   snake_case convention</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#bug-fixes","title":"Bug fixes","text":"<ul> <li>Repository maintenance and CI<ul> <li>#4: Fix mike</li> <li>#9: Add batch of fixes</li> <li>#10: Fix Index: quick links and remove empty types   pages</li> <li>#18: Fix TODO, add todos.py script, and more   formatting issues</li> <li>#19: Remove todos on deploy, fix wikilinks warnings</li> <li>#21: Fix whitespaces</li> <li>#22: Fix indexes generation with macros and optimize   caching</li> <li>#24: Fix minors</li> <li>#25: CI fixes</li> <li>#74: Fix broken links in navigation bar and a few   pages</li> <li>#77: Fix CI: deploy website by PRs against main, v1,   and v2</li> <li>#78: Fix: CI doesnt trigger on edits</li> <li>#91: Fix default views and deploys in the CI</li> <li>#96: Fix navigation bar and more broken links due #60</li> <li>#101: Fix typos and small improve wording</li> <li>#105: Fix warnings messages due to recent refactors</li> <li>#122: Fix support for Juvix Markdown snippets</li> <li>#123: Fix merging conflicts chris-update-basic-types</li> <li>#124: Fix tutorial nav structure and broken links in   the footer</li> <li>#132: Fix minor issues with directories and filenames</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"changelog.html#features_4","title":"Features","text":"<ul> <li>Application documentation<ul> <li>#198: Add transparent RM implementation documentation</li> </ul> </li> <li>Python-related changes<ul> <li>#133: Add support for multi-line wiki-style links</li> </ul> </li> <li>Repository maintenance and CI<ul> <li>#2: Add better support for WikiLinks and other goodies</li> <li>#3: Update README and run pre-commit</li> <li>#5: Add Ubuntu dependencies to the CI</li> <li>#6: Use site_url for link generation</li> <li>#7: Add new hook for images</li> <li>#8: Add lightboxes to images, fix local image loading</li> <li>#11: Improve link resolution for urls outside nav</li> <li>#14: Add Last updated time to the footer and other   fixes</li> <li>#15: Add a more explicit MathJax config</li> <li>#17: Revised macros configuration</li> <li>#20: Refactor hooks</li> <li>#23: Add previews for PRs</li> <li>#27: Fix url indexes and improve PR previews</li> <li>#28: Add tutorial basic instructions</li> <li>#31: Translate Haskell snippets to Juvix and fix typos</li> <li>#51: Configuration Engine</li> <li>#52: Add nix flake</li> <li>#56: Add page on dynamic code loading</li> <li>#58: Homogeneous consensus for V2</li> <li>#59: Readme: tighten up install instructions</li> <li>#61: Updates kudos spec</li> <li>#63: Counter example</li> <li>#68: Add New Engine Specifications from Anoma Elixir   Database</li> <li>#75: Add proof-of-stake example</li> <li>#80: Re-introduced full execution machine for V2</li> <li>#81: Add BibTeX entries and fix configuration</li> <li>#84: Add templates for defining engine systems</li> <li>#92: Add global table of contents</li> <li>#95: Continue v2 updates</li> <li>#97: Add git branching strategy</li> <li>#98: Add citation instructions and restructure markdown   tutorials</li> <li>#99: Delete previews for closed PRs on gh-pages branch</li> <li>#100: Split CI workflows: deploy, pull-request, clean-   ups</li> <li>#103: Additional reorganization &amp; updates</li> <li>#117: Tweaks to message types in basics</li> <li>#120: Refactor tutorial organization and add a few   more on conventions</li> <li>#121: Improve look&amp;feel, organized nav, hide extra   links and move them to the footer</li> <li>#127: Update basic abstractions</li> <li>#131: Add RMv3 content</li> <li>#135: Show PR number in the site name</li> <li>#209: Add changelog management system</li> <li>#214: Add GitHub template for creating PRs</li> </ul> </li> <li>Tutorial and documentation<ul> <li>#134: Refactor tutorial for wiki-style links</li> </ul> </li> <li>Juvix types and updates<ul> <li>#128: Add new Juvix definitions from PR-84</li> <li>#130: Translate SML Identity definitions to Juvix</li> </ul> </li> </ul>","tags":["changelog"]},{"location":"everything.html","title":"Everything","text":"<pre><code>module everything;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"everything.html#prelude","title":"Prelude","text":"<pre><code>import prelude;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"everything.html#system","title":"System","text":"<pre><code>import arch.system.identity.identity;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"everything.html#resource-machine","title":"Resource Machine","text":"<pre><code>import arch.system.state.resource_machine.data_structures.transaction.transaction_with_payment;\nimport arch.system.state.resource_machine.data_structures.transaction.transaction;\nimport arch.system.state.resource_machine.data_structures.transaction.transaction_function;\nimport arch.system.state.resource_machine.data_structures.transaction.delta_proof;\nimport arch.system.state.resource_machine.data_structures.compliance_unit.compliance_proof;\nimport arch.system.state.resource_machine.data_structures.compliance_unit.compliance_unit;\nimport arch.system.state.resource_machine.data_structures.action.resource_logic_proof;\nimport arch.system.state.resource_machine.data_structures.action.index;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.resource_commitment;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.kind;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.nullifier;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.delta;\nimport arch.system.state.resource_machine.data_structures.resource.computable_components.introduction;\nimport arch.system.state.resource_machine.data_structures.resource.index;\nimport arch.system.state.resource_machine.primitive_interfaces.transaction_function_vm;\nimport arch.system.state.resource_machine.primitive_interfaces.set;\nimport arch.system.state.resource_machine.primitive_interfaces.nullifier_set;\nimport arch.system.state.resource_machine.primitive_interfaces.map;\nimport arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_types;\nimport arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_delta;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.fixed_size_type;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.hash;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.delta_hash;\nimport arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.arithmetic;\nimport arch.system.state.resource_machine.primitive_interfaces.index;\nimport arch.system.state.resource_machine.primitive_interfaces.ordered_set;\nimport arch.system.state.resource_machine.primitive_interfaces.commitment_accumulator;\nimport arch.system.state.resource_machine.notes.storage;\nimport arch.system.state.resource_machine.notes.function_formats.transaction_function_format;\nimport arch.system.state.resource_machine.notes.applications;\nimport arch.system.state.resource_machine.notes.roles_and_requirements;\nimport arch.system.state.resource_machine.notes.nockma;\nimport arch.system.state.resource_machine.notes.nockma_runnable;\nimport arch.system.state.resource_machine.notes.runnable;\nimport arch.system.state.resource_machine.index;\nimport arch.system.state.resource_machine.execution_flow.flow;\n</code></pre>","tags":["index","juvix"],"boost":2},{"location":"prelude.html","title":"Prelude","text":"Juvix imports <pre><code>module prelude;\nimport Stdlib.Trait open public;\nimport Stdlib.Trait.Ord open using {Ordering; module Ordering; Equal; isEqual} public;\nimport Stdlib.Trait.Eq open using {==} public;\nimport Stdlib.Debug.Fail open using {failwith};\nimport Stdlib.Data.Fixity open public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#juvix-specs-prelude","title":"Juvix Specs Prelude","text":"<p>The following are frequent and basic abstractions used in the Anoma specification.</p>","tags":["prelude","index"]},{"location":"prelude.html#combinators","title":"Combinators","text":"<pre><code>import Stdlib.Function open\n  using {\n    &lt;&lt;;\n    &gt;&gt;;\n    const;\n    id;\n    flip;\n    &lt;|;\n    |&gt;;\n    iterate;\n    &gt;-&gt;;\n  } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#useful-type-classes","title":"Useful Type Classes","text":"","tags":["prelude","index"]},{"location":"prelude.html#functor","title":"<code>Functor</code>","text":"<pre><code>import Stdlib.Trait.Functor.Polymorphic as Functor;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#applicative","title":"<code>Applicative</code>","text":"<pre><code>import Stdlib.Trait.Applicative as Applicative\n  open using\n  { Applicative;\n  } public;\nimport Stdlib.Trait.Applicative as Applicative\n  open using\n  { Applicative;\n  } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#monad","title":"<code>Monad</code>","text":"<pre><code>import Stdlib.Trait.Monad as Monad\n  open using {Monad} public;\nimport Stdlib.Trait.Monad as Monad\n  open using {Monad} public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#join","title":"<code>join</code>","text":"<p>Join function for monads</p> <pre><code>join\n  {M : Type -&gt; Type}\n  {A}\n  {{Monad M}}\n  (mma : M (M A)) : M A :=\n  bind mma id;  -- using the built-in `bind`\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#bifunctor","title":"<code>Bifunctor</code>","text":"<p>Two-argument functor</p> <pre><code>trait\ntype Bifunctor (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    bimap {A B C D} :  (A -&gt; C) -&gt; (B -&gt; D) -&gt; F A B -&gt; F C D\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#associativeproduct","title":"<code>AssociativeProduct</code>","text":"<p>Product with associators</p> <pre><code>trait\ntype AssociativeProduct (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    assocLeft {A B C} : F A (F B C) -&gt; F (F A B) C;\n    assocRight {A B C} : F (F A B) C -&gt; F A (F B C)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#commutativeproduct","title":"<code>CommutativeProduct</code>","text":"<p>Product with commuters</p> <pre><code>trait\ntype CommutativeProduct (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    swap {A B} : F A B -&gt; F B A;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unitalproduct","title":"<code>UnitalProduct</code>","text":"<p>Product with units</p> <pre><code>trait\ntype UnitalProduct U (F : Type -&gt; Type -&gt; Type) :=\n  mk@{\n    unitLeft {A} : A -&gt; F U A;\n    unUnitLeft {A} : F U A -&gt; A;\n    unitRight {A} : A -&gt; F A U;\n    unUnitRight {A} : F A U -&gt; A;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#traversable","title":"<code>Traversable</code>","text":"<pre><code>import Stdlib.Trait.Traversable as Traversable\n  open using {\n    Traversable;\n    sequenceA;\n    traverse;\n    } public;\nimport Stdlib.Trait.Traversable as Traversable\n  open using {\n    Traversable;\n    sequenceA;\n    traverse;\n    } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#bool","title":"Bool","text":"<p>The type <code>Bool</code> represents boolean values (<code>true</code> or <code>false</code>). Used for logical operations and conditions.</p> <pre><code>import Stdlib.Data.Bool as Bool\n  open using\n  { Bool;\n    true;\n    false;\n    &amp;&amp;;\n    ||;\n    not;\n    or;\n    and;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>verdad : Bool := true;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#xor","title":"<code>xor</code>","text":"<p>Exlusive or</p> <pre><code>xor (a b : Bool) : Bool :=\n  if\n    | a := not b\n    | else := b\n  ;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nand","title":"<code>nand</code>","text":"<p>Not and</p> <pre><code>nand (a b : Bool) : Bool := not (and a b);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nor","title":"<code>nor</code>","text":"<p>Not or</p> <pre><code>nor (a b : Bool) : Bool := not (or a b);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nat","title":"<code>Nat</code>","text":"<p>The type <code>Nat</code> represents natural numbers (non-negative integers). Used for counting and indexing.</p> <pre><code>import Stdlib.Data.Nat as Nat\n  open using\n  { Nat;\n    zero;\n    suc;\n    natToString;\n    +;\n    sub;\n    *;\n    div;\n    mod;\n    ==;\n    &lt;=;\n    &gt;;\n    &lt;;\n    min;\n    max;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>ten : Nat := 10;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pred","title":"<code>pred</code>","text":"<p>Predecessor function for natural numbers.</p> <pre><code>pred (n : Nat) : Nat :=\n  case n of {\n    | zero := zero\n    | suc k := k\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#booltonat","title":"<code>boolToNat</code>","text":"<p>Convert boolean to a Bool to a Nat in the standard way of circuits.</p> <pre><code>boolToNat (b : Bool) : Nat :=\n  if\n    | b := 0\n    | else := 1\n  ;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#iszero","title":"<code>isZero</code>","text":"<p>Check if a natural number is zero.</p> <pre><code>isZero (n : Nat) : Bool :=\n  case n of {\n    | zero := true\n    | suc k := false\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#iseven-and-isodd","title":"<code>isEven</code> and <code>isOdd</code>","text":"<p>Parity checking functions</p> <pre><code>isEven (n : Nat) : Bool := mod n 2 == 0;\n</code></pre> <pre><code>isOdd (n : Nat) : Bool := not (isEven n);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#foldnat","title":"<code>foldNat</code>","text":"<p>Fold over natural numbers.</p> <pre><code>terminating\nfoldNat {B} (z : B) (f : Nat -&gt; B -&gt; B) (n : Nat) : B :=\n  case n of {\n    | zero := z\n    | suc k := f k (foldNat z f k)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#iter","title":"<code>iter</code>","text":"<p>Iteration of a function.</p> <pre><code>iter {A} (f : A -&gt; A) (n : Nat) (x : A) : A :=\n  foldNat x \\{_ y := f y} n;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#exp","title":"<code>exp</code>","text":"<p>The exponentiation function.</p> <pre><code>exp (base : Nat) (exponent : Nat) : Nat :=\n  iter \\{product := base * product} exponent 1;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#factorial","title":"<code>factorial</code>","text":"<p>The factorial function.</p> <pre><code>factorial : Nat -&gt; Nat := foldNat 1 \\{k r := suc k * r};\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#gcd","title":"<code>gcd</code>","text":"<p>Greatest common divisor function.</p> <pre><code>terminating\ngcd (a b : Nat) : Nat :=\n  case b of {\n    | zero := a\n    | suc _ := gcd b (mod a b)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#lcm","title":"<code>lcm</code>","text":"<p>Least common multiple function.</p> <pre><code>lcm (a b : Nat) : Nat :=\n  case b of {\n    | zero := zero\n    | suc _ :=\n      case a of {\n        | zero := zero\n        | suc _ := div (a * b) (gcd a b)\n      }\n    };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#string","title":"<code>String</code>","text":"<p>The type <code>String</code> represents sequences of characters. Used for text and communication.</p> <pre><code>import Stdlib.Data.String\n  as String\n  open using\n  { String;\n    ++str;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>hello : String := \"Hello, World!\";\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#comparison-instance-for-string","title":"Comparison instance for <code>String</code>","text":"<pre><code>stringCmp (s1 s2 : String) : Ordering :=\n  if\n    | s1 == s2 := Ordering.Equal\n    | else := Ordering.GreaterThan\n  ;\n\ninstance\nStringOrd : Ord String :=\n  Ord.mk@{\n    compare := stringCmp;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#bytestring","title":"<code>ByteString</code>","text":"<pre><code>ByteString : Type := String;\n</code></pre> <p>A basic type for representing binary data.</p> <pre><code>emptyByteString : ByteString := \"\";\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unit","title":"<code>Unit</code>","text":"<p>The type <code>Unit</code> represents a type with a single value. Often used when a function does not return any meaningful value.</p> <pre><code>import Stdlib.Data.Unit\n  as Unit\n  open using {\n    Unit;\n    unit\n  } public;\n</code></pre> <p>For example,</p> <pre><code>unitValue : Unit := unit;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#trivial","title":"<code>trivial</code>","text":"<p>Unique function to the unit. Universal property of terminal object.</p> <pre><code>trivial {A} : A -&gt; Unit := const unit;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#empty","title":"<code>Empty</code>","text":"<p>The type <code>Empty</code> represents a type with a single value. Often used when a function does not return any meaningful value.</p> <pre><code>axiom Empty : Type;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#explode","title":"<code>explode</code>","text":"<p>Unique function from empty. Universal property of initial object.</p> <pre><code>axiom explode {A} : Empty -&gt; A;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pair-a-b","title":"<code>Pair A B</code>","text":"<p>The type <code>Pair A B</code> represents a tuple containing two elements of types <code>A</code> and <code>B</code>. Useful for grouping related values together.</p> <pre><code>import Stdlib.Data.Pair as Pair;\nopen Pair using { Pair } public;\nopen Pair using { , };\n\nimport Stdlib.Data.Pair as Pair\n  open using\n  { ordProductI;\n    eqProductI\n  } public;\n</code></pre> <pre><code>import Stdlib.Data.Fixity open;\nsyntax alias mkPair := ,;\n</code></pre> <p>For example,</p> <pre><code>pair : Pair Nat Bool := mkPair 42 true;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fst-and-snd","title":"<code>fst</code> and <code>snd</code>","text":"<p>Projections</p> <pre><code>fst {A B} : Pair A B -&gt; A\n  | (mkPair a _) := a;\n</code></pre> <pre><code>snd {A B} : Pair A B -&gt; B\n  | (mkPair _ b) := b;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#paircommutativeproduct","title":"<code>PairCommutativeProduct</code>","text":"<p>Swap components</p> <pre><code>instance\nPairCommutativeProduct : CommutativeProduct Pair :=\n  CommutativeProduct.mk@{\n    swap := \\{p := mkPair (snd p) (fst p)}\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pairassociativeproduct","title":"<code>PairAssociativeProduct</code>","text":"<p>Pair associations</p> <pre><code>instance\nPairAssociativeProduct : AssociativeProduct Pair :=\n  AssociativeProduct.mk@{\n    assocLeft := \\{p :=\n      let pbc := snd p;\n      in mkPair (mkPair (fst p) (fst pbc)) (snd pbc)\n    };\n    assocRight := \\{p :=\n      let pab := fst p;\n      in mkPair (fst pab) (mkPair (snd pab) (snd p))\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pairunitalproduct","title":"<code>PairUnitalProduct</code>","text":"<p>Unit maps for pairs and units</p> <pre><code>instance\nPairUnitalProduct : UnitalProduct Unit Pair :=\n  UnitalProduct.mk@{\n    unitLeft := \\{a := mkPair unit a};\n    unUnitLeft := snd;\n    unitRight := \\{a := mkPair a unit};\n    unUnitRight := \\{{A} := fst};\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#pairbifunctor","title":"<code>PairBifunctor</code>","text":"<p>Map functions over pairs</p> <pre><code>instance\nPairBifunctor : Bifunctor Pair :=\n  Bifunctor.mk@{\n    bimap := \\{f g p := mkPair (f (fst p)) (g (snd p))};\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fork","title":"<code>fork</code>","text":"<p>Universal property of pairs</p> <pre><code>fork\n  {A B C}\n  (f : C -&gt; A)\n  (g : C -&gt; B)\n  (c : C) : Pair A B :=\n  mkPair (f c) (g c);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#result-a-b","title":"<code>Result A B</code>","text":"<p>The <code>Result A B</code> type represents either a success with a value of <code>ok x</code> with <code>x</code> of type <code>A</code> or an error with value <code>error e</code> with <code>e</code> of type <code>B</code>.</p> <pre><code>import Stdlib.Data.Result.Base as Result;\nopen Result using { Result; ok; error } public;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#either-a-b","title":"<code>Either A B</code>","text":"<p>The type <code>Either A B</code>, or sum type of <code>A</code> and <code>B</code>, represents a value of type <code>A</code> or <code>B</code>. It is equivalent to <code>Result A B</code>, however, the meaning of the values is different. There is no such thing as an error or success value in the <code>Either</code> type, instead the values are either <code>left a</code> of type <code>A</code> or <code>right b</code> of type <code>B</code>.</p> <pre><code>syntax alias Either := Result;\nsyntax alias left := error;\nsyntax alias right := ok;\n</code></pre> <p>For example,</p> <pre><code>thisString : Either String Nat := left \"Error!\";\nthisNumber : Either String Nat := right 42;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#isleft-and-isright","title":"<code>isLeft</code> and <code>isRight</code>","text":"<p>Check components of either.</p> <pre><code>isLeft {A B} (e : Either A B) : Bool :=\n  case e of {\n    | left _ := true\n    | right _ := false\n  };\n</code></pre> <pre><code>isRight {A B} (e : Either A B) : Bool :=\n  case e of {\n    | left _ := false\n    | right _ := true\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fromleft","title":"<code>fromLeft</code>","text":"<p>Get left element (with default)</p> <pre><code>fromLeft {A B} (e : Either A B) (d : A) : A :=\n  case e of {\n    | (left x) := x\n    | (right _) := d\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fromright","title":"<code>fromRight</code>","text":"<p>Get right element (with default)</p> <pre><code>fromRight {A B} (e : Either A B) (d : B) : B :=\n  case e of {\n    | (left _) := d\n    | (right x) := x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eithercommutativeproduct","title":"<code>EitherCommutativeProduct</code>","text":"<p>Swap elements</p> <pre><code>swapEither {A B} (e : Either A B) : Either B A :=\n  case e of {\n    | (left x) := right x\n    | (right x) := left x\n  };\n</code></pre> <pre><code>instance\nEitherCommutativeProduct : CommutativeProduct Either :=\n  CommutativeProduct.mk@{ swap := swapEither };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherbifunctor","title":"<code>EitherBifunctor</code>","text":"<p>Map onto elements of either</p> <pre><code>eitherBimap\n  {A B C D}\n  (f : A -&gt; C)\n  (g : B -&gt; D)\n  (e : Either A B) : Either C D :=\n  case e of {\n    | (left a) := left (f a)\n    | (right b) := right (g b)\n  };\n</code></pre> <pre><code>instance\nEitherBifunctor : Bifunctor Either :=\n  Bifunctor.mk@{\n    bimap := eitherBimap\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherunitalproduct","title":"<code>EitherUnitalProduct</code>","text":"<p>Unit maps for Either and Empty</p>","tags":["prelude","index"]},{"location":"prelude.html#ununitlefteither","title":"<code>unUnitLeftEither</code>","text":"<pre><code>unUnitLeftEither {A} (e : Either Empty A) : A :=\n  case e of {\n    | left x := explode x\n    | right x := x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#ununitrighteither","title":"<code>unUnitRightEither</code>","text":"<pre><code>unUnitRightEither {A} (e : Either A Empty) : A :=\n  case e of {\n    | left x := x\n    | (right x) := explode x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherunitalproduct_1","title":"<code>EitherUnitalProduct</code>","text":"<p>Unit maps for Either and Empty</p> <pre><code>instance\nEitherUnitalProduct : UnitalProduct Empty Either :=\n  UnitalProduct.mk@{\n    unitLeft := right;\n    unUnitLeft := unUnitLeftEither;\n    unitRight := \\{{A} := left};\n    unUnitRight := unUnitRightEither;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fuse","title":"<code>fuse</code>","text":"<p>Universal property of coproduct</p> <pre><code>fuse\n  {A B C}\n  (f : A -&gt; C)\n  (g : B -&gt; C)\n  (e : Either A B) : C :=\n  case e of {\n    | (left x) := f x\n    | (right x) := g x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherassociativeproduct","title":"<code>EitherAssociativeProduct</code>","text":"<p>Association functions for either</p>","tags":["prelude","index"]},{"location":"prelude.html#assoclefteither","title":"<code>assocLeftEither</code>","text":"<pre><code>assocLeftEither\n  {A B C}\n  (e : Either A (Either B C)) : Either (Either A B) C :=\n  case e of {\n    | (left x) := left (left x)\n    | (right ebc) :=\n      case ebc of {\n        | (left y) := left (right y)\n        | (right z) := right z\n      }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#assocrighteither","title":"<code>assocRightEither</code>","text":"<pre><code>assocRightEither\n  {A B C}\n  (e : Either (Either A B) C)\n  : Either A (Either B C) :=\n  case e of {\n    | (left eab) :=\n      case eab of {\n        | (left x) := left x\n        | (right y) := right (left y)\n      }\n    | (right z) := right (right z)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#eitherassociativeproduct_1","title":"<code>EitherAssociativeProduct</code>","text":"<pre><code>instance\nEitherAssociativeProduct : AssociativeProduct Either :=\n  AssociativeProduct.mk@{\n    assocLeft := assocLeftEither;\n    assocRight := assocRightEither;\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#option-a","title":"<code>Option A</code>","text":"<p>The type <code>Option A</code> represents an optional value of type <code>A</code>. It can be either <code>Some A</code> (containing a value) or <code>None</code> (no value). This type is an alias for <code>Maybe A</code> from the standard library.</p> <pre><code>import Stdlib.Data.Maybe as Maybe;\nopen Maybe using {\n    Maybe;\n    just;\n    nothing\n  };\n</code></pre> <pre><code>syntax alias Option := Maybe;\nsyntax alias some := just;\nsyntax alias none := nothing;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#isnone","title":"<code>isNone</code>","text":"<p>Check if an optional value is <code>none</code>:</p> <pre><code>isNone {A} (x : Option A) : Bool\n  := case x of {\n  | none := true\n  | some _ := false\n  }\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#issome","title":"<code>isSome</code>","text":"<p>Check if an optional value is <code>some</code>:</p> <pre><code>isSome {A} (x : Option A) : Bool := not (isNone x);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#fromoption","title":"<code>fromOption</code>","text":"<p>Extract the value from an <code>Option</code> term:</p> <pre><code>fromOption {A} (x : Option A) (default : A) : A :=\n  case x of {\n  | none := default\n  | some x := x\n};\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#option","title":"<code>option</code>","text":"<p>Map over option with default</p> <pre><code>option\n  {A B}\n  (o : Option A)\n  (default : B)\n  (f : A -&gt; B)\n  : B :=\n  case o of {\n    | none := default\n    | some x := f x\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#filteroption","title":"<code>filterOption</code>","text":"<p>Filter option according to predicate</p> <pre><code>filterOption\n  {A}\n  (p : A -&gt; Bool)\n  (opt : Option A) : Option A :=\n  case opt of {\n    | none := none\n    | some x :=\n      if\n        | p x := some x\n        | else := none\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#list-a","title":"<code>List A</code>","text":"<p>The type <code>List A</code> represents a sequence of elements of type <code>A</code>. Used for collections and ordered data.</p> <pre><code>import Stdlib.Data.List as List\n  open using {\n  List;\n  nil;\n  ::;\n  isElement;\n  head;\n  tail;\n  length;\n  take;\n  drop;\n  ++;\n  reverse;\n  any;\n  all;\n  zip;\n} public;\n</code></pre> <p>For example,</p> <pre><code>numbers : List Nat := 1 :: 2 :: 3 :: nil;\n-- alternative syntax:\nniceNumbers : List Nat := [1 ; 2 ; 3];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#findindex","title":"<code>findIndex</code>","text":"<p>Get the first index of an element satisfying a predicate if such an index exists and none, otherwise.</p> <pre><code>findIndex {A} (predicate : A -&gt; Bool) : List A -&gt; Option Nat\n  | nil := none\n  | (x :: xs) :=\n    if\n      | predicate x := some zero\n      | else := case findIndex predicate xs of\n        | none := none\n        | some i := some (suc i);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#last","title":"<code>last</code>","text":"<p>Get last element of a list</p> <pre><code>last {A} (lst : List A) (default : A) : A :=\n  head default (reverse lst);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#most","title":"<code>most</code>","text":"<p>Get list with last element dropped</p> <pre><code>most {A} (lst : List A) : List A :=\n  tail (reverse lst);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#snoc","title":"<code>snoc</code>","text":"<p>Prepend element to a list</p> <pre><code>snoc {A} (xs : List A) (x : A) : List A :=\n  xs ++ [x];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#uncons","title":"<code>uncons</code>","text":"<p>Split one layer of list</p> <pre><code>uncons {A} : List A -&gt; Option (Pair A (List A))\n  | nil := none\n  | (x :: xs) := some (mkPair x xs)\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unsnoc","title":"<code>unsnoc</code>","text":"<p>Split one layer of list from the end</p> <pre><code>unsnoc {A} : List A -&gt; Option (Pair (List A) A)\n  | nil := none\n  | (x :: xs) := some (mkPair (most (x :: xs)) (last xs x))\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unfold","title":"<code>unfold</code>","text":"<p>Unfold a list, layerwise</p> <pre><code>terminating\nunfold {A B}\n  (step : B -&gt; Option (Pair A B))\n  (seed : B) : List A :=\n  case step seed of\n    | none := nil\n    | some (x, seed') := x :: unfold step seed';\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#unzip","title":"<code>unzip</code>","text":"<p>Unzip a list of pairs into two lists</p> <pre><code>terminating\nunzip {A B}\n  (xs : List (Pair A B)) : Pair (List A) (List B) :=\n  case xs of {\n    | nil := mkPair nil nil\n    | p :: ps :=\n      let unzipped := unzip ps\n      in mkPair (fst p :: fst unzipped) (snd p :: snd unzipped)\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#partitioneither","title":"<code>partitionEither</code>","text":"<p>Partition a list</p> <pre><code>partitionEither\n  {A B} (es : List (Either A B)) : Pair (List A) (List B) :=\n  foldr\n    (\\{e acc :=\n      case e of {\n        | left a := mkPair (a :: (fst acc)) (snd acc)\n        | right b := mkPair (fst acc) (b :: (snd acc))\n      }})\n    (mkPair nil nil)\n    es;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#partitioneitherwith","title":"<code>partitionEitherWith</code>","text":"<pre><code>partitionEitherWith\n  {A B C}\n  (f : C -&gt; Either A B)\n  (es : List C) : Pair (List A) (List B) :=\n  partitionEither (map f es);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#catoptions","title":"<code>catOptions</code>","text":"<p>Collapse list of options</p> <pre><code>catOptions {A} : List (Option A) -&gt; List A :=\n  foldr\n    (\\{opt acc :=\n      case opt of {\n        | none := acc\n        | some x := x :: acc\n      }})\n    nil;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#maximumby","title":"<code>maximumBy</code>","text":"<p>Get the maximal element of a list.</p> <pre><code>maximumBy {A B} {{Ord B}}\n  (f : A -&gt; B)\n  (lst : List A)\n  : Option A :=\n  let maxHelper := \\{curr acc :=\n    case acc of {\n      | none := some curr\n      | some maxVal :=\n        if\n          | f curr &gt; f maxVal := some curr\n          | else := some maxVal\n    }\n  };\n  in foldr maxHelper none lst;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#minimumby","title":"<code>minimumBy</code>","text":"<p>Get the minimal element of a list.</p> <pre><code>minimalBy {A B} {{Ord B}}\n  (f : A -&gt; B)\n  (lst : List A)\n  : Option A :=\n  let minHelper := \\{curr acc :=\n    case acc of {\n      | none := some curr\n      | some minVal :=\n        if\n          | f curr &lt; f minVal := some curr\n          | else := some minVal\n    }\n  };\n  in foldr minHelper none lst;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#chunksof","title":"<code>chunksOf</code>","text":"<p>Splits a list into chunks of size <code>n</code>. The last chunk may be smaller than <code>n</code> if the length of the list is not divisible by <code>n</code>.</p> <p>Example:</p> <ul> <li>chunksOf 2 [1;2;3;4;5] = [[1;2]; [3;4]; [5]]</li> </ul> <pre><code>terminating\nchunksOf {A} : (chunkSize : Nat) -&gt; (list : List A) -&gt; List (List A)\n  | zero _ := nil\n  | _ nil := nil\n  | n xs := take n xs :: chunksOf n (drop n xs);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#sliding","title":"<code>sliding</code>","text":"<p>Returns all contiguous sublists of size <code>n</code>. If <code>n</code> is larger than the list length, returns empty list. If <code>n</code> is zero, returns empty list.</p> <p>Example: - sliding 2 [1;2;3;4] = [[1;2]; [2;3]; [3;4]]</p> <pre><code>sliding {A} : (windowSize : Nat) -&gt; (list : List A) -&gt; List (List A)\n  | zero _ := nil\n  | n xs :=\n    let\n      len : Nat := length xs;\n      terminating\n      go : List A -&gt; List (List A)\n        | nil := nil\n        | ys :=\n          if\n            | length ys &lt; n := nil\n            | else := take n ys :: go (tail ys);\n    in if\n      | n &gt; len := nil\n      | else := go xs;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#span","title":"<code>span</code>","text":"<p>Takes a predicate and a list, and returns a tuple where:</p> <ul> <li>First element is the longest prefix of the list that satisfies the predicate</li> <li>Second element is the remainder of the list</li> </ul> <pre><code>span {A} (p : A -&gt; Bool) : List A -&gt; Pair (List A) (List A)\n  | nil := mkPair nil nil\n  | (x :: xs) :=\n    if\n      | p x :=\n        let\n          (ys1, ys2) := span p xs;\n        in mkPair (x :: ys1) ys2\n      | else := mkPair nil (x :: xs);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#groupby-and-group","title":"<code>groupBy</code> and <code>group</code>","text":"<p>Groups consecutive elements in a list that satisfy a given equality predicate.</p> <p>Example:</p> <ul> <li>groupBy (==) [1;1;2;2;2;3;1;1] = [[1;1];[2;2;2];[3];[1;1]]</li> </ul> <pre><code>terminating\ngroupBy {A} (eq : A -&gt; A -&gt; Bool) : List A -&gt; List (List A)\n  | nil := nil\n  | (x :: xs) :=\n    case span (eq x) xs of\n      ys1, ys2 := (x :: ys1) :: groupBy eq ys2;\n</code></pre> <pre><code>group {A} {{Eq A}} : List A -&gt; List (List A) := groupBy (==)\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nubby","title":"<code>nubBy</code>","text":"<p>Returns a list with duplicates removed according to the given equivalence function, keeping the first occurrence of each element. Unlike regular ;nub;, this function allows specifying a custom equality predicate.</p> <p>Examples:</p> <ul> <li>nubBy ({x y := mod x 3 == mod y 3}) [1;2;3;4;5;6] = [1;2;3]</li> <li>nub [1;1;2;2;3;3] = [1;2;3]</li> </ul> <pre><code>nubBy {A} (eq : A -&gt; A -&gt; Bool) : List A -&gt; List A :=\n  let\n    -- Checks if an element is already in the accumulator\n    elemBy (x : A) : List A -&gt; Bool\n      | nil := false\n      | (y :: ys) := eq x y || elemBy x ys;\n\n    go : List A -&gt; List A -&gt; List A\n      | acc nil := reverse acc\n      | acc (x :: xs) :=\n        if\n          | elemBy x acc := go acc xs\n          | else := go (x :: acc) xs;\n  in go nil;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#nub","title":"<code>nub</code>","text":"<pre><code>nub {A} {{Eq A}} : List A -&gt; List A := nubBy (==);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#powerlists","title":"<code>powerlists</code>","text":"<p>Generate all possible sublists of a list. Each element can either be included or not.</p> <pre><code>powerlists {A} : List A -&gt; List (List A)\n  | nil := nil :: nil\n  | (x :: xs) :=\n    let\n      rest : List (List A) := powerlists xs;\n      withX : List (List A) := map ((::) x) rest;\n    in rest ++ withX;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#set-a","title":"<code>Set A</code>","text":"<p>The type <code>Set A</code> represents a collection of unique elements of type <code>A</code>. Used for sets of values.</p> <pre><code>import Stdlib.Data.Set as Set open using {\n    Set; module Set;\n    difference;\n    union;\n    insert;\n    eqSetI;\n    ordSetI;\n    isSubset;\n  } public;\n</code></pre> <p>For example,</p> <pre><code>uniqueNumbers : Set Nat := Set.fromList [1 ; 2 ; 2 ; 2; 3];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#setmap","title":"<code>setMap</code>","text":"<pre><code>setMap {A B} {{Ord B}} (f : A -&gt; B) (set : Set A) : Set B :=\n  Set.fromList (map f (Set.toList set));\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#setjoin","title":"<code>setJoin</code>","text":"<p>Collapse a set of sets into a set</p> <pre><code>setJoin {A} {{Ord A}} (sets : Set (Set A)) : Set A :=\n  for (acc := Set.empty) (innerSet in sets) {\n    Set.union acc innerSet\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#disjointunion","title":"<code>disjointUnion</code>","text":"<pre><code>--- Computes the disjoint union of two ;Set;s.\ndisjointUnion {T} {{Ord T}} (s1 s2 : Set T) : Result (Set T) (Set T) :=\n  case Set.intersection s1 s2 of\n    | Set.empty := ok (Set.union s1 s2)\n    | s := error s;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#symmetricdifference","title":"<code>symmetricDifference</code>","text":"<p>Caclulate the symmetric difference of two sets.</p> <pre><code>symmetricDifference\n  {A} {{Ord A}} (s1 s2 : Set A) : Set A :=\n  let\n    in1not2 := difference s1 s2;\n    in2not1 := difference s2 s1;\n  in union in1not2 in2not1;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#cartesianproduct","title":"<code>cartesianProduct</code>","text":"<p>Generate the set of all cartesian products of a set.</p> <pre><code>cartesianProduct\n  {A B}\n  {{Ord A}} {{Ord B}}\n  (s1 : Set A)\n  (s2 : Set B)\n  : Set (Pair A B) :=\n  let\n    -- For a fixed element from set1, create a set of all pairs with elements from s2\n    pairsForElement (a : A) : Set (Pair A B) :=\n      for (acc := Set.empty) (b in s2) {\n        insert (mkPair a b) acc\n      };\n\n    -- Create set of sets, each containing pairs for one element from s1\n    pairSets : Set (Set (Pair A B)) :=\n      for (acc := Set.empty) (a in s1) {\n        insert (pairsForElement a) acc\n      };\n  in setJoin pairSets;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#powerset","title":"<code>powerset</code>","text":"<p>Generate the powerset (set of all subsets) of a set.</p> <pre><code>powerset {A} {{Ord A}} (s : Set A) : Set (Set A) :=\n  let\n    elements := Set.toList s;\n    subLists := powerlists elements;\n  in Set.fromList (map Set.fromList subLists);\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#ispropersubset","title":"<code>isProperSubset</code>","text":"<p>Checks if all elements of <code>set1</code> are in <code>set2</code>, and that the two sets are not the same.</p> <pre><code>isProperSubset {A} {{Eq A}} {{Ord A}} (set1 set2 : Set A) : Bool :=\n  isSubset set1 set2 &amp;&amp; not (set1 == set2)\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#map-k-v","title":"<code>Map K V</code>","text":"<p>The type <code>Map K V</code> represents a collection of key-value pairs, sometimes called a dictionary, where keys are of type <code>K</code> and values are of type <code>V</code>.</p> <pre><code>import Stdlib.Data.Map as Map public;\nopen Map using {\n    Map\n  } public;\n</code></pre> <p>For example,</p> <pre><code>codeToken : Map Nat String := Map.fromList [ (1 , \"BTC\") ; (2 , \"ETH\") ; (3, \"ANM\")];\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#updatelookupwithkey","title":"<code>updateLookupWithKey</code>","text":"<p>Updates a value at a specific key using the update function and returns both the old value (if the key existed) and the updated map.</p> <pre><code>updateLookupWithKey\n  {Key Value}\n  {{Ord Key}}\n  (updateFn : Key -&gt; Value -&gt; Option Value)\n  (k : Key)\n  (map : Map Key Value)\n  : Pair (Option Value) (Map Key Value) :=\n  let\n    oldValue : Option Value := Map.lookup k map;\n    newMap : Map Key Value :=\n      case oldValue of {\n        | none := map\n        | some v :=\n          case updateFn k v of {\n            | none := Map.delete k map\n            | some newV := Map.insert k newV map\n          }\n      };\n  in oldValue, newMap;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapkeys","title":"<code>mapKeys</code>","text":"<p>Maps all keys in the Map to new keys using the provided function. If the mapping function is not injective (maps different keys to the same key), later entries in the map will overwrite earlier ones with the same new key.</p> <pre><code>mapKeys\n  {Key1 Key2 Value}\n  {{Ord Key2}}\n  (fun : Key1 -&gt; Key2)\n  (map : Map Key1 Value)\n  : Map Key2 Value :=\n  Map.fromList\n    (for (acc := nil) ((k, v) in Map.toList map) {\n      (fun k, v) :: acc\n    });\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#restrictkeys","title":"<code>restrictKeys</code>","text":"<p>Restrict a map to only contain keys from the given set.</p> <pre><code>restrictKeys\n  {Key Value}\n  {{Ord Key}}\n  (map : Map Key Value)\n  (validKeys : Set.Set Key)\n  : Map Key Value :=\n  for (acc := Map.empty) (k, v in map) {\n    if\n      | Set.isMember k validKeys := Map.insert k v acc\n      | else := acc\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#withoutkeys","title":"<code>withoutKeys</code>","text":"<p>Remove all entries from a map whose keys appear in the given set.</p> <pre><code>withoutKeys\n  {Key Value}\n  {{Ord Key}}\n  (map : Map Key Value)\n  (invalidKeys : Set.Set Key)\n  : Map Key Value :=\n  for (acc := Map.empty) (k, v in map) {\n    if\n      | Set.isMember k invalidKeys := acc\n      | else := Map.insert k v acc\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mappartition","title":"<code>mapPartition</code>","text":"<p>Split a map according to a predicate on values. Returns a pair of maps, (matching, non-matching).</p> <pre><code>mapPartition\n  {Key Value}\n  {{Ord Key}}\n  (predicate : Value -&gt; Bool)\n  (map : Map Key Value)\n  : Pair (Map Key Value) (Map Key Value) :=\n  for (matching, nonMatching := Map.empty, Map.empty) (k, v in map) {\n    if\n      | predicate v := Map.insert k v matching, nonMatching\n      | else := matching, Map.insert k v nonMatching\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#partitionwithkey","title":"<code>partitionWithKey</code>","text":"<p>Split a map according to a predicate that can examine both key and value. Returns a pair of maps, (matching, non-matching).</p> <pre><code>partitionWithKey\n  {Key Value}\n  {{Ord Key}}\n  (predicate : Key -&gt; Value -&gt; Bool)\n  (map : Map Key Value)\n  : Pair (Map Key Value) (Map Key Value) :=\n  for (matching, nonMatching := Map.empty, Map.empty) (k, v in map) {\n    if\n      | predicate k v := Map.insert k v matching, nonMatching\n      | else := matching, Map.insert k v nonMatching\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapoption","title":"<code>mapOption</code>","text":"<p>Apply a partial function to all values in the map, keeping only the entries where the function returns 'some'.</p> <pre><code>mapOption\n  {Key Value1 Value2} {{Ord Key}}\n  (f : Value1 -&gt; Option Value2)\n  (map : Map Key Value1)\n  : Map Key Value2 :=\n  for (acc := Map.empty) (k, v in map) {\n    case f v of {\n      | none := acc\n      | some v' := Map.insert k v' acc\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapoptionwithkey","title":"<code>mapOptionWithKey</code>","text":"<p>Same as mapOption but allows the function to examine the key as well.</p> <pre><code>mapOptionWithKey\n  {Key Value1 Value2} {{Ord Key}}\n  (f : Key -&gt; Value1 -&gt; Option Value2)\n  (map : Map Key Value1)\n  : Map Key Value2 :=\n  for (acc := Map.empty) (k, v in map) {\n    case f k v of {\n      | none := acc\n      | some v' := Map.insert k v' acc\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapeither","title":"<code>mapEither</code>","text":"<p>Apply a function that returns Either to all values in the map.</p> <pre><code>mapEither\n  {Key Value Error Result}\n  {{Ord Key}}\n  (f : Value -&gt; Either Error Result)\n  (map : Map Key Value)\n  : Pair (Map Key Error) (Map Key Result) :=\n  for (lefts, rights := Map.empty, Map.empty) (k, v in map) {\n    case f v of {\n      | error e := Map.insert k e lefts, rights\n      | ok r := lefts, Map.insert k r rights\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#mapeitherwithkey","title":"<code>mapEitherWithKey</code>","text":"<p>Same as mapEither but allows the function to examine the key as well.</p> <pre><code>mapEitherWithKey\n  {Key Value Error Result}\n  {{Ord Key}}\n  (f : Key -&gt; Value -&gt; Either Error Result)\n  (map : Map Key Value)\n  : Pair (Map Key Error) (Map Key Result) :=\n  for (lefts, rights := Map.empty, Map.empty) (k, v in map) {\n    case f k v of {\n      | error e := Map.insert k e lefts, rights\n      | ok r := lefts, Map.insert k r rights\n    }\n  };\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#undefined-values","title":"Undefined values","text":"<p>The term <code>undef</code> is a placeholder for unspecified values.</p>","tags":["prelude","index"]},{"location":"prelude.html#undef","title":"<code>undef</code>","text":"<pre><code>axiom undef {A} : A;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#todo","title":"<code>TODO</code>","text":"<pre><code>axiom TODO {A} : A;\n</code></pre>","tags":["prelude","index"]},{"location":"prelude.html#omap-k-v","title":"<code>OMap K V</code>","text":"<p>A simple map implementation represented as a function from keys to optional values. Note: Unlike <code>Stdlib.Data.Map</code>, this implementation does not require an <code>Ord</code> instance for the key type <code>K</code>. However, operations like <code>insert</code>, <code>delete</code>, and <code>fromList</code> require an <code>Eq</code> instance instead of an <code>Ord</code> instance.</p> <p>Meant for usage with <code>String</code> which does not have a working <code>Ord</code> instance but does have a working <code>Eq</code> instance.</p> <pre><code>module OMap;\n\n  type OMap K V := mk@{\n    omap : K -&gt; Option V\n  };\n\n  -- The empty map maps every key to `none`.\n  empty {K V} : OMap K V := OMap.mk \\{_ := none};\n\n  -- Look up a key in the map.\n  lookup {K V} (k : K) (m : OMap K V) : Option V := OMap.omap m k;\n\n  -- Insert a key-value pair. Requires an equality function for the key type.\n  insert {K V} {{Eq K}} (k : K) (v : V) (m : OMap K V) : OMap K V :=\n    OMap.mk@{omap := \\{k' := if | k == k' := some v\n                                | else := OMap.omap m k'}};\n\n  -- Delete a key. Requires an equality function for the key type.\n  delete {K V} {{Eq K}} (k : K) (m : OMap K V) : OMap K V :=\n    OMap.mk@{omap := \\{k' := if | k == k' := none\n                                | else := OMap.omap m k'}};\n\n  -- Create a map from a list of key-value pairs. Requires an equality function.\n  fromList {K V} {{Eq K}} (pairs : List (Pair K V)) : OMap K V :=\n    foldl (\\{m (k, v) := insert k v m}) empty pairs;\n\n  -- Map a function over the values of the map.\n  map {K V1 V2} (f : V1 -&gt; V2) (m : OMap K V1) : OMap K V2 :=\n    OMap.mk@{omap := \\{k := Functor.map f (OMap.omap m k)}};\n\n  -- Apply a function that returns an Option to values, keeping only `some` results.\n  mapOption {K V1 V2} (f : V1 -&gt; Option V2) (m : OMap K V1) : OMap K V2 :=\n    OMap.mk@{omap := \\{k := case OMap.omap m k of { none := none | some v1 := f v1 }}};\n\n  -- Apply a function that returns an Option to keys and values, keeping only `some` results.\n  mapOptionWithKey {K V1 V2} (f : K -&gt; V1 -&gt; Option V2) (m : OMap K V1) : OMap K V2 :=\n    OMap.mk@{omap := \\{k := case OMap.omap m k of { none := none | some v1 := f k v1 }}};\n\n  -- Fold over the map *given a specific list of keys*.\n  -- Note: A true fold isn't possible without knowing the domain.\n  foldWithKeys {K V Acc} (f : K -&gt; V -&gt; Acc -&gt; Acc) (init : Acc) (keys : List K) (m : OMap K V) : Acc :=\n    foldl\n      (\\{acc k := case OMap.omap m k of { none := acc | some v := f k v acc }})\n      init\n      keys;\n\n  -- Create a map with a single key-value pair.\n  singleton {K V} {{Eq K}} (k : K) (v : V) : OMap K V :=\n    OMap.mk@{omap := \\{k' := if | k == k' := some v | else := none}};\n\nend;\n</code></pre>","tags":["prelude","index"]},{"location":"arch/overview.html","title":"Anoma architecture","text":"<p>The Anoma architecture is the blueprint that defines the structure and behaviour of the components that make up the Anoma protocol. There is one high-level component: the System architecture<sup>1</sup>.</p>","tags":["index"],"boost":2},{"location":"arch/overview.html#system-architecture","title":"System architecture","text":"<p>Defines the high-level structure and behaviour of the distributed network, including:</p> <ul> <li>Distributed state management </li> <li>Core data types and data flow for Network operations</li> <li>System-wide properties and guarantees</li> </ul> <ol> <li> <p>The Node architecture is a work-in-progress and can be found in the v0.2.0 release.\u00a0\u21a9</p> </li> </ol>","tags":["index"],"boost":2},{"location":"arch/integrations/adapters/index.html","title":"Protocol Adapters","text":"<p>A protocol adapter provides executor engine and shard engine functionality on a foreign blockchain protocol (adaptee) being independent of the Anoma protocol (target). In other words, it processes resource machine (RM) transactions and updates the RM state in correspondence with the adaptee's state changes.</p> <p>In general, the aim of a protocol adapter is to allow Anoma applications to be run on existing chains (similar to how drivers allow an operating system to be run on different pieces of physical hardware).</p> <p>In order to support a protocol adapter, the adaptee protocol has to be programmable (i.e., support smart contracts).</p>","tags":["index","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/index.html#instances","title":"Instances","text":"<ul> <li>Ethereum Virtual Machine protocol adapter (settlement-only)</li> </ul>","tags":["index","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/index.html","title":"Ethereum Virtual Machine Protocol Adapter","text":"<p>The Ethereum Virtual Machine (EVM) protocol adapter is a smart contract written in Solidity that can be deployed to any EVM-compatible chain in order to allow it to support Anoma applications.</p> <p>The current prototype is a settlement-only protocol adapter, i.e., it is only capable of processing fully-evaluated transaction functions and therefore does not implement the full executor engine behaviour.</p> <p>The implementation can be found in the <code>anoma/evm-protocol-adapter</code> GH repo.</p>","tags":["index","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/index.html#supported-networks","title":"Supported Networks","text":"<p>For the upcoming product version, the Protocol Adapter will be deployed on Ethereum Mainnet, Arbitrum, and Base.</p>","tags":["index","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/index.html#contents","title":"Contents","text":"<ul> <li>Primitive Interfaces</li> <li>Datatypes</li> <li>Execution Flow</li> <li>EVM Interoperability</li> </ul>","tags":["index","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/data_structures.html","title":"EVM Resource Machine Datatypes","text":"<p>This section contains the descriptions of the RM datatype implementations and their interfaces.</p> <p>The \"Proof\" sections try to describe the explicit implementation details that may differ from the original RM specification.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/data_structures.html#resource","title":"Resource","text":"<p>A resource is implemented as the following Solidity struct:</p> <pre><code>struct Resource {\n    bytes32 logicRef;\n    bytes32 labelRef;\n    bytes32 valueRef;\n    bytes32 nullifierKeyCommitment;\n    bytes32 nonce;\n    bytes32 randSeed;\n    uint128 quantity;\n    bool ephemeral;\n}\n</code></pre>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/data_structures.html#resource-computable-components","title":"Resource Computable Components","text":"Commitment <p>A commitment of resource <code>resource</code> is computed as packed bytes of the resource fields alongside with hardcoded 17 bytes prepending randomness values:</p> <pre><code>    function commitment(Resource memory resource) internal pure returns (bytes32 cm) {\n        cm = sha256(\n            abi.encodePacked(\n                resource.logicRef,\n                resource.labelRef,\n                resource.quantity,\n                resource.valueRef,\n                resource.ephemeral,\n                resource.nonce,\n                resource.nullifierKeyCommitment,\n                rcm(resource)\n            )\n        );\n    }\n\n    function rcm(Resource memory resource) internal pure returns (bytes32 randCm) {\n        bytes17 prfExpandPersonalization = 0x52495343305f457870616e645365656401;\n        randCm = sha256(abi.encodePacked(prfExpandPersonalization, resource.randSeed, resource.nonce));\n    }\n</code></pre> Nullifier <p>A nullifier of a resource <code>resource</code> with nullifier key <code>nullifierKey</code> is computed as packed bytes of the nullifier key, nonce, hardcoded 17 bytes with randomness fields of a resource, as well as the commitment of a resource as described above.</p> <pre><code>    function nullifier(Resource memory resource, bytes32 nullifierKey) internal pure returns (bytes32 nf) {\n        nf = sha256(abi.encodePacked(nullifierKey, resource.nonce, psi(resource), commitment(resource)));\n    }\n\n    function psi(Resource memory resource) internal pure returns (bytes32 randNf) {\n        bytes17 prfExpandPersonalization = 0x52495343305f457870616e645365656400;\n        randNf = sha256(abi.encodePacked(prfExpandPersonalization, resource.randSeed, resource.nonce));\n    }\n</code></pre> Kind <p>A kind of a resource <code>resource</code> with <code>logicRef = resource.logicRef</code> and <code>labelRef = resource.labelRef</code> is computed as <code>sha256(abi.encode(logicRef, labelRef))</code>.</p> Delta <p>The delta of a resource <code>resource</code> is computed as the multiple of the resource kind and quantity seen as scalars and Pedersen-committed to a 2D point on the K256 curve. However, we do not use them for verification purposes. For details one can consult the compliance circuit.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/data_structures.html#compliance-unit","title":"Compliance Unit","text":"<p>The compliance unit is defined as the <code>VerifierInput</code> struct:</p> <pre><code>    struct VerifierInput {\n        bytes proof;\n        Instance instance;\n    }\n</code></pre> <p>where the instance is the expected compliance unit instance type:</p> <pre><code>    struct Instance {\n        ConsumedRefs consumed;\n        CreatedRefs created;\n        bytes32 unitDeltaX;\n        bytes32 unitDeltaY;\n    }\n</code></pre> <p>where</p> <pre><code>    struct ConsumedRefs {\n        bytes32 nullifier;\n        bytes32 logicRef;\n        bytes32 commitmentTreeRoot;\n    }\n</code></pre> <p>and</p> <pre><code>    struct CreatedRefs {\n        bytes32 commitment;\n        bytes32 logicRef;\n    }\n</code></pre> <p>As mentioned in EVM Primitive Interfaces page, the unit delta is represented as a 2D point.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/data_structures.html#action","title":"Action","text":"<p>The action datatype is described as</p> <pre><code>struct Action {\n    Logic.VerifierInput[] logicVerifierInputs;\n    Compliance.VerifierInput[] complianceVerifierInputs;\n}\n</code></pre> <p>Where the compliance verifier input time is defined above, while the logic verifier input is defined as:</p> <pre><code>    struct VerifierInput {\n        bytes32 tag;\n        bytes32 verifyingKey;\n        AppData appData;\n        bytes proof;\n    }\n</code></pre> <p>The <code>AppData</code> stands for the 4 different payloads we posess:</p> <pre><code>    struct AppData {\n        ExpirableBlob[] resourcePayload;\n        ExpirableBlob[] discoveryPayload;\n        ExpirableBlob[] externalPayload;\n        ExpirableBlob[] applicationPayload;\n    }\n</code></pre> <p>with <code>ExpirableBlob</code> defined as</p> <pre><code>    struct ExpirableBlob {\n        DeletionCriterion deletionCriterion;\n        bytes blob;\n    }\n</code></pre> <p>There are only two deletion criteria we support:</p> <pre><code>    enum DeletionCriterion {\n        Immediately,\n        Never\n    }\n</code></pre> <p>The storage of the criteria is designated to the EVM event history logs. Once the transaction is executed, the event will be transmitted, including the blobs, which will then be recoverable by an interested party through indexing services.</p> <p>The <code>actionTreeRoot</code> is computed as the root of a merkle tree of depth 4 with leaves provided by the <code>tag</code>s in the corresponding Action.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/data_structures.html#transaction","title":"Transaction","text":"<p>The transaction is defined as a list of actions with the delta prove attesting to the balancing of the action alongside an aggregation proof, attesting to the verification of all the logic and compliance verifying keys present in the transaction given the instances:</p> <pre><code>struct Transaction {\n    Action[] actions;\n    bytes deltaProof;\n    bytes aggregationProof;\n}\n</code></pre> <p>If an aggregation proof is present, the PA only checks the delta and the aggregation proofs.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html","title":"Execution Flow of the EVM Protocol Adapter","text":"<p>This page describes at a high-level the Protocol Adapter implementation on the EVM. This page in particular explains how we address all the out of circuit checks and any additional ones implemented.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#resource-machine","title":"Resource Machine","text":"<p>The resource machine functionality is implemented via the <code>execute</code> function, processing the verification of the transaction as per the RM specification and updating state consisting of a commitment accumulator, set of historical tree roots, and the nullifier set.</p> <p>The <code>execute</code> function updates the commitment accumulator and the nullifier set if and only if the following two criteria are fulfilled:</p> <ul> <li>All checks specified by the RM specification pass. In particular:<ul> <li>All compliance proofs are valid.</li> <li>All resource logic proofs are valid.</li> <li>The delta proof is valid.</li> <li>For each action, its compliance units partition its tags.</li> <li>Verifying keys of tags match the logic references in the compliance units.</li> <li>Historical roots defined in the compliance units exist in the set of historical roots.</li> <li>There are no repeated commitments or nullifiers in the transaction.</li> <li>Each commitment in a transaction has not been added to the commitment accumulator before.</li> <li>Each nullifier in a transaction has not been added to the nullifier set before.</li> </ul> </li> <li>All forwarder calls in each <code>externalPayload</code> return the expected outcomes and do not revert.</li> </ul> <p>Given all of this is done, all the commitments in a transaction are added to the commitment Merkle tree and the nullifiers are added to the nullifier set. We also emit several events relevant to the transaction during the execution.</p> <p>Below, we go into details regarding verification and event-emission details.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#verification","title":"Verification","text":"<p>Verification can be split into two conceptual components as specified above:</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#rm-checks","title":"RM Checks","text":"<p>We go through the list explicating how each check is made:</p> <ul> <li>All compliance proofs are valid.</li> </ul> <p>We grant that by iterating over the compliance units and verifying their proofs by calling the trusted Risc0 Verifier.</p> <ul> <li>All resource logic proofs are valid.</li> </ul> <p>When iterating over compliance units, for each tag present we fetch the corresponding proofs from the action, verifying it by calling the trusted Risc0 Verifier.</p> <ul> <li>The delta proof is valid.</li> </ul> <p>At the end of the transaction, we run ECDSA signature verification, which corresponds to verifying a delta proof.</p> <ul> <li>For each action, its compliance units partition its tags.</li> </ul> <p>This check is split into four components.</p> <ol> <li> <p>When iterating over the compliance units of the action, we call <code>lookup</code> on every nullifier and commitment. This function iterates over the logic verifier inputs in a given action and reverts if no matching tag has been found. This ensures that the set of tags in compliance unit is a subset of a set of tags of the action.</p> </li> <li> <p>When adding nullifiers to the nullifier set, the operation reverts on a repeating nullifier insertion. This grants that nullifiers across the compliance units are unique.</p> </li> <li> <p>Our compliance circuit ensures that if a resource is committed, it uses a nullifier of a consumed resource present in the same compliance unit as its nonce. Since nullifiers are unique, this statistically grants uniqueness of commitments.</p> </li> <li> <p>During the initial allocation of array sizes for tags, we compute the number of the overall tags by <code>countTags</code> function. It in particular ensures that the number of tags in the compliance units and logic verifier inputs match.</p> </li> </ol> <ul> <li>Verifying keys of tags match the logic references in the compliance units.</li> </ul> <p>When doing <code>lookup</code> we check that these match explicitly. Note that in this implementation, the hashing function to get the logic reference from the verifying key is just the identity function, hence we check for explicit equality.</p> <ul> <li>Historical roots defined in the compliance units exist in the set of historical roots.</li> </ul> <p>When iterating over the compliance units, we explicitly check containment of all roots provided in the set of roots we store on-chain.</p> <ul> <li>There are no repeated commitments or nullifiers in the transaction.</li> </ul> <p>As mentioned, the uniqueness of commitments and nullifiers are granted by the semantics of nullifier set and the compliance circuit constraints.</p> <ul> <li>Each commitment in a transaction has not been added to the commitment accumulator before.</li> </ul> <p>Same here.</p> <ul> <li>Each nullifier in a transaction has not been added to the nullifier set before.</li> </ul> <p>Same here.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#external-call-checks","title":"External Call Checks","text":"<p>After verifying a logic proof of a resource, we iterate over the <code>externalPayload</code>in its application data. In each position, the verifier expects to be encoded a tuple with:</p> <ol> <li>External address</li> <li>Input bytes</li> <li>Output bytes</li> </ol> <p>The external address is assumed to be a forwarder contract which can hence be called via <code>forwardCall</code> interface, giving the <code>logicRef</code> of the resource and the input bytes as the arguments.</p> <p>The call ought to return exactly the output bytes, otherwise, the verifier reverts with the appropriate error.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#events","title":"Events","text":"<p>For each payload blob with deletion criterion <code>Never</code>, we emit it as an event to be recorded in Ethereum's history and picked up by apporpriate indexers:</p> <pre><code>event ResourcePayload(bytes32 indexed tag, uint256 index, bytes blob);\n\nevent DiscoveryPayload(bytes32 indexed tag, uint256 index, bytes blob);\n\nevent ExternalPayload(bytes32 indexed tag, uint256 index, bytes blob);\n\nevent ApplicationPayload(bytes32 indexed tag, uint256 index, bytes blob);\n</code></pre> <p>Regardless of the deletion criterion, we also emit an event signaling that a forwarder call has been made:</p> <pre><code> event ForwarderCallExecuted(address indexed untrustedForwarder, bytes input, bytes output);\n</code></pre> <p>Alongside that, we have separate events informing that a specific action has executed with specified root:</p> <pre><code>event ActionExecuted(bytes32 actionTreeRoot, uint256 actionTagCount);\n</code></pre> <p>And the final transaction event listing all tags and their verification keys in the order provided by the compliance units:</p> <pre><code>event TransactionExecuted(bytes32[] tags, bytes32[] logicRefs);\n</code></pre>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#user","title":"User","text":"<p>From the perspective of the user, there are two things they are concerned about:</p> <p>1) Getting to know which resources are relevant to them</p> <p>2) Composing and submitting transactions</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#resource-state-sync","title":"Resource State Sync","text":"<p>For the former, the user can listen to the incoming <code>TransactionExecuted</code> events and inspect individual <code>appData</code> fields. Each user is assumed to have some sets of keypairs. Specifically some sets for decoding the <code>discoveryPayload</code> and <code>resourcePayload</code> contained in the <code>appData</code> of the given <code>tag</code>.</p> <p>While these fields are permissionless, they are incentivized (and frequently required by the resource logics) to contain specific sort of info. Specifically, the user expects that if the <code>tag</code> is relevant to them, the <code>discoveryPayload</code> decodes to a single byte with their private discovery key. This way the user understands that <code>tag</code> is a resource they are interested in. Afterwards, they can use their resource payload decryption key to decrypt <code>resourcePayload</code> which they can expect to contain the resource plaintext and other relevant information.</p> <p>If the resource needs to make a forwarder call, the user is expected to put the plaintext in a universally decodable format into the head of the <code>resourcePayload</code> alongside with the nullifier key afterwards in the array if the resource making a call is consumed. The PA decided on the validity of the call based on the provided information in these predetermined locations.</p> <p>Given the plaintext, the user can then check that the plaintext actually corresponds to the <code>tag</code> by committing or nullifying (given that the nullifier key is provided) the resource. That way the user gets to know what resource was created or consumed in a shielded context.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#transaction-generation","title":"Transaction Generation","text":"<p>There are only two non-application specific pieces of data that a user needs to know regarding the global state if they want to generate a transaction. Both of them are needed to nullify a given resource <code>R</code>. These are:</p> <ul> <li>Some root at which <code>R</code> has been created.</li> <li>The path to <code>R</code> at that root.</li> </ul> <p>If <code>R</code> has indeed been created, it exists at the latest root. The EVM PA supports getting the information about the latest root by using the</p> <pre><code>function latestCommitmentTreeRoot() external view returns (bytes32 root);\n</code></pre> <p>The Merkle proofs are not availiable on-chain for gas reasons.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#solvers","title":"Solvers","text":"<p>Solvers can also get information regarding resources interesting to them similarly to the users: from inspecting the <code>discoveryPayload</code>.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/execution_flow.html#executor","title":"Executor","text":"<p>For the EVM Protocol Adapter the role of the executor depends on the chain on which it has been deployed. For example, for the PA deployed on Ethereum the executor will be the validator set of the Ethereum chain.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html","title":"EVM Protocol Adapter Primitive Interfaces","text":"<p>This section contains descriptions of the implementations of primitive interfaces in the EVM Protocol Adapter.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#set","title":"Set","text":"<p>The set implementation we use is the OpenZeppelin <code>EnumerableSet</code> v5.2.0 implementation.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#map","title":"Map","text":"<p>We use two representations of maps.</p> <p>The first - used in the the core datatype implementation such as the <code>logicVerifierInputs</code> - is the representation of a map as a list of structs containing an explicit field for the <code>key</code> field, namely <code>logicVerifierInputs</code> contains field <code>Instance</code> which in turn contains a field <code>tag</code> which is seen as a key to the map.</p> <p>We also use Solidity's <code>mapping</code> for the commitment accumilator functionality.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#fixed-size-type","title":"Fixed Size Type","text":"<p>We generally used <code>bytes32</code>/<code>uint256</code> in the implementation, also using <code>uint128</code> for quantity of resources.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#proving-system","title":"Proving System","text":"<p>For the current implementation, for resource logics and the compliance proofs we use the Risc0 proving system, specifically v3.0.3 of Risc0 alongside the appropriate version of the EVM verifier. The delta values are computed as 2D points (<code>uint256[2]</code>) on the <code>secp256k1</code> (K-256) elliptic curve and verified using ECDSA.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#compliance-circuit","title":"Compliance Circuit","text":"<p>Our compliance circuits are fixed size of exactly 2 resources: 1 created and 1 consumed. This allows us to also ensure that the <code>nonce</code> of the created resource contains the hash of the consumed resource. This grants uniqueness of comitments automatically given uniqueness of nullifiers.</p> <p>The compliance verifying key is fixed and hardcoded as an internal constant:</p> <pre><code>bytes32 internal constant _VERIFYING_KEY = ...;\n</code></pre> <p>Other than the checks described in the Compliance Proof page, the compliance proof for the EVM protocol adapter constraints the created resource to use the nullifier of the consumed resource.</p> <p>For details, consult the contrains in the arm-risc0 library.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#delta-proof","title":"Delta Proof","text":"<p>The delta proving system uses the ECDSA signature scheme over the K256 eliptic curve. The signature (delta proof) is the sum of the randomness across all compliance units, while the verification key comes from the keccak-256 hash over the list of all nullifier and commitments pairs obtained by iterating over the compliance units (see <code>src/proving/Delta.sol</code>). The instance for the proving system comes from the sum of unit deltas, where the latter are generated as the curve point representation of corresponding resources.</p> <p>The verification tries to recover from the verifying key hash using the proof as the signature and check the correspondence with the instance.</p> <p>We use OpenZeppelin's <code>ECDSA</code> library for recovery.</p> <p>The elliptic curve addition and conversion methods are defined in <code>proving/Delta.sol</code>. The curve implementation is taken from Witnet's <code>eliptic-curve-solidity</code> library v0.2.1. This includes:</p> <ul> <li>curve parameters</li> <li>curve addition (<code>ecAdd</code>)</li> <li>curve multiplication (<code>ecMul</code>)</li> </ul>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#commitment-accumilator","title":"Commitment Accumilator","text":"<p>Our commitment accumulator is a modified version of OpenZeppelin's <code>MerkleTree</code> and <code>MerkleProof</code> implementations. The core difference is the fact that it is a dynamic sparse merkle tree which expands its depth when needed to fit enough leaves.</p> <p>This keeps the gas costs of updating the commitment merkle tree to a minimum. For details, please consult the documentation).</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/primitives.html#nullifier-accumulator","title":"Nullifier Accumulator","text":"<p>As our nullifier accumulator we use a set. As noted above, the implementation is provided by OpenZeppelin <code>EnumerableSet</code> v5.2.0 implementation.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/index.html","title":"EVM Interoperability","text":"<p>The Resource Machine inherently operates with resources and is chain-agnostic. However, the EVM protocol adapter has an ability to interact with other contracts on the chain it was deployed to. This section is devoted to explicating the architecture for such interactions and its motivation.</p>","tags":["index","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/index.html#contents","title":"Contents","text":"<ul> <li>Architecture Motivation</li> <li>Implementation</li> <li>Example Apps</li> </ul>","tags":["index","evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/example.html","title":"EVM Interoprability Example Applications","text":"","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/example.html#examples","title":"Examples","text":"<p>This section is devoted to example applications showcasing EVM interop. The core example is taken from the appropriate forwarder page</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/example.html#erc20-forwarder","title":"ERC20 Forwarder","text":"<p>The ERC20 Forwarder Contract is made in order to facilitate the ability to lock <code>ERC20</code> tokens such as USDC or wrapped ETH in it.</p> <p>The <code>forwardCall</code> implementation is a direct one:</p> <p>We first check that the caller is the Protocol Adapter, so that no other agent can interact with the state.</p> <pre><code>        if (msg.sender != _PROTOCOL_ADAPTER) {\n            revert UnauthorizedCaller({expected: _PROTOCOL_ADAPTER, actual: msg.sender});\n        }\n</code></pre> <p>afterwards we case on the given input. The call provided can either be <code>Wrap</code>, which indicates that the user is willing to lock up funds on the forwarder in order to freely use it on the RM side, or <code>Unwrap</code>, where an owner of the RM assets wants to withdraw them back to a specified Ethereum address.</p> <p>On <code>Wrap</code>, we expect the input to decode into a struct containing a Permit2 signature of a user over an action tree root provided as witness:</p> <pre><code>        (\n            , // CallType\n            address from,\n            ISignatureTransfer.PermitTransferFrom memory permit,\n            bytes32 witness,\n            bytes memory signature\n        ) = abi.decode(input, (CallType, address, ISignatureTransfer.PermitTransferFrom, bytes32, bytes));\n</code></pre> <p>The signature should allow the forwarder to lock up a specified ammount of funds.</p> <p>Then the forwarder runs <code>permitWitnessTransferFrom</code> and returns empty bytes.</p> <p>On <code>Unwrap</code>, we decode the input as:</p> <pre><code>        (\n            , // CallType\n            address token,\n            address to,\n            uint128 amount\n        ) = abi.decode(input, (CallType, address, address, uint128));\n</code></pre> <p>and simply call <code>safeTransfer</code>, sending a specified amount of the specified token to the provided address.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/example.html#block-time-forwarder","title":"Block Time Forwarder","text":"<p>A block time forwarder is a trivial forwarder accessible to anyone. Its core purpose is to inform resource of whether a certain block time has passed. That is, the contract expects a certain block time as an input, and returns a comparative result (\"less than\", \"equal\", \"greater than\") encoded as an enum.</p> <p>The implementation is trivial:</p> <pre><code>        (uint48 expectedTime) = abi.decode(input, (uint48));\n\n        uint48 currentTime = Time.timestamp();\n\n        TimeComparison result;\n        if (expectedTime &lt; currentTime) {\n            result = TimeComparison.LT;\n        } else if (expectedTime &gt; currentTime) {\n            result = TimeComparison.GT;\n        } else {\n            result = TimeComparison.EQ;\n        }\n\n        output = abi.encode(result);\n</code></pre>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/impl.html","title":"EVM Interoperability Implementation","text":"","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/impl.html#implementation","title":"Implementation","text":"<p>Below we detail the exact code using which we perform the interoperability calls.</p> <p>During <code>execute</code>, while going over all the verifier inputs to the resource logics, after their verificatoon we iterate over the <code>externalPayload</code> of said resource.</p> <p>For each element of the list, we try to decode the blob present as follows:</p> <pre><code> (address untrustedForwarder, bytes memory input, bytes memory expectedOutput) =\n            abi.decode(callBlob, (address, bytes, bytes));\n</code></pre> <p>The interpretation of the variable names should be clear.</p> <p>At this point we just execute the calls and make sure that the outputs correspond to the preset ones. Note that the verifier provides the logic reference of the appropriate resource as an explict extra input ot the function.</p> <pre><code>        bytes memory actualOutput =\n            IForwarder(untrustedForwarder).forwardCall({logicRef: carrierLogicRef, input: input});\n\n        if (keccak256(actualOutput) != keccak256(expectedOutput)) {\n            revert ForwarderCallOutputMismatch({expected: expectedOutput, actual: actualOutput});\n        }\n</code></pre>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/motivation.html","title":"EVM Interoperability Achitecture Motivation","text":"","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/motivation.html#architecture-motivation","title":"Architecture Motivation","text":"<p>Below we expound on the motivation of the interoperability mechanism. Particularly relating to the definitions of terms \"forwarder contract\" and \"calldata resource\".</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/motivation.html#forwarder-contracts","title":"Forwarder Contracts","text":"<p>The core idea we start with is: the RM and specifically some applications want to be able to communicate with other contracts on Ethereum. For example, there is an ERC-20 contract, it may have some functions such as <code>transfer</code> that we are interested in calling. Another example would be a <code>counter</code> contract that stores a natural number which can be incremented. Generally, as applications on Anoma are permissionless, so is their choice regarding which contract functionality they would be interested in.</p> <p>We could - theoretically - call these contracts directly, but what we are interested in is allowing calls to be made bound to certain logic enforceable through the RM. That is, we want a call to a contract <code>C</code> to be connected with some resource <code>R</code> such that only if its resource logic is satisfied, the call can induce a state change (supposing the call is successful).</p> <p>As an example, we may want to create a resource connected to the increment contract described above such that the resource can only be created if its quantity matches the current value of the counter stored. Or we may want to issue a resource <code>R</code> of quantity <code>R.q</code> only if somebody has locked some tokens of the same quantity to be used inside the RM.</p> <p>That means, that what we want is not just to make a call, but to make a call subject to a certain logic.</p> <p>Therefore we need not only the original contract, but a place to store the logic connected to the application. For that, we need to have a forwarder contract. It will be a contract that can perform the needed calls with arbitrary constraints and store the needed resource logics making sure only specific applications will be able to perform possible operations through them.</p> <p>A forwarder contract is a contract which has one required function interface: <code>forwardCall</code> accepting a logic reference and input bytes.</p> <p><code>forwardCall</code> will be called by the PA, in order to perform arbitrary logic with inputs specified.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/motivation.html#calldata-resources","title":"Calldata Resources","text":"<p>Interoperability requires actors on both sides: on the RM and EVM. On the EVM we need the forwarder contracts to allow arbitrary calls to be made by application developers bound to a specific application. On the RM side, we need resources representing an application to verify that a call is being made.</p> <p>For that, we need to store the information regarding a call inside the context of the resource logics being evaluated. In particular, we have the <code>externalPayload</code> field inside <code>appData</code>. There we put information such as the address of the forwarder contract we call, inputs to the call, as well as the expected outputs.</p> <p>As <code>appData</code> gets exposed to the resource logics they can make sure that a call is present (or absent) and will be made by the PA, returning the desired output.</p> <p>At the same time, forwarder also can control which resources are able to call them. The PA other than feeding the specified inputs to the <code>forwardCall</code>, also send the logic reference of a resource calling it. This allows the forwarder contract to revert in case it does not trust the logic (and hence the inputs) of a resource making the call.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/integrations/adapters/evm/interop/motivation.html#emergency-calls","title":"Emergency Calls","text":"<p>The final piece of the puzzle to motivate are emergency calls.</p> <p>While <code>forwardCall</code> is the only function that constitute the interface of a forwarder - as these are the minimal interface to interact with the PA - there are some additional functions we recommend developers to implement in order to be certain that their applications can be migratable.</p> <p>In partciular, note that a Resource Machine needs a proving system. One specific component it needs is a verifier. The PA implementation uses a Risc0-supplied verifier contract. In case Risc0 find a vulnerability for the appropriate version, the verifier gets shut down. As no state change can happen without verifying the compliance and logic proofs, there will be no state changes after the shut down.</p> <p>As many applications will require <code>forwarderCall</code> to be made only by the PA for good design, that would completely block the removal of any funds locked inside such forwarder contracts.</p> <p>In order to mitigate this and allow for people to move their funds after the proving system gets shut down, we recommend that developers implement the <code>EmergencyMigratable</code> interface. Specifically:</p> <pre><code>interface IEmergencyMigratable {\n    function forwardEmergencyCall(bytes memory input) external returns (bytes memory output);\n\n    function setEmergencyCaller(address newEmergencyCaller) external;\n\n    function emergencyCaller() external view returns (address caller);\n}\n</code></pre> <p>The semantics is that the designer of a forwarder contract sets up an emergecny committee when deploying the contract. The emergency committee can call <code>setEmergencyCaller</code>, which sets up the address that can use <code>forwardEmergencyCall</code> function, which implements arbitrary logic. The <code>setEmergencyCaller</code> has two constraints:</p> <ul> <li>It can only be called by the emergency committee and</li> <li>Appropriate PA was stopped</li> </ul> <p>This way <code>forwardEmergencyCall</code> will only succeed if the verifier (or the PA itself) gets shut down.</p>","tags":["evm","resource-machine","protocol-adapter"],"boost":2},{"location":"arch/system/identity/identity.html","title":"Identity Architecture Types","text":"Juvix imports <pre><code>module arch.system.identity.identity;\nimport prelude open;\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-architecture","title":"Identity Architecture","text":"Type definitions <pre><code>type OrdKey OrdKeyType :=\n  mkOrdKey@{\n    compare : OrdKeyType -&gt; OrdKeyType -&gt; Ordering\n  };\n</code></pre> <pre><code>type HASH OrdKeyType Hashable :=\n  mkHASH@{\n    ordKey : OrdKey OrdKeyType;\n    hash : Hashable -&gt; OrdKeyType\n  };\n</code></pre> <pre><code>-- Note: instance of this with Data.Map should be made\ntype OrdMap (OrdKeyType : Type) (MapCon : Type -&gt; Type) :=\n  mkMap {\n    ordKey : OrdKey OrdKeyType;\n    empty {A} : MapCon A;\n    map {A B} : (A -&gt; B) -&gt; MapCon A -&gt; MapCon B;\n    insert {A} : Pair (MapCon A) (Pair OrdKeyType A) -&gt; MapCon A;\n    foldl {A B} : (Pair A B -&gt; B) -&gt; B -&gt; MapCon A -&gt; B;\n    intersectWith {A B C} : (Pair A B -&gt; C) -&gt; Pair (MapCon A) (MapCon B) -&gt; MapCon C;\n    all {A} : (A -&gt; Bool) -&gt; MapCon A -&gt; Bool\n    -- Bunch of stuff, see https://www.smlnj.org/doc/smlnj-lib/Util/sig-OrdMap.html\n  };\n</code></pre> <p>The base abstraction of the protocol is a knowledge-based identity  interface, where the identity of an agent is defined entirely on the  basis of whether or not they know some secret information.</p> <p>Agents can use private information (likely randomness) to create an  internal identity, from which they can derive an  external identity to which it corresponds. The external identity can be shared with other parties. The agent who knows the internal identity can sign messages, which any  agent who knows the external identity can verify, and any agent who  knows the external identity can encrypt messages which the agent with  knowledge of the internal identity can decrypt. This identity interface is independent of the particular cryptographic  mechanisms, which may vary.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-interface","title":"Identity Interface","text":"","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#internal-identity","title":"Internal Identity","text":"<p>An internal identity includes private information necessary for signing and  decryption. Formally, an internal identity has two parts: a Signer and a Decryptor.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signer-juvix-type","title":"Signer Juvix Type","text":"<p>A signature describing a type <code>SignerType</code> that can cryptographically  <code>sign</code> (or credibly commit) to something (a <code>Signable</code>), forming a  <code>Commitment</code>. Implementations should ultimately include, for example  BLS keys,   which should be able to sign anything that can be marshaled into a   bitstring.</p> <p>Properties:</p> <ul> <li> <p>In general, every <code>S : Signer</code> needs a corresponding <code>V : Verifier</code>, and   every <code>s : SignerType</code> needs a corresponding <code>v : VerifierType</code>, such that:</p> <ul> <li>For any message <code>m</code> : <code>verify v m x = (x = (sign s m))</code></li> </ul> <ul> <li>for most cryptosystems, a computationally bounded adversary should not be   able to approximate <code>s</code> knowing only <code>v</code>.</li> </ul> </li> </ul> <pre><code>type Signer SignerType Signable Commitment :=\n  mkSigner@{\n    sign : SignerType -&gt; Signable -&gt; Commitment\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#decryptor-juvix-type","title":"Decryptor Juvix Type","text":"<p>A signature describing a type <code>DecryptorType</code> that can cryptographically  <code>decrypt</code> something (a <code>Ciphertext</code>), resulting in a <code>Plaintext</code>  (or <code>none</code>, if decryption fails). Implementations should ultimately include, for example,  AES-256  keys,  which should be able to decrypt bitstrings into anything that  can be unmarshaled from a bitstring.</p> <p>Properties:</p> <ul> <li>a computationally bounded adversary should not be able to   approximate <code>decrypt d</code> without knowledge of <code>d</code>.</li> </ul> <ul> <li><code>decrypt</code> should take polynomial time (in the size of its inputs)</li> </ul> <ul> <li> <p>Each <code>D : Decryptor</code> should have a corresponding <code>E : Encryptor</code>, and   each <code>d : DecryptorType</code> has a corresponding <code>e : EncryptorType</code> such   that:</p> <ul> <li>for all <code>c : Ciphertext</code>, <code>p : Plaintext</code>:   <code>decrypt d c = Some p</code> iff <code>c = encrypt e p</code></li> </ul> <ul> <li>if <code>d = e</code>, we call this \"symmetric encryption,\" and otherwise   it's \"asymmetric encryption\"</li> </ul> </li> </ul> <pre><code>type Decryptor DecryptorType Plaintext Ciphertext :=\n  mkDecryptor@{\n    decrypt : DecryptorType -&gt; Ciphertext -&gt; Option Plaintext\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#internal-identity-juvix-type","title":"Internal Identity Juvix Type","text":"<p>An Internal Identity structure simply specifies everything specified by both Signer and Decryptor.</p> <p>An Internal Identity structure specifies the necessary types and  functions for both a Signer and a Decryptor. Implementations should ultimately include, for example,  RSA private keys,  which should be able to decrypt integers into anything that can be  unmarshaled from a bitstring, and sign anything which can be  marshaled into a bytestring to form an integer.</p> <p>An internal_identity includes:</p> <ul> <li>a type <code>SignerType</code> that can cryptographically   <code>sign</code> (or credibly commit) to something (a <code>Signable</code>), forming a   <code>Commitment</code>.</li> </ul> <ul> <li>a type <code>DecryptorType</code> that can cryptographically <code>decrypt</code> something   (a <code>Ciphertext</code>), resulting in a <code>Plaintext</code>   (or <code>none</code>, if decryption fails).</li> </ul> <p>Properties are inherited from <code>Signer</code> and <code>Decryptor</code>.</p> <pre><code>type InternalIdentity\n    SignerType\n    Signable\n    Commitment\n    DecryptorType\n    Plaintext\n    Ciphertext :=\n  mkInternalIdentity@{\n    signer : Signer SignerType Signable Commitment;\n    decryptor : Decryptor DecryptorType Plaintext Ciphertext\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#external-identity","title":"External Identity","text":"<p>An external identity includes only public information. An external identity can verify signatures produced by an internal identity, and encrypt messages the internal identity can then decrypt. Formally, an external identity has two parts: a verifier and an Encryptor. Each is hashable: any structure specifying verifier and Encryptor types must also specify a hash function, so that external identities can be specified by hash.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#verifier-juvix-type","title":"Verifier Juvix Type","text":"<p>A signature describing a type <code>VerifierType</code> that can cryptographically  <code>verify</code> that a <code>Commitment</code> (or cryptographic signature) corresponds  to a given message (a <code>Signable</code>), and was signed by the <code>SignerType</code>  corresponding to this <code>VerifierType</code>. A <code>VerifierType</code> can be hashed (producing a unique identifier), so a  structure with signature <code>Verifier</code> must specify a <code>VerifierHash</code>  structure defining a suitable <code>hash</code> function. Implementations should ultimately include, for example  BLS  identities.</p> <p>Properties:</p> <ul> <li> <p>In general, every <code>V : Verifier</code> needs a corresponding <code>S : Signer</code>, and   every <code>s : SignerType</code> needs a corresponding <code>v : VerifierType</code>, such that:</p> <ul> <li>For any message <code>m</code> : <code>verify v m x = (x = (sign s m))</code></li> </ul> <ul> <li>for most cryptosystems, a computationally bounded adversary should not be   able to approximate <code>s</code> knowing only <code>v</code>.</li> </ul> </li> </ul> <pre><code>type Verifier OrdKey VerifierType Signable Commitment :=\n  mkVerifier@{\n    verify : VerifierType -&gt; Signable -&gt; Commitment -&gt; Bool;\n    verifierHash : HASH OrdKey VerifierType\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#encryptor-juvix-type","title":"Encryptor Juvix Type","text":"<p>A signature describing a type <code>EncryptorType</code> that can cryptographically  <code>encrypt</code> a <code>Plaintext</code> (message) to create a <code>Ciphertext</code> readable  only by the corresponding <code>DecryptorType</code>. An <code>EncryptorType</code> can be hashed (producing a unique identifier), so a  structure with signature <code>Encryptor</code> must specify an <code>encryptorHash</code>  structure defining a suitable hash function. Implementations should ultimately include, for example,  AES-256  keys,  which should be able to decrypt bitstrings into anything that  can be  unmarshaled from a bitstring.</p> <p>Properties:</p> <ul> <li><code>encrypt</code> should take polynomial time (in the size of its inputs)</li> </ul> <ul> <li> <p>Each <code>E : Encryptor</code> should have a corresponding <code>D : Decryptor</code>, and   each <code>d : DecryptorType</code> has a corresponding <code>e : EncryptorType</code> such   that:</p> <ul> <li>for all <code>c : Ciphertext</code>, <code>p : Plaintext</code>:   <code>decrypt d c = Some p</code> iff <code>c = encrypt e p</code></li> </ul> <ul> <li>if <code>d = e</code>, we call this \"symmetric encryption,\" and otherwise   it's \"asymmetric encryption.\"   In an asymmetric cryptosystem, a computationally bounded adversary   should not be able to approximate <code>d</code> knowing only <code>e</code>.</li> </ul> </li> </ul> <pre><code>type Encryptor OrdKey EncryptorType Plaintext Ciphertext :=\n  mkEncryptor@{\n    encrypt : EncryptorType -&gt; Plaintext -&gt; Ciphertext;\n    encryptorHash : HASH OrdKey EncryptorType\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#external-identity-juvix-type","title":"External Identity Juvix Type","text":"<p>An External Identity structure specifies the necessary types and  functions for both a Verifier and an Encryptor. Implementations should ultimately include, for example,  RSA public keys.</p> <p>An external_identity includes:</p> <ul> <li>a type <code>VerifierType</code> that can cryptographically <code>verify</code> that a   <code>Commitment</code> (or cryptographic signature) corresponds to a given   message (a <code>Signable</code>), and was signed by the <code>SignerType</code>   corresponding to this <code>VerifierType</code>.</li> </ul> <ul> <li>a type <code>EncryptorType</code> that can cryptographically <code>encrypt</code> a   <code>Plaintext</code> (message) to create a <code>Ciphertext</code> readable only by the   corresponding <code>DecryptorType</code>.</li> </ul> <p>Properties are inherited from <code>Verifier</code> and <code>Encryptor</code>.</p> <pre><code>type ExternalIdentity\n  VerifierOrdKeyType\n  VerifierType\n  Signable\n  Commitment\n  EncryptorOrdKeyType\n  EncryptorType\n  Plaintext\n  Ciphertext\n  :=\n  mkExternalIdentity@{\n    verifier : Verifier VerifierOrdKeyType VerifierType Signable Commitment;\n    encryptor : Encryptor EncryptorOrdKeyType EncryptorType Plaintext Ciphertext\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-juvix-type","title":"Identity Juvix Type","text":"<p>An Identity structure, formally, specifies all the types for  corresponding internal and external identities. So, for a given Identity structure <code>I</code>, its <code>VerifierType</code> should be the  type of objects that can verify <code>Commitment</code>s produced by a  corresponding object of type <code>SignerType</code>. Likewise, its <code>DecryptorType</code> should be the type of objects that can decrypt  <code>Ciphertext</code>s produced by a corresponding object of type  <code>EncryptorType</code>. Implementations should ultimately include, for example,  RSA  public / private keys sytems.</p> <p>An Identity includes:</p> <ul> <li>a type <code>SignerType</code> that can cryptographically <code>sign</code> (or credibly commit) to something (an <code>InternalSignable</code>), forming an <code>InternalCommitment</code>.</li> </ul> <ul> <li>a type <code>DecryptorType</code> that can cryptographically <code>decrypt</code> something (an <code>InternalCiphertext</code>), resulting in an <code>InternalPlaintext</code> (or <code>none</code>, if decryption fails).</li> </ul> <ul> <li>a type <code>VerifierType</code> that can cryptographically <code>verify</code> that an <code>ExternalCommitment</code> (or cryptographic signature) corresponds to a given message (an <code>ExternalSignable</code>), and was signed by the <code>SignerType</code> corresponding to this <code>VerifierType</code>.</li> </ul> <ul> <li>a type <code>EncryptorType</code> that can cryptographically <code>encrypt</code> an <code>ExternalPlaintext</code> (message) to create an <code>ExternalCiphertext</code> readable only by the corresponding <code>DecryptorType</code>.</li> </ul> <p>Properties are inherited from <code>Verifier</code>, <code>Encryptor</code>, <code>Signer</code>, and <code>Decryptor</code>.</p> <pre><code>type Identity\n  SignerType\n  InternalSignable\n  InternalCommitment\n  DecryptorType\n  InternalCiphertext\n  InternalPlaintext\n  VerifierOrdKeyType\n  VerifierType\n  ExternalSignable\n  ExternalCommitment\n  EncryptorOrdKeyType\n  EncryptorType ExternalPlaintext ExternalCiphertext\n   :=\n  mkIdentity@{\n    internalIdentity : InternalIdentity SignerType InternalSignable InternalCommitment DecryptorType InternalPlaintext InternalCiphertext;\n    externalIdentity : ExternalIdentity VerifierOrdKeyType VerifierType ExternalSignable ExternalCommitment EncryptorOrdKeyType EncryptorType ExternalPlaintext ExternalCiphertext\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-relation","title":"SignsFor Relation","text":"<p>Some identities may have the authority to sign statements on behalf of other  identities. For example, Alice might grant Bob the authority to sign arbitrary messages on her behalf. We write this relationship as Bob <code>signsFor</code> Alice.</p> <p>In general, <code>signsFor</code> is a partial order over identities. This means <code>signsFor</code> is transitive: if A <code>signsFor</code> B and B <code>signsFor</code> C, then A <code>signsFor</code> C. The <code>signsFor</code> relation becomes especially useful with regard to composed identities, discussed below.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-evidence","title":"SignsFor Evidence","text":"<p>We do not specify all the ways one might know if one identity <code>signsFor</code> another. In general, an Identity Engine might accept (and perhaps store) a variety of forms of evidence as proof. As one simple form of evidence, we can specify a format for signed statements from B that proves some specified A <code>signsFor</code> B.</p> <p>Note that <code>signsFor</code> evidence cannot be revoked, and so a <code>signsFor</code> relation is not stateful: it cannot depend on the current state of, for example, a blockchain.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-juvix-type","title":"SignsFor Juvix Type","text":"<p>Formally, a <code>signsFor</code> relation requires a type of evidence, and a  <code>Verifier</code> structure. This codifies a belief about what <code>VerifierType</code>'s <code>Commitments</code> are  \"at least as good as\" another <code>VerifierType</code>'s. Evidence can be signed statements, proofs, or even local state about beliefs.</p> <p>For example, suppose <code>Alice</code> wants to grant authority to <code>Bob</code> to  <code>sign</code> on her behalf. Nodes who want to take this into account might accept some sort of  <code>e : Evidence</code>, perhaps a signed statement from <code>Alice</code>, so that they  can recognize that <code>signsFor e (Bob, Alice)</code>.</p> <p>Note that <code>signsFor</code> is not symmetric: <code>signsFor e (x,y)</code> does not  imply that any <code>z</code> exists such that <code>signsFor z (y,x)</code>.</p> <pre><code>type SignsFor OrdKey VerifierType Signable Commitment Evidence :=\n  mkSignsFor@{\n    verifier : Verifier OrdKey VerifierType Signable Commitment;\n    signsFor : Evidence -&gt; (Pair VerifierType VerifierType) -&gt; Bool\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-equivalence","title":"SignsFor Equivalence","text":"<p>We can also define a kind of identity equivalence : A <code>signsSameAs</code> B  precisely when A <code>signsFor</code> B and B <code>signsFor</code> A. This means that (in  general), if you want to sign a message as A, but for whatever reason it's cheaper to sign a message as B, it's safe to just use B instead, and vice  versa.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-relation","title":"ReadsFor Relation","text":"<p>Similar to <code>signsFor</code>, it is useful to sometimes note that one identity can read  information encrypted to another identity. For example, suppose Alice gives her private <code>DecryptorType</code> to Bob, and wants to let everyone know that Bob can  now read anything encrypted to Alice. Nodes who want to take this into  account might accept some sort of <code>evidence</code>, perhaps a signed statement from Alice, so that they can recognize that Bob <code>readsFor</code> Alice.</p> <p>Like <code>signsFor</code>, <code>readsFor</code> is a partial order over identities. This means <code>readsFor</code> is transitive: if A <code>readsFor</code> B and B <code>readsFor</code> C, then A <code>readsFor</code> C. The <code>readsFor</code> relation becomes especially useful with regard to composed identities, discussed below.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-evidence","title":"ReadsFor Evidence","text":"<p>We do not specify all the ways one might know if one identity <code>readsFor</code>  another. In general, an Identity Engine might accept (and perhaps store) a variety of forms of evidence as proof. As one simple form of  evidence, we can specify a format for signed statements from B that proves A <code>readsFor</code> B.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-juvix-type","title":"ReadsFor Juvix Type","text":"<p>Formally, a <code>readsFor</code> relation requires a type of evidence, and an  <code>Encryptor</code> structure. This codifies a belief about what <code>Decryptor</code>s can read other  <code>Encryptor</code>s ciphertext. Evidence can be signed statements, proofs, or even local state about beliefs.</p> <p>Specifically, if a node expresses a <code>readsFor</code> relation, and  <code>readsFor e (x,y)</code>, then the node believes that any node knowing the  decryptor corresponding to <code>x</code> can decrypt <code>encrypt y p</code>. If there is some Plaintext <code>p</code> such that some node knowing a decryptor  corresponding to <code>x</code> cannot read <code>encrypt y p</code>, then the node's  beliefs, as encoded in the <code>readsFor</code> relation, are incorrect.</p> <p>For example, suppose <code>Alice</code> gives her private <code>DecryptorType</code> to <code>Bob</code>,  and wants to let everyone know that <code>Bob</code> can now read anything  encrypted to <code>Alice</code>. Nodes who want to take this into account might accept some sort of  <code>e : Evidence</code>, perhaps a signed statement from <code>Alice</code>, so that they  can recognize that <code>readsFor e (Bob, Alice)</code>.</p> <p>Note that <code>readsFor</code> is not symmetric: <code>readsFor e (x,y)</code> does not  imply that any <code>z</code> exists such that <code>readsFor z (y,x)</code>.</p> <pre><code>type ReadsFor (OrdKey EncryptorType Plaintext Ciphertext Evidence : Type) :=\n  mkReadsFor {\n    encryptor : Encryptor OrdKey EncryptorType Plaintext Ciphertext;\n    readsFor : Evidence -&gt; (Pair EncryptorType EncryptorType) -&gt; Bool\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#equivalence","title":"Equivalence","text":"<p>We can also define a kind of identity equivalence: A <code>readsSameAs</code> B precisely when A <code>readsFor</code> B and B <code>readsFor</code> A. This means that, in general, if you want to encrypt a message to A, but for whatever reason it's cheaper to encrypt a message for B, it's safe to just use B instead, and vice versa.</p> <p>In total, A <code>equivalent</code> B when A <code>readsSameAs</code> B and A <code>signsSameAs</code> B. This means that (in general) A and B can be used interchangeably.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#composition","title":"Composition","text":"<p>There are a variety of ways to refer to groups of identities as  single, larger identities.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#threshold-composition","title":"Threshold Composition","text":"<p>Suppose we want an identity M that refers to any majority from a  set of shareholders. A signature from M would require that a majority of shareholders  participated in signing, and encrypting information for M would  require that a majority of shareholders participate in decryption. To construct M, we start with a set of shareholder identities, each  paired with a weight (their share), and define a weight threshold  which specifies the minimum weight for a \"majority.\"</p> <p>There are several ways we could imagine constructing Threshold  Composition Identities, but without specifying anything about the  underlying identities:</p> <ul> <li>A threshold composition identity signature is a map from (hashes of)    external identities, to signatures.   To verify a signature for some message <code>x</code>, we verify each signature    with <code>x</code> and its external identity, and check that the weights of    the external identities sum to at least the threshold.</li> </ul> <ul> <li>A threshold composition identity encrypted message is a map from    (hashes of) external identities, to ciphertexts.   To decrypt, any subset of internal identities with weights summing    to at least the threshold must decrypt their corresponding    ciphertexts, and the resulting plaintexts must be combined using an    erasure coding scheme.</li> </ul>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#threshold-composition-juvix-type-signer-and-verifier","title":"Threshold Composition Juvix Type (Signer and verifier)","text":"<p>A <code>ThresholdCompose</code> <code>VerifierType</code> consists of a  threshold (<code>Nat</code>), and a set of <code>VerifierType</code>s, each paired with a  weight (<code>Nat</code>).  (this set is encoded as a <code>Map.map</code> from hashes of <code>verifiers</code> to   <code>Pair Nat VerifierType</code> pairs). <code>Commitments</code> are simply <code>Map</code>s from hashes of the underlying  identities to <code>Commitments</code> signed by that identitity. A <code>Commitment</code> verifies iff the set of valid Commitments included  correspond to a set of <code>verifiers</code> whose weights sum to at least  the threshold. Note that this satisfies both signatures <code>Verifier</code> and <code>Signer</code>.</p> <p>In general, <code>ThresholdCompose</code> <code>SignerType</code>s and <code>VerifierType</code>s may not be  used much directly. Instead, nodes can make more efficient identities (using cryptographic  signature aggregation techniques), and express their relationship to  <code>ThresholdCompose</code> <code>VerifierType</code>s as a <code>SignsFor</code> relationship. This will let nodes reason about identities using simple  <code>ThresholdCompose</code> <code>VerifierType</code>s, while actually using more efficient  implementations.</p> <p>Formally, to specify a <code>ThresholdCompose</code>, we need:</p> <ul> <li><code>verifier</code>, the structure of the underlying <code>Verifiers</code>.</li> </ul> <ul> <li><code>signer</code>, the corresponding structure of the underlying <code>Signers</code>.</li> </ul> <ul> <li><code>map : OrdMap</code>, to be used to encode weights and <code>Commitment</code>s.   (Note that this needs the <code>OrdKey</code> to be the hash type of the    underlying <code>verifier</code>)</li> </ul> <ul> <li><code>thresholdComposeHash</code>, which specifies a <code>hash</code> function that can    hash our composed <code>VerifierType</code>s (type <code>ComposeHashable VerifierType MapCon</code>).</li> </ul> <pre><code>type ComposeHashable (VerifierType : Type) (MapCon : Type -&gt; Type) :=\n  mkComposeHashable {\n    threshold : Nat;\n    weights : MapCon (Pair Nat VerifierType)\n  };\n</code></pre> <p>A <code>ThresholdCompose</code> structure provides:</p> <ul> <li><code>map : OrdMap</code> the underlying <code>OrdMap</code> used in    <code>VerifierType</code> and <code>Commitment</code></li> </ul> <ul> <li><code>underlyingVerifier : Verifier</code> the structure describing    the types of the underlying <code>VerifierType</code>s which can be composed.</li> </ul> <ul> <li><code>underlyingSigner : Signer</code> the structure describing    the types of the underlying <code>SignerType</code>s which can be composed.</li> </ul> <ul> <li><code>VerifierHash : HASH</code> describes the hash function for    hashing these composed <code>verifiers</code></li> </ul> <ul> <li>The <code>SignerType</code> type of the composed verifiers is the type of composed signers.    These are just <code>MapCon Commitment</code>, meaning each is    stored under the hash of the corresponding    <code>VerifierType</code>.    This <code>SignerType</code> does not need to encode weights or threshold.</li> </ul> <ul> <li>The <code>VerifierType</code> type of composed verifiers. These are    <code>ComposeHashable VerifierType MapCon</code></li> </ul> <ul> <li>The <code>Signable</code> type , being the type of message that can be signed. This is    exactly the same as what the underlying verifiers can sign    (<code>Signable</code> of <code>underlyingVerifier</code>).</li> </ul> <ul> <li>The <code>Commitment</code> type describes composed signatures, these are a    <code>MapCon</code> from hashes of underlying verifiers to signatures    (<code>Commitment</code> of <code>underlyingVerifier</code>)</li> </ul> <ul> <li>The <code>sign</code> function creates a <code>Commitment</code> using all    <code>underlyingSigner</code> <code>SignerType</code>s in the composed <code>SignerType</code>.</li> </ul> <ul> <li>The <code>verify</code> function returns true iff the set of valid Commitments included    correspond to a set of <code>underlyingVerifier</code> <code>VerifierType</code>s whose weights    sum to at least the threshold.</li> </ul> <ul> <li>The <code>signerCompose</code> function constructs a composed <code>SignerType</code> from a list of    <code>Pair VerifierType SignerType</code> pairs.    Note that each <code>SignerType</code> must be paired with its correct <code>VerifierType</code>,     or the composed <code>SignerType</code> will not produce verifiable     <code>Commitment</code>s.</li> </ul> <ul> <li> <p>The <code>verifierCompose</code> function is useful for constructing the composition of    a list of verifiers.   Returns a composed <code>VerifierType</code>.   Its arguments are:</p> <ul> <li>the threshold (<code>Nat</code>)</li> </ul> <ul> <li>a <code>list</code> of weights(<code>Nat</code>), <code>VerifierType</code> pairs.</li> </ul> </li> </ul> <ul> <li>The <code>verifierAnd</code> function creates a composed <code>VerifierType</code> that is the \"&amp;&amp;\" of    two input verifiers: a <code>SignerType</code> must encode the information of the    signers for both <code>x</code> and <code>y</code> to sign statements <code>verifierAnd x y</code>    will verify.</li> </ul> <ul> <li>The <code>verifierOr</code> function creates a composed <code>VerifierType</code> that is the \"||\" of    two input verifiers: a <code>SignerType</code> must encode the information of the    signers for either <code>x</code> or <code>y</code> to sign statements <code>verifierOr x y</code>    will verify.</li> </ul> <pre><code>type ThresholdCompose\n  ( OrdKey : Type ) ( MapCon : Type -&gt; Type )\n  ( VerifierType Signable Commitment SignerType VerifierHashOrdKeyType : Type)\n  :=\n  mkThresholdCompose {\n    map : OrdMap OrdKey MapCon;\n    underlyingVerifier : Verifier OrdKey VerifierType Signable Commitment;\n    underlyingSigner : Signer SignerType Signable Commitment;\n    verifierHash : HASH VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon);\n\n    sign : MapCon SignerType -&gt; Signable -&gt; MapCon Commitment;\n    verify : (ComposeHashable VerifierType MapCon) -&gt; Signable -&gt; MapCon Commitment -&gt; Bool;\n    signerCompose : List (Pair VerifierType SignerType) -&gt; MapCon SignerType;\n    verifierCompose : Nat -&gt; List (Pair Nat VerifierType) -&gt; (ComposeHashable VerifierType MapCon);\n    verifierAnd : VerifierType -&gt; VerifierType -&gt; (ComposeHashable VerifierType MapCon);\n    verifierOr : VerifierType -&gt; VerifierType -&gt; (ComposeHashable VerifierType MapCon);\n  };\n</code></pre> <pre><code>projectVerifier\n  { MapCon : Type -&gt; Type }\n  { OrdKey VerifierType Signable Commitment SignerType VerifierHashOrdKeyType : Type }\n  ( tc : ThresholdCompose OrdKey MapCon VerifierType Signable Commitment SignerType VerifierHashOrdKeyType ) :\n  Verifier VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon) Signable (MapCon Commitment) :=\n  Verifier.mkVerifier@{\n    verify := ThresholdCompose.verify tc;\n    verifierHash := ThresholdCompose.verifierHash tc;\n  };\n</code></pre> <pre><code>ThresholdComposeFunctor\n  { MapCon : Type -&gt; Type }\n  { OrdKey VerifierType Signable Commitment SignerType VerifierHashOrdKeyType : Type }\n  (verifier : Verifier OrdKey VerifierType Signable Commitment)\n  (signer : Signer SignerType Signable Commitment)\n  (mapIn : OrdMap OrdKey MapCon)\n  (thresholdComposeHash : HASH VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon)) :\n  ThresholdCompose\n    OrdKey MapCon\n    VerifierType Signable Commitment\n    SignerType\n    VerifierHashOrdKeyType\n  :=\n  ThresholdCompose.mkThresholdCompose@{\n    map := mapIn;\n    underlyingVerifier := verifier;\n    underlyingSigner := signer;\n    verifierHash := thresholdComposeHash;\n    sign := \\ {s m := OrdMap.map map \\ { i := Signer.sign underlyingSigner i m } s};\n    verify := \\ {\n      | (ComposeHashable.mkComposeHashable t ws) s c := (\n          t &lt;= (\n            OrdMap.foldl map \\{(mkPair x y) := x + y} 0 (\n              OrdMap.intersectWith map (\n                \\{ | (mkPair (mkPair w v) x) :=\n                      if | (Verifier.verify underlyingVerifier v s x) := w\n                         | else := 0\n                }\n            ) (mkPair ws c)))\n      )\n    };\n\n    signerCompose := \\{ l :=\n        foldl\n        \\{ m (mkPair v s) :=\n          OrdMap.insert map (mkPair m (mkPair (\n            HASH.hash (Verifier.verifierHash underlyingVerifier) v\n          ) s))\n        }\n        (OrdMap.empty map) l\n    };\n\n    verifierCompose := \\{\n      threshold weights :=\n        (ComposeHashable.mkComposeHashable threshold\n          (foldl\n            \\ { m (mkPair w v) :=\n              OrdMap.insert map (mkPair m (mkPair (\n                HASH.hash (Verifier.verifierHash underlyingVerifier) v\n              ) (mkPair w v)))\n            }\n            (OrdMap.empty map) weights\n        ))\n    };\n\n    verifierAnd := \\{ x y := verifierCompose 2 [(mkPair 1 x); (mkPair 1 y)]};\n    verifierOr := \\{ x y := verifierCompose 1 [(mkPair 1 x); (mkPair 1 y)] };\n  };\n</code></pre> <p>While this construction is rather naive, it is general, and crucially, we can reason about  equivalence with any number of more interesting schemes:</p> <ul> <li>We can show that a threshold RSA signature scheme <code>signsSameAs</code> as a Threshold Composition    Identity.</li> </ul> <ul> <li>We can show that a secret sharing scheme <code>readsSameAs</code> a Threshold Composition Identity.</li> </ul> <p>By phrasing our discussion in terms of equivalence and Threshold Composition Identities, we can  abstract over the actual cryptography used. We can also derive some <code>signsFor</code> and <code>readsFor</code>  relations that must hold, by looking at the relations that must hold for Threshold Composition Identities:</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#signsfor-threshold-composition","title":"<code>signsFor</code> Threshold Composition","text":"<p>Like any identity, Threshold Composition Identities can define any number of ways to delegate signing power, or be delegated signing power. However, some cases should always hold: A <code>signsFor</code> B if every identity in A has no more weight (divided by threshold) than identities it <code>signsFor</code> in B. This implies that any collection of identities that can sign as A can also sign as B.</p> <p>A <code>signsFor</code> relation for easy comparison of   <code>ThresholdCompose</code> <code>VerifierType</code>s  x <code>signsFor</code> y if every underlying VerifierType in x has no more   weight (divided by threshold) as verifiers it <code>signsFor</code> in y. This implies that anything which can sign as x can also sign  as y.</p> <p>This requires an underlying <code>S : SignsFor</code> for comparing the weighted  signers in x and y, which in turn may require evidence. No additional evidence is required.</p> <p>Other parameters necessary to define the <code>ThresholdCompose</code> <code>verifiers</code> include:</p> <ul> <li><code>signer</code>, the corresponding structure of the underlying <code>signers</code>.</li> </ul> <ul> <li><code>map : OrdMap</code>, to be used to encode weights and <code>Commitment</code>s.   (Note that this needs <code>OrdKey</code> to be the hash type of the    underlying <code>verifier</code>)</li> </ul> <ul> <li><code>thresholdComposeHash</code>, which specifies a <code>hash</code> function that can    hash our composed <code>VerifierType</code>s (type    <code>ComposeHashable VerifierType MapCon</code>).</li> </ul> <pre><code>type ThresholdComposeSignsFor\n  ( OrdKey VerifierType Signable Commitment Evidence : Type )\n  ( MapCon : Type -&gt; Type )\n  ( VerifierHashOrdKeyType )\n  :=\n  mkThresholdComposeSignsFor {\n    underlyingSignsFor : SignsFor OrdKey VerifierType Signable Commitment Evidence;\n    verifier : ThresholdCompose OrdKey MapCon VerifierType Signable Commitment VerifierType VerifierHashOrdKeyType;\n    signsFor : Evidence -&gt; Pair (ComposeHashable VerifierType MapCon) (ComposeHashable VerifierType MapCon) -&gt; Bool;\n  };\n</code></pre> <pre><code>projectSignsFor\n  { OrdKey VerifierType Signable Commitment Evidence }\n  { MapCon : Type -&gt; Type }\n  { VerifierHashOrdKeyType : Type }\n  ( tc : ThresholdComposeSignsFor OrdKey VerifierType Signable Commitment Evidence MapCon VerifierHashOrdKeyType ) :\n  SignsFor VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon) Signable (MapCon Commitment) Evidence :=\n  SignsFor.mkSignsFor@{\n    verifier := projectVerifier (ThresholdComposeSignsFor.verifier tc);\n    signsFor := ThresholdComposeSignsFor.signsFor tc;\n  };\n</code></pre> <pre><code>ThresholdComposeSignsForFunctor\n  { OrdKey VerifierType Signable Commitment Evidence }\n  { MapCon : Type -&gt; Type }\n  { VerifierHashOrdKeyType : Type }\n  ( S : SignsFor OrdKey VerifierType Signable Commitment Evidence )\n  ( signer : Signer VerifierType Signable Commitment)\n  ( map : OrdMap OrdKey MapCon )\n  ( thresholdComposeHash : HASH VerifierHashOrdKeyType (ComposeHashable VerifierType MapCon) ) :\n  ThresholdComposeSignsFor OrdKey VerifierType Signable Commitment Evidence MapCon VerifierHashOrdKeyType\n  :=\n  ThresholdComposeSignsFor.mkThresholdComposeSignsFor@{\n    underlyingSignsFor := S;\n    verifier := ThresholdComposeFunctor (SignsFor.verifier underlyingSignsFor) signer map thresholdComposeHash;\n    signsFor := \\{\n      e (mkPair (ComposeHashable.mkComposeHashable t0 w0) (ComposeHashable.mkComposeHashable t1 w1)) :=\n        OrdMap.all map\n          \\{ (mkPair w v) :=\n              (w * t1) &lt;=\n              ((OrdMap.foldl map\n                \\{ (mkPair (mkPair x v1) s) :=\n                    if | (SignsFor.signsFor underlyingSignsFor e (mkPair v v1)) := x + s\n                       | else := s\n                }\n                0 w1\n                ) * t0)\n          }\n          w0\n    };\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#encryptor-threshold-composition","title":"<code>Encryptor</code> Threshold Composition","text":"<p>DANGER: NOT YET IMPLEMENTED</p> <p>Implementing this requires secret sharing.  The threshold composed <code>encryptor</code> is a threshold, and a set of weights  paired with <code>UnderlyingEncryptor.encryptor</code>s. There are stored in a <code>Map.map</code>  under their hashes, to ensure uniqueness.</p> <p>The idea is that an encrypted <code>plaintext</code> should only be  decryptable by a <code>decryptor</code> that encodes the information from a  set of <code>decryptor</code>s corresponding to a set of <code>encryptor</code>s whose  weight sums to at least the threshold.</p> <pre><code>type ThresholdComposeEncryptor\n  (OrdKey EncryptorType Plaintext Ciphertext : Type)\n  (MapCon : Type -&gt; Type)\n  (EncryptorHashOrdKeyType : Type)\n  :=\n  mkThresholdComposeEncryptor@{\n    map : OrdMap OrdKey MapCon;\n    underlyingEncryptor : Encryptor OrdKey EncryptorType Plaintext Ciphertext;\n    encryptorHash : HASH EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon);\n    compose : Nat -&gt; List (Pair Nat EncryptorType) -&gt; ComposeHashable EncryptorType MapCon;\n    encrypt : (ComposeHashable EncryptorType MapCon) -&gt; Plaintext -&gt; Ciphertext;\n  };\n</code></pre> <pre><code>projectEncryptor\n  {OrdKey EncryptorType Plaintext Ciphertext}\n  {MapCon : Type -&gt; Type}\n  {EncryptorHashOrdKeyType}\n  (tc : ThresholdComposeEncryptor OrdKey EncryptorType Plaintext Ciphertext MapCon EncryptorHashOrdKeyType) :\n  Encryptor EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon) Plaintext Ciphertext\n  :=\n  Encryptor.mkEncryptor@{\n    encrypt := ThresholdComposeEncryptor.encrypt tc;\n    encryptorHash := ThresholdComposeEncryptor.encryptorHash tc;\n  };\n</code></pre> <pre><code>axiom encrypt_DUMMY\n  {EncryptorType Plaintext Ciphertext}\n  {MapCon}\n  : (ComposeHashable EncryptorType MapCon) -&gt; Plaintext -&gt; Ciphertext;\n</code></pre> <pre><code>ThresholdComposeEncryptorFunctor\n  {OrdKey EncryptorType Plaintext Ciphertext}\n  {MapCon : Type -&gt; Type}\n  {EncryptorHashOrdKeyType}\n  (encryptor : Encryptor OrdKey EncryptorType Plaintext Ciphertext)\n  (mapIn : OrdMap OrdKey MapCon)\n  (thresholdComposeHash : HASH EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon)) :\n  ThresholdComposeEncryptor OrdKey EncryptorType Plaintext Ciphertext MapCon EncryptorHashOrdKeyType\n  := ThresholdComposeEncryptor.mkThresholdComposeEncryptor@{\n    map := mapIn;\n    underlyingEncryptor := encryptor;\n    encryptorHash := thresholdComposeHash;\n    compose := \\{\n      t w :=\n        ComposeHashable.mkComposeHashable@{\n          threshold := t;\n          weights :=\n            foldl\n              \\{m (mkPair w e) :=\n                OrdMap.insert map (mkPair m (mkPair (HASH.hash (Encryptor.encryptorHash underlyingEncryptor) e) (mkPair w e)))\n              }\n              (OrdMap.empty map) w\n        }\n    };\n    encrypt := encrypt_DUMMY;\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#readsfor-threshold-composition","title":"<code>readsFor</code> Threshold Composition","text":"<p>Like any identity, ThresholdCompositionIdentities can have arbitrary  <code>readsFor</code> relationships. However, some cases should always hold : A <code>readsFor</code> B if every  identity in A has no more weight (divided by threshold) than  identities it <code>readsFor</code> in B. This implies that any collection of identities that can read messages  encrypted with A can also read messages encrypted as B.</p> <p>A <code>readsFor</code> relation for easy comparison of   <code>ThresholdComposeEncryptor</code> <code>EncryptorType</code>s  x <code>readsFor</code> y if every underlying <code>EncryptorType</code> in x has no more   weight (divided by threshold) as encryptors it <code>readsFor</code> in y. This implies that anything which can decrypt as x can also decrypt  as y.</p> <p>This requires an underlying <code>R : ReadsFor</code> for comparing the weighted  encryptors in  x and y, which in turn may require evidence. No additional evidence is required.</p> <pre><code>type ThresholdComposeReadsFor\n  ( OrdKey EncryptorType Plaintext Ciphertext Evidence : Type )\n  ( MapCon : Type -&gt; Type )\n  ( EncryptorHashOrdKeyType : Type )\n  :=\n  mkThresholdComposeReadsFor@{\n    underlyingReadsFor : ReadsFor OrdKey EncryptorType Plaintext Ciphertext Evidence;\n    encryptor : ThresholdComposeEncryptor OrdKey EncryptorType Plaintext Ciphertext MapCon EncryptorHashOrdKeyType;\n    readsFor : Evidence -&gt; Pair (ComposeHashable EncryptorType MapCon) (ComposeHashable EncryptorType MapCon) -&gt; Bool;\n  };\n</code></pre> <pre><code>projectReadsFor\n  { OrdKey VerifierType Signable Commitment Evidence }\n  { MapCon : Type -&gt; Type }\n  { EncryptorHashOrdKeyType : Type }\n  ( tc : ThresholdComposeReadsFor\n          OrdKey\n          VerifierType\n          Signable\n          Commitment\n          Evidence\n          MapCon\n          EncryptorHashOrdKeyType ) :\n    ReadsFor\n    EncryptorHashOrdKeyType\n    (ComposeHashable VerifierType MapCon)\n    Signable\n    Commitment\n    Evidence\n  := ReadsFor.mkReadsFor@{\n    encryptor := projectEncryptor (ThresholdComposeReadsFor.encryptor tc);\n    readsFor := ThresholdComposeReadsFor.readsFor tc;\n  };\n</code></pre> <pre><code>ThresholdComposeReadsForFunctor\n  { OrdKey EncryptorType Plaintext Ciphertext Evidence}\n  { MapCon : Type -&gt; Type }\n  { EncryptorHashOrdKeyType}\n  ( r : ReadsFor OrdKey EncryptorType Plaintext Ciphertext Evidence )\n  ( map : OrdMap OrdKey MapCon )\n  ( thresholdComposeHash : HASH EncryptorHashOrdKeyType (ComposeHashable EncryptorType MapCon) ) :\n  ThresholdComposeReadsFor OrdKey EncryptorType Plaintext Ciphertext Evidence MapCon EncryptorHashOrdKeyType\n  :=\n  ThresholdComposeReadsFor.mkThresholdComposeReadsFor@{\n    underlyingReadsFor := r;\n    encryptor := ThresholdComposeEncryptorFunctor (ReadsFor.encryptor underlyingReadsFor) map thresholdComposeHash;\n    readsFor := \\{\n      e (mkPair (ComposeHashable.mkComposeHashable t0 w0) (ComposeHashable.mkComposeHashable t1 w1)) :=\n        OrdMap.all map\n          \\{ (mkPair w v) :=\n              (w * t1) &lt;=\n              ((OrdMap.foldl map\n                \\{ (mkPair (mkPair x v1) s) :=\n                    if | (ReadsFor.readsFor underlyingReadsFor e (mkPair v v1)) := x + s\n                       | else := s\n                }\n                0 w1\n              ) * t0)\n          }\n          w0\n    };\n  }\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#and-identities","title":"\"And\" Identities","text":"<p>We can compose identities with conjunction: A <code>&amp;&amp;</code> B is the identity which requires an agent to have both A's internal identity and B's internal identity to sign or decrypt. It represents A and B working together. In practice, A <code>&amp;&amp;</code> B can be defined as a special case of Threshold composition (see <code>verifierAnd</code> above).</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#or-identities","title":"\"Or\" Identities","text":"<p>We can compose identities with disjunction as well: A <code>||</code> B requires an agent to have either A's internal identity or B's internal identity. It represents either A or B, without specifying which. In practice, A <code>||</code> B can be defined as a special case of Threshold Composition (see <code>verifierOr</code> above).</p> <p>In principle, we could define things differently: Threshold Composition could be defined using <code>&amp;&amp;</code> and <code>||</code> as primitives, by building a disjunction of every possible conjunction that satisfies the threshold. In several important cases, however, this takes much more space to express, so we use the equally general and more numerically efficient threshold composition abstraction.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#opaque-composition","title":"Opaque Composition","text":"<p>A group of agents can also compose an opaque identity such that composition information is not available to the outside. One example would be using distributed key generation and a threshold cryptosystem e.g. Threshold RSA. Here the agents compute one RSA keypair together, with only shares of the private key being generated by each agent. Decryption of messages encrypted to the single public key then requires cooperation of a subset of agents holding key shares, fulfilling the threshold requirements. This group would have a single External Identity based on a regular RSA public key, and it would not necessarily be clear how the identity was composed.</p> <p>Specific evidence could prove that this threshold cryptosystem identity is <code>equivalent</code> to some  <code>ThresholdCompose</code> identity. This kind of proof requires <code>readsFor</code> and <code>signsFor</code> relations tailored to the cryptosystem used. Once equivalence is proven, however, one could use the threshold  cryptosystem identity for efficiency, but reason using the  <code>ThresholdCompose</code> identity.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#special-identities","title":"Special identities","text":"<p>The following special identities illustrate the generality of our identity abstractions:</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#true-all","title":"\"true / All\"","text":"<p>Anyone can sign and decrypt (<code>verify</code> returns true and <code>encrypt</code> returns the <code>Plaintext</code>). No secret knowledge is required, so all agents can take on this identity.</p> <p>The true identity preserves structure under conjunction (x <code>&amp;&amp;</code> true <code>equivalent</code> x) and forgets structure under disjunction (x <code>||</code> true <code>equivalent</code> true).</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#false-none","title":"\"false / None\"","text":"<p>No one can sign or decrypt (<code>verify</code> returns false and <code>encrypt</code>  returns empty string). No secret knowledge exists that fulfills these  requirements, so no agent can take on this identity.</p> <p>The false identity forgets structure under disjunction  (x <code>&amp;&amp;</code> false <code>equivalent</code> false) and preserves structure under  disjunction (x <code>||</code> false <code>equivalent</code> x).</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-names","title":"Identity Names","text":"<p>Sometimes it is useful to have a name for an external identity before the relevant cryptographic values are available. For example, we might refer to \"a quorum of validators from chain <code>X</code> at epoch <code>Y</code>\". Before epoch <code>Y</code> has begun, chain <code>X</code> may not have yet decided who constitutes a quorum.</p> <p>It would be possible to build a <code>Verifier</code>, where the evidence that the signers are in fact a quorum of validators from chain <code>X</code> at epoch <code>Y</code> is part of the signature. One might later build a simpler <code>Verifier</code>, which elides this evidence, and then prove that the two <code>signsSameAs</code> using the evidence. However, barring some really exciting cryptography, we'd need to know the quorums from chain <code>X</code> at epoch <code>Y</code> before we could make an <code>Encryptor</code>.</p> <p>We therefore introduce a new type, Identity Name, which represents a placeholder to be filled in when an appropriate external identity can be found. Specifically, each type of identity name comes with a predicate, which can be satisfied by an external identity, and accompanying evidence. Identity names can also be hashed, like external identities.</p> <p>Identity names can be described in two structures: one for checking that  a <code>VerifierType</code> corresponds with an <code>IdentityName</code>, and one for checking  that an <code>EncryptorType</code> corresponds with an <code>IdentityName</code>. The same name can refer to both a <code>VerifierType</code> and an <code>EncryptorType</code>.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#verifier-name-juvix-type","title":"Verifier Name Juvix Type","text":"<p>An <code>IdentityName</code> can be mapped to an appropriate <code>VerifierType</code>  when suitable <code>Evidence</code> is found. Here, <code>checkVerifierName</code> defines what evidence is acceptable for a  <code>VerifierType</code>.</p> <p>Note that <code>IdentityName</code>s are also hashable: we require a structure  <code>verifierNameHash</code> that details how to hash them.</p> <pre><code>type VerifierName\n  (OrdKey VerifierType Signable Commitment Evidence IdentityName VerifierNameHashOrdKeyType) :=\n  mkVerifierName {\n    verifier : Verifier OrdKey VerifierType Signable Commitment;\n    checkVerifierName : IdentityName -&gt; VerifierType -&gt; Evidence -&gt; Bool;\n    verifierNameHash : HASH VerifierNameHashOrdKeyType IdentityName\n  };\n</code></pre>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#encryptor-name-juvix-type","title":"Encryptor Name Juvix Type","text":"<p>An <code>IdentityName</code> can be mapped to an appropriate Encryptor <code>EncryptorType</code>  when suitable <code>Evidence</code> is found. Here, <code>checkEncryptorName</code> defines what evidence is acceptable for an  <code>Encryptor</code> <code>EncryptorType</code>. Note that <code>IdentityName</code>s are also hashable: we require a structure  <code>encryptorNameHash</code> that details how to hash them.</p> <pre><code>type EncryptorName\n  (OrdKey EncryptorType Plaintext Ciphertext Evidence IdentityName EncryptorNameHashOrdKeyType) :=\n  mkEncryptorName {\n    verifier : Encryptor OrdKey EncryptorType Plaintext Ciphertext;\n    checkEncryptorName : IdentityName -&gt; EncryptorType -&gt; Evidence -&gt; Bool;\n    encryptorNameHash : HASH EncryptorNameHashOrdKeyType IdentityName\n  };\n</code></pre> <p>For example, for the identity name \"a quorum of validators from chain <code>X</code> at epoch <code>Y</code>\", a satisfying external identity would be composed from the validators selected for epoch <code>Y</code>, and the accompanying evidence would be a light-client proof from chain <code>X</code> that these are the correct validators for epoch <code>Y</code>.</p> <p>Note that multiple identity names can refer to the same external identity, and in principle, multiple external identities could have the same identity name. Usually, multiple external identities only have the same identity name when there is Byzantine behaviour, but that is not explicitly part of the identity abstractions at this layer.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#sub-identities","title":"Sub-Identities","text":"<p>One particularly common case for identity names is when one party (the super-identity) wants to designate a specific name they use to refer to another identity. Here, the super-identity is acting like a certificate authority: they designate which external identity corresponds with this identity name. This sub-identity is often something the super-identity controls: a specific machine they own, or a process they run on that machine. Such a sub-identity might be associated with a string, such as <code>\"acceptor\"</code>, which might designate the process participating in consensus within a validator. In this case, the predicate should check that the super-identity has signed a statement declaring that the external identity matches the sub-identity.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#notation","title":"\".\" Notation","text":"<p>Because sub-identities using string names are so common, we have a short-cut notation for expressing identity names. Given some identity Alice, for any string <code>\"foo\"</code>, Alice.foo is an identity name. For example, even before they learn anything about Alice, validators might refer to Alice.acceptor to mean the specific process Alice is running to participate in consensus. The identity Alice can sign statements to let people know what external identity they should (immutably) use for Alice.foo or Alice.acceptor. These are left associative, so Alice.foo can designate Alice.foo.bar (shorthand for (Alice.foo).bar) and Alice.foo.bar can designate Alice.foo.bar.baz (shorthand for ((Alice.foo).bar).baz), and so on. These are a special case of sub-identities: X.Y is a sub-identity of X.</p> <p>Formally, we use <code>mkPair (hash Alice) \"foo\"</code> as the Juvix representation of Alice.foo:</p> <p>A specific kind of identity name, wher ethe evidence is a signed  statement from a specified parent saying that it associates this  VerifierType with a specific <code>name</code>.</p> <p>Here,</p> <ul> <li><code>Name</code> is the type the parent identifies with a child.   For example, for <code>name = string</code>, and some identity Alice, we can specify   <code>(hash(Alice),\"bob\")</code>, or Alice.bob, as the identity that   Alice refers to as <code>\"bob\"</code>.</li> </ul> <ul> <li><code>child</code> : <code>Verifier</code> type that can be identified with a name.</li> </ul> <ul> <li> <p><code>parent</code> : <code>Verifier</code> type that signs evidence statements.</p> <p>Crucially, it must be able to sign tuples of the form (string, name, child's hash type) In our example, where Alice refers to Bob as Alice.<code>\"bob\"</code>, <code>child</code> describes Bob, <code>parent</code> describes Alice, and <code>name</code> describes <code>\"bob\"</code>.</p> </li> </ul> <ul> <li><code>hash</code> Describes what will become the <code>verifierNameHash</code>.   Crucially, it must be able to hash pairs of the form   (parent's hash type, name)</li> </ul> <pre><code>SubVerifierFunctor\n  (OrdKey VerifierType Signable Commitment Name ParentOrdKeyType : Type)\n  (child : Verifier OrdKey VerifierType Signable Commitment)\n  (parent : Verifier ParentOrdKeyType VerifierType (Pair String (Pair Name OrdKey)) Commitment)\n  (hash : HASH ParentOrdKeyType (Pair ParentOrdKeyType Name)) :\n  VerifierName OrdKey VerifierType Signable Commitment (Pair VerifierType Commitment) (Pair ParentOrdKeyType Name) ParentOrdKeyType :=\n  VerifierName.mkVerifierName@{\n    verifier := child;\n    checkVerifierName := \\{\n      (mkPair ph n) c (mkPair pv pc) :=\n        (Verifier.verify parent pv (mkPair \"I identify this verifier with this name : \" (mkPair n (HASH.hash (Verifier.verifierHash child) c))) pc) &amp;&amp;\n        ((OrdKey.compare (HASH.ordKey (Verifier.verifierHash parent)) ph (HASH.hash (Verifier.verifierHash parent) pv)) == Equal)\n    };\n    verifierNameHash := hash;\n  }\n</code></pre> <p>In other words, we have a specific, standardized thing an external identity can sign to designate that another external identity corresponds to a \".\" name.</p> <p>Note that we can use \".\" sub-identities for purposes other than identifying identities that the super-identity controls. Alice might have a friend Bob, and designate his external identity as Alice.bob. This is an example of a place where \"sub-identity-ness\" is not transitive: Alice.bob.carol is (Alice.bob).carol, a sub-identity of Alice.bob, so it is up to Bob to designate which external identity he associates with <code>\"carol\"</code>, and Alice has no say: Alice.bob.carol is not a sub-identity of Alice.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-engine","title":"Identity Engine","text":"<p>In practice, using Identity Names requires each physical machine to maintain a mapping from identity names to known external identities. The machine does not have to store the accompanying evidence for each, although it might be useful to do so sometimes (for example, in order to present to a third party). When any process on that machine wants to do any operation using an identity name instead of an external identity, it can query this mapping to see if there is a known external identity to use for that operation.</p> <p>An Identity Engine can also store evidence for known <code>signsFor</code> and <code>readsFor</code> relationships, and help choose which external identity is most efficient for a task. For example, if an agent wants to encrypt a message to \"a quorum of validators from chain <code>X</code> at epoch <code>Y</code>\", they would first resolving the identity name to an identity (possibly a Threshold Composed Identity), and might then ask if there is some known equivalent identity (such as a threshold encryption identity) with cheaper encryption.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/identity/identity.html#identity-name-resolution","title":"Identity Name Resolution","text":"<p>There is no general mechanism for finding external identities (and accompanying evidence) for arbitrary identity names, with arbitrary forms of evidence. However, for some common types of identity names, such as \".\" sub-identities, we can establish a standard server and query language, which participating Identity Engines can query to resolve those identity names.</p>","tags":["system-architecture","identity"],"boost":2},{"location":"arch/system/state/resource_machine/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.index;\n</code></pre>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#introduction","title":"Introduction","text":"<p>The Anoma Resource Machine (ARM) is the part of the Anoma protocol that defines and enforces the rules for valid state updates that satisfy users' preferences. The new proposed state is then agreed on by the consensus participants. In that sense the role of the Anoma Resource Machine in the Anoma protocol is similar to the role of the Ethereum Virtual Machine in the Ethereum protocol.</p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#data-structures","title":"Data structures","text":"<p>The atomic unit of the ARM state is called a resource. Resources are immutable, they can be created once and consumed once. The system state is represented by the set of active resources: the resources that were created but not nullified.</p> <p>Transactions produced by the ARM represent the proposed state update. They consist of actions, which group resources with the same execution context.</p> <p>Ensuring the correctness of the transaction is achieved with the help of non-interactive proofs attached to it:</p> <ol> <li>to prove the transaction is balanced correctly, there are delta proofs. Balance is the criterion of a transaction's completeness.</li> <li>to prove the transaction complies with the ARM rules, there are compliance proofs. Actions are partitioned into compliance units that define the compliance proof scope.</li> <li>to prove the transaction satisfies the user constraints, there are resource logic proofs.</li> </ol> <p></p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#common-flavours-of-arms","title":"Common flavours of ARMs","text":"<p>A resource machine instantiation is called shielded if it achieves both data and function privacy. Any other resource machine is considered transparent from the privacy perspective.</p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#the-role-of-the-arm","title":"The role of the ARM","text":"<p>The ARM is used to create, compose, and verify transactions. It is stateless and run by every node that processes transactions. Anoma users submit their intents to the intent gossip network in the form of unbalanced ARM transactions with metadata, which are received and processed by solvers that output balanced ARM transactions. These transactions are then ordered and finally sent to the executor node, that verifies and executes the transactions in the determined order, updating the global state.</p>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/index.html#the-specification","title":"The specification","text":"<p>This specification describes a common interface shared by all ARM instantiations. Depending on the primitive instantiation choices, the resulting ARM instantiation will have different properties. For example, using zk-SNARKs to create and verify the ARM proofs might result in a succinct or even shielded ARM instantiation. The ARM interface is designed to provide interoperability between different ARM instantiations.</p> <p>The design of the Anoma Resource Machine was significantly inspired by the Zcash protocol.</p> <ul> <li>Keywords: anoma, blockchain technology, protocol design, resource machine</li> </ul>","tags":["resource-machine","protocol","commitment","nullifier","accumulator","resource logic"],"boost":2},{"location":"arch/system/state/resource_machine/data_structures/action/index.html","title":"Action","text":"<p>icon: material/file-document-outline search:   exclude: false   boost: 2</p> <pre><code>module arch.system.state.resource_machine.data_structures.action.index;\n</code></pre>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#action","title":"Action","text":"<p>An action is a composite structure of type <code>Action</code> that contains the following components:</p> Component Type Description <code>logicVerifierInputs</code> <code>Map Tag LogicVerifierInputs</code> For each resource tag, contains the associated logic proof and everything required to verify it. The structure of <code>LogicVerifierInputs</code> is further described below. <code>complianceUnits</code> <code>List ComplianceUnit</code> The set of transaction's compliance units."},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#logicverifierinputs","title":"<code>LogicVerifierInputs</code>","text":"Name Type Description <code>verifyingKey</code> <code>ResourceLogicProvingSystem.verifyingKey</code> Contains the verifying key used to verify the logic proof. <code>applicationData</code> <code>(ResourcePayload, DiscoveryPayload, ExternalPayload, ApplicationPayload)</code> Contains inputs required to verify the RL proof. Each payload type is <code>List(BitString, DeletionCriterion)</code>. The tuple entries are further described below. The deletion criterion field is further described here. <code>proof</code> <code>ResourceLogicProvingSystem.Proof</code> The proof of the resource logic."},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#applicationdata","title":"<code>applicationData</code>","text":"<p>Application data contains the inputs required to verify the RL proof. It has four entries, all of which of type <code>List (BitString, DeletionCriterion)</code>:</p> <ol> <li><code>ResourcePayload</code> \u2013 contains resource-object-related data. For example, encrypted (or not) resource object.</li> <li><code>DiscoveryPayload</code> \u2013 contains data related to discovery, for example, FMD ciphertext.</li> <li><code>ExternalPayload</code> \u2013 contains data associated with external calls, for example, <code>forwarderCallData</code> from Ethereum.</li> <li><code>ApplicationPayload</code> \u2013 contains other data expected by the resource logic, for example, a signature to be verified.</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#definitions","title":"Definitions","text":"<p>Actions partition the state change induced by a transaction and limit the evaluation context of resource logics: proofs created in the context of an action have access only to the resources associated with the action. A resource is said to be associated with an action if its tag is a key of the <code>logicVerifierInputs</code> map. A resource is associated with at most two actions: resource creation is associated with exactly one action and resource consumption is associated with exactly one action. A resource is said to be consumed in the action for a valid action if its nullifier is a key of the <code>logicVerifierInputs</code> map. A resource is said to be created in the action for a valid action if its commitment is a key of the <code>logicVerifierInputs</code> map.</p> <p>Note</p> <p>Unlike transactions, actions don't need to be balanced, but if an action is valid and balanced, it is sufficient to create a balanced transaction.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#interface","title":"Interface","text":"<ol> <li><code>create(List (NullifierKey, Resource, deltaExtraInput, CMtreePath, CMTreeRoot, applicationData, PS.Witness), List (Resource, deltaExtraInput, applicationData, PS.Witness)) -&gt; Action</code></li> <li><code>verify(Action) -&gt; Bool</code></li> <li><code>delta(Action) -&gt; DeltaHash</code></li> <li><code>to_instance(Action, Tag) -&gt; Maybe ResourceLogicProvingSystem.Instance</code></li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#proofs","title":"Proofs","text":"<p>For each resource consumed or created in the action, it is required to provide a proof that the logic associated with that resource evaluates to <code>True</code> given the input parameters that describe the state transition induced by the action. The number of such proofs in an action equals to the amount of resources (both created and consumed) in that action, even if some resources have the same logics. Resource logic proofs are further described here.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#create","title":"<code>create</code>","text":"<ol> <li><code>complianceUnits</code>: Partition the resources into compliance units and compute a compliance proof for each unit</li> <li><code>logicVerifierInputs</code>: For each resource, compute a resource logic proof and associate each proof with the tag of the resource and other components that are required to verify it.</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#verify","title":"<code>verify</code>","text":"<p>Validity of an action can only be determined for actions that are associated with a transaction. Assuming that an action is associated with a transaction, an action is considered valid if all of the following conditions hold:</p> <ol> <li>All resource logic proofs associated with the action are valid</li> <li>All compliance proofs associated with the action are valid: <code>cu.verify() = True for cu in complianceUnits</code></li> <li><code>logicVerifierInputs</code> keys = the list of tags associated with <code>complianceUnits</code> (ignoring the order)</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#delta","title":"<code>delta</code>","text":"<p><code>action.delta()</code> computes the action delta. Action delta is computed from <code>r.delta()</code> of the resources that comprise the action and defined as <code>action.delta() = sum(cu.delta() for cu in action.complianceUnits)</code>.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/index.html#to_instance","title":"<code>to_instance</code>","text":"<p>This function assembles the instance required to verify a resource logic proof from the data in the action.</p> <p>The main task is to assemble the tree root containing all created and consumed resource in the action. The exact depth and shape of the tree is instantiation-dependent.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html","title":"Resource logic proof","text":"<p>icon: material/file-document-outline search:   exclude: false   boost: 2</p> <pre><code>module arch.system.state.resource_machine.data_structures.action.resource_logic_proof;\n</code></pre>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#resource-logic-proof","title":"Resource logic proof","text":"<p>Resource logic proofs attest to validity of resource logics. A resource logic is a computable predicate associated with a resource (this resource is referred to as <code>self</code> in this context) that constrains the creation and consumption of a resource. Each time a resource is created or consumed, the corresponding resource logic proof is required in order for the action (and thus the transaction) to be valid.</p> <p>It is worth noting that resource logics are permissionless. The ARM, acting as the verifier, can only control the instance shape.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#action-tree","title":"Action tree","text":"<p>When proving, resource logics take as input resources created and consumed in that action represented by a root of a merkle tree containing the relevant resources.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#instance","title":"Instance","text":"<ol> <li>Resource's commitment/nullifier</li> <li><code>isConsumed</code> - a flag that tells the logic if the resource is consumed or created. Can be inferred from the position of the tag in the corresponding compliance unit.</li> <li><code>actionTreeRoot</code>. Action tree is a Merkle tree that contains commitments and nullifiers of the action resources. The resource logic takes as input the root of the action tree.</li> <li><code>applicationData.ResourcePayload</code></li> <li><code>applicationData.DiscoveryPayload</code></li> <li><code>applicationData.ExternalPayload</code></li> <li><code>applicationData.ApplicationPayload</code></li> </ol> <p>Including <code>applicationData</code> payloads in the instance requires collecting the first entry from each tuple: <code>List (BitString, DeletionCriterion) -&gt; List BitString</code>. We assume that a proving system can differentiate between the four payloads, in partciular, given an argument from application data, the circuit can differentiate from which payload it came.</p> <p>The original order of the elements must be preserved at each step.</p>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#witness","title":"Witness","text":"<p>Note</p> <p>As resource logics are permissionless, the RM does not control the possible witness structure. Nevertheless, below we provide the recommended structure for applications to support.</p> <ol> <li><code>self</code> resource object</li> <li>If <code>isConsumed = True</code>: nullifier key of <code>self</code></li> <li>Resource objects of consumed resources: <code>List (Resource, NullifierKey, ActionTreePath)</code></li> <li>Resource objects of created resources: <code>List (Resource, ActionTreePath)</code></li> <li>Application-specific inputs</li> </ol>"},{"location":"arch/system/state/resource_machine/data_structures/action/resource_logic_proof.html#constraints","title":"Constraints","text":"<p>Note</p> <p>The circuit contraints 1-3 are also recommended but ultimately can only be decided to be enforced by applications themselves.</p> <ol> <li>For created resources: created commitment integrity: <code>r.commitment() = cm</code></li> <li>For consumed resources: <code>r.nullifier(nullifierKey) = nf</code></li> <li>Application-specific constraints</li> </ol> <p>Checks that require access to global <code>CMTree</code> and <code>NullifierSet</code>:</p> <ol> <li>each created resource wasn't created in prior transactions</li> <li>each consumed resource wasn't consumed in prior transactions</li> </ol> <p>Note</p> <p>Actions can be verified as parts of supposedly valid transactions and individually, when building a valid transaction (e.g., in the partial solving case). In case the actions are verified not individually, all global checks can be aggregated and verified at once to reduce the amount of global communication.</p>"},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html","title":"Compliance proof","text":"<pre><code>module arch.system.state.resource_machine.data_structures.compliance_unit.compliance_proof;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#compliance-proof","title":"Compliance proof","text":"<p>Compliance proofs are created by <code>ComplianceProvingSystem</code> and computed over compliance units. Compliance proofs ensure that the provided state transition complies with the resource machine definitions.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#compliance-inputs","title":"Compliance inputs","text":"","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#instance","title":"Instance","text":"Name Type Description <code>consumed</code> <code>List (nf: Nullifier, root: CMTree.Value, logicVKOuter: LogicVKOuterHash)</code> Each entry corresponds to a consumed resource and includes a hash of the resource's <code>logicRef</code> component <code>created</code> <code>List (cm: Commitment, logicVKOuter: LogicVKOuterHash)</code> Each entry corresponds to a created resource <code>unitDelta</code> <code>DeltaHash</code>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#witness","title":"Witness","text":"<ol> <li> <p>for consumed resources:</p> <p>1. resource object <code>r</code></p> <p>2. <code>nullifierKey</code></p> <p>3. <code>CMtree</code> path to the consumed resource commitment</p> <p>4. pre-image of <code>logicVKOuter</code></p> <p>5. <code>deltaExtraInput</code> used to compute resource delta</p> </li> <li> <p>for created resources:</p> <ol> <li> <p>resource object <code>r</code></p> </li> <li> <p>pre-image of <code>logicVKOuter</code></p> </li> <li> <p><code>deltaExtraInput</code> used to compute resource delta</p> </li> </ol> </li> </ol> <p>Note</p> <p>Instance and witness elements are expected to go in the same order: the first element of the instance corresponds to the first (4 for consumed and 2 for created) elements of the witness and so on.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_proof.html#compliance-constraints","title":"Compliance constraints","text":"<p>Each resource machine compliance proof must check the following:</p> <ol> <li> <p>Merkle path validity: <code>CMTree::Verify(r.commitment(), path, root) = True</code> for each resource associated with a nullifier from the <code>consumed</code>. For ephemeral resources a \"fake\" relation is checked.</p> </li> <li> <p>For each consumed resource <code>r</code>:</p> <ol> <li>Nullifier integrity: <code>r.nullifier(nullifierKey) is in consumed</code></li> <li>Logic integrity: <code>logicVKOuter = logicVKOuterHash(r.logicRef, ...)</code></li> </ol> </li> <li> <p>For each created resource <code>r</code>:</p> <ol> <li>Commitment integrity: <code>r.commitment() is in created</code></li> <li>Logic integrity: <code>logicVKOuter = logicVKOuterHash(r.logicRef, ...)</code></li> </ol> </li> <li> <p>Delta integrity: <code>unitDelta = sum(r.delta(deltaExtraInput(r)) for r in consumed) - sum(r.delta(deltaExtraInput(r)) for r in created)</code> where <code>deltaExtraInput(r)</code> returns <code>deltaExtraInput</code> associated with resource <code>r</code></p> </li> </ol> <p>Note</p> <p>Kind integrity is checked implicitly in delta integrity</p> <p>Note</p> <p>[2.3, 3.2]: Combined with checking the logic proofs, logic integrity checks allow to ensure that the logics associated with the resources are satisfied</p> <p>Note</p> <p>[2.1, 3.1]: To ensure correct binding between the instance and the witness, resource tags have to be recomputed from the witness and compared to what is provided in the instance.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html","title":"Compliance unit","text":"<pre><code>module arch.system.state.resource_machine.data_structures.compliance_unit.compliance_unit;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#compliance-unit","title":"Compliance unit","text":"<p><code>ComplianceUnit</code> is a data structure used to verify compliance proofs. It partitions the action, meaning that:</p> <ol> <li>there might be multiple compliance units for a single action</li> <li>the sets of resource tags validated by any two compliance units don't intersect</li> <li>together the compliance units cover all of the resources in the action</li> </ol> <p>The table below describes the components of a compliance unit:</p> Component Type Description <code>vk</code> <code>ComplianceProvingSystem.VerifyingKey</code> The verifying key for the compliance circuit. Assumed to correspond to the hardcoded verifying key stored per ARM instance. <code>instance</code> <code>ComplianceProvingSystem.Instance</code> The instance required to verify the compliance proof. Includes the tags of the checked resources, compliance unit delta, <code>CMtree</code> roots for consumed resources. <code>proof</code> <code>ComplianceProvingSystem.Proof</code> Compliance proof. <p>The number of created and consumed resources in each unit is determined by the resource machine instantiation. The total number of compliance proofs required for an action is determined by the number of compliance units that comprise the action. For example, if the instantiation defines a single compliance proof to include 1 input and 1 output resource, and an action contains 3 input and 2 output resources, the total number of compliance units will be 3 (with a placeholder output resource in the third compliance unit).</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#interface","title":"Interface","text":"<ol> <li><code>create(ComplianceProvingSystem.ProvingKey, ComplianceProvingSystem.VerifyingKey, ComplianceProvingSystem.Instance, ComplianceProvingSystem.Witness) -&gt; ComplianceUnit</code> - computes the compliance unit proof and populates the compliance unit</li> <li><code>created(ComplianceUnit) -&gt; List Commitment</code> - returns the commitments of the created resources checked in the unit</li> <li><code>consumed(ComplianceUnit) -&gt; List Nullifier</code> - returns the nullifiers of the consumed resources checked in the unit</li> <li><code>verify(ComplianceUnit) -&gt; Bool</code> - returns <code>ComplianceProvingSystem.Verify(vk, instance, proof)</code></li> <li><code>delta(ComplianceUnit) -&gt; DeltaHash</code> - returns the compliance unit delta, which is stored in <code>complianceData</code>: <code>unit.delta() = unit.complianceData.delta</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#create","title":"<code>create</code>","text":"<p>Create is a function that provers use to create a compliance unit.</p> <ol> <li>Compute the compliance proof: <code>ComplianceProvingSystem.Prove(ComplianceProvingSystem.ProvingKey, ComplianceProvingSystem.Instance, ComplianceProvingSystem.Witness) -&gt; ComplianceProvingSystem.Proof</code>. What comprises the instance and witness here is described in Compliance proof.</li> <li>Create the compliance unit given the proof, verifying key, and instance.</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#delta","title":"Delta","text":"<p>Compliance unit delta is used to compute action and transaction deltas and is itself computed from resource deltas: <code>delta = sum(r.delta(deltaExtraInput(r))) for r in outputResources - sum(r.delta(deltaExtraInput(r)) for r in inputResources))</code>. Note that the delta is computed by the prover (who knows the resource objects of resources associated with the unit) and is a part of the instance. The compliance proof must ensure the correct computation of delta from the resource deltas available at the proving time.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#delta-for-computing-balance","title":"Delta for computing balance","text":"<p>From the homomorphic properties of Delta hash, for the resources of the same kind \\(kind\\), adding together the deltas of the resources results in the delta corresponding to the total quantity of that resource kind: \\(\\sum_j{h_\\Delta(kind, q_{r_{i_j}})} - \\sum_j{h_\\Delta(kind, q_{r_{o_j}})} = \\sum_j{\\Delta_{r_{i_j}}} - \\sum_j{\\Delta_{r_{o_j}}} =  h_\\Delta(kind, q_{kind})\\), where \\(q_{kind}\\) is the total quantity of the resources of kind \\(kind\\).</p> <p>The kind-distinctness property of \\(h_\\Delta\\) allows computing \\(\\Delta = \\sum_j{\\Delta_{r_{i_j}}} - \\sum_j{\\Delta_{r_{o_j}}}\\) adding resources of all kinds together without the need to account for distinct resource kinds explicitly: \\(\\sum_j{\\Delta_{r_{i_j}}} - \\sum_j{\\Delta_{r_{o_j}}} = \\sum_j{h_\\Delta(kind_j, q_{kind_j})}\\).</p> <p>Note</p> <p>The delta extra inputs omitted in the formulae above are added/subtracted accordingly.</p> <p>As a result, the properties of <code>DeltaHash</code> allow computing the total balance for a compliance unit, action, or transaction, without having direct access to quantities and kinds of the resources that comprise the data structure.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/compliance_unit/compliance_unit.html#verify","title":"<code>verify</code>","text":"<ol> <li><code>vk</code> is an approved verifying key for the hardcoded compliance proof.</li> <li><code>ComplianceProvingSystem.Verify(vk, instance, proof) = True</code></li> <li>Global check: <code>CMTree</code> roots used to verify the proof are valid <code>CMTree</code> roots</li> </ol> <p>Note</p> <p>Compliance units can be verified as parts of supposedly valid transactions and individually, when building a valid transaction (e.g., in the partial solving case). In case the compliance units are verified not individually, all global checks can be aggregated and verified at once to reduce the amount of global communication.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.index;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/index.html#resource","title":"Resource","text":"<p>A resource is a composite structure <code>Resource</code> that contains the following components:</p> Component Type Description <code>logicRef</code> <code>LogicVKCompact</code> Resource logic's verifying key <code>labelRef</code> <code>LabelHash</code> Hash of the resource label. Resource label specifies the fungibility domain for the resource. Resources within the same fungibility domain are seen as equivalent kinds of different quantities. Resources from different fungibility domains are seen and treated as non-equivalent kinds. This distinction comes into play in the balance check described later <code>valueRef</code> <code>ValueHash</code> Hash of the resource value. Resource value is the fungible data associated with the resource. It contains extra information but does not affect the resource's fungibility <code>quantity</code> <code>Quantity</code> is a number representing the quantity of the resource <code>isEphemeral</code> <code>Bool</code> is a flag that reflects the resource's ephemerality. Ephemeral resources do not get checked for existence when being consumed <code>nonce</code> <code>Nonce</code> guarantees the uniqueness of the resource computable components <code>nullifierKeyCommitment</code> <code>NullifierKeyCommitment</code> is a nullifier key commitment. Corresponds to the nullifier key \\(nk\\) used to derive the resource nullifier (nullifiers are further described here) <code>randSeed</code> <code>RandSeed</code> randomness seed used to derive whatever randomness needed <p>To distinguish between the resource data structure consisting of the resource components and a resource as a unit of state identified by just one (or some) of the resource computed fields, we sometimes refer to the former as a resource object. Data which is referenced by the resource object - such as the preimage of <code>valueRef</code> - we refer to as resource-linked data.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/delta.html","title":"Delta","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.delta;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/delta.html#resource-delta","title":"Resource Delta","text":"<p>Resource delta is used to reason about the total quantities of different kinds of resources in transactions. For a resource <code>r</code>, its delta is computed as <code>r.delta(deltaExtraInput) = deltaHash(r.kind(), r.quantity, deltaExtraInput)</code>. <code>deltaExtraInput</code> contains the extra data required to derive resource delta, e.g., randomness. It may be empty if no extra data is required.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/delta.html#delta-for-data-structures","title":"Delta for data structures","text":"<p>Delta is a computable component that can be computed for compliance units, actions, and transactions from resource deltas of the resources comprising the data structures.</p> <p>Note that transactions are partitioned into actions, actions are partitioned into compliance units, and compliance units are partitioned into resources. For that reason, the mechanism for computation of the deltas of these data structures is almost the same.</p> <ol> <li>For compliance units, delta is computed by using signed addition over the deltas of the resources that comprise the unit: <code>unit.delta() = sum(r.delta(deltaExtraInput(r))) for r in outputResources - sum(r.delta(deltaExtraInput(r)) for r in inputResources))</code></li> <li>For actions, delta is computed by adding the deltas of the compliance units that comprise the action: <code>action.delta() = sum(unit.delta() for unit in action)</code>. To make sure the action's delta is computed correctly, validate the compliance unit delta and make sure the action's deltas are computed using compliance unit deltas values.</li> <li>For transactions, delta is computed by adding the deltas of the actions that comprise the transaction: <code>transaction.delta() = sum(action.delta() for unit in transaction)</code>. To make sure transaction's delta is computed correctly, make sure it is computed using the validated action deltas.</li> </ol> <p>Note</p> <p>For every data structure, the delta can also be computed directly from resource deltas that comprise it, the way it is done for compliance units.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/introduction.html","title":"Introduction","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.introduction;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/introduction.html#computable-components","title":"Computable components","text":"<p>Resource computable components are the components that are not a resource component but can be derived from the resource components, other computable components, and possibly some extra data.</p> <p>Resources have four computable components:</p> <ol> <li>Resource Commitment</li> <li>Nullifier</li> <li>Kind</li> <li>Delta</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/introduction.html#tag","title":"Tag","text":"<p>The resource tag is used to identify a resource when checking constraints without referring to the resource's plaintext directly: <code>tag(Resource, Bool) -&gt; Commitment or Nullifier</code>.</p> <p>For created resources: <code>r.tag(consumed=False) = r.commitment()</code>; for consumed resources: <code>r.tag(consumed=True) = r.nullifier(nullifierKey)</code></p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/kind.html","title":"Kind","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.kind;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/kind.html#kind","title":"Kind","text":"<p>For a resource <code>r</code>, its kind is computed as: <code>r.kind() = kindHash(r.labelRef, r.logicRef)</code>.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/nullifier.html","title":"Nullifier","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.nullifier;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/nullifier.html#nullifier","title":"Nullifier","text":"<p>A resource nullifier is a computed field, the publishing of which marks the resource associated with the nullifier as consumed.</p> <p>For a resource <code>r</code>, <code>r.nullifier(nullifierKey) = nullifierHash(nullifierKey, r)</code>, where <code>nullifierKey</code> is a key provided externally.</p> <p>A resource can be consumed only once. Nullifiers of consumed resources are stored in a public append-only structure called the resource nullifier set. This structure is external to the resource machine, but the resource machine can read from it and append to it.</p> <p>Note</p> <p>Every time a resource is consumed, it has to be checked that the resource existed before (the resource's commitment is in the commitment tree) and has not been consumed yet (the resource's nullifier is not in the nullifier set).</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/resource_commitment.html","title":"Commitment","text":"<pre><code>module arch.system.state.resource_machine.data_structures.resource.computable_components.resource_commitment;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/resource/computable_components/resource_commitment.html#resource-commitment","title":"Resource Commitment","text":"<p>Resource commitment is a unique identifier of a resource used to prove the resource's existence and address the resource. Using resource commitment allows to decouple resource semantics (contained in the resource object) and the fact of the resource's existence. For a resource <code>r</code>, <code>r.commitment() = commitmentHash(r)</code>.</p> <p>To establish the resource's existence, its commitment is added to a global structure called a commitment tree. This structure is external to the resource machine but the resource machine can read from it.</p> <p>Note</p> <p>The resource commitment is also used as the resource's address \\(r.addr\\) in the content-addressed storage.</p> <p>Note</p> <p>Consumption of the resource does not necessarily affect the resource's status in the storage (e.g., it doesn't get deleted).</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html","title":"Delta proof","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.delta_proof;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#delta-proof","title":"Delta proof","text":"","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#instance","title":"Instance","text":"Name Type Description <code>delta</code> <code>DeltaHash</code> Transaction delta (computed from compliance unit deltas by adding them together) <code>expectedBalance</code> <code>Balance</code> Balanced transactions have delta pre-image 0 for all involved kinds, for unbalanced transactions <code>expectedBalance</code> is a non-zero value","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#witness","title":"Witness","text":"<ol> <li>Resource delta pre-images</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/delta_proof.html#constraints","title":"Constraints","text":"<ol> <li><code>delta = sum(unit.delta() for unit in action.units for action in tx)</code> - can be checked outside of the circuit since all values are public</li> <li><code>delta</code>'s preimage's quantity component is <code>expectedBalance</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html","title":"Transaction","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.transaction;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#transaction","title":"Transaction","text":"<p>A transaction is a necessary and sufficient collection of fields required to validate and apply a state update to the state. It is a composite structure that contains the following components:</p> Component Type Description <code>actions</code> <code>Set Action</code> A set of actions that comprise the transaction <code>deltaProof</code> <code>DeltaProvingSystem.Proof</code> Balance proof. It makes sure that <code>transactionDelta</code> is correctly derived from the actions' deltas and commits to the expected publicly known value, called a balancing value. There is just one delta proof per transaction <code>delta_vk</code> <code>DeltaProvingSystem.VerifyingKey</code> Used to verify the delta proof. Might be optional in case the key is computable from other components <code>expectedBalance</code> <code>Balance</code> Balanced transactions have delta pre-image 0 for all involved kinds, for unbalanced transactions <code>expectedBalance</code> is a non-zero value.","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#interface","title":"Interface","text":"<ol> <li><code>create(Set Actions, DeltaProvingSystem.ProvingKey, DeltaProvingSystem.Instance, DeltaProvingSystem.Witness) -&gt; Transaction</code></li> <li><code>compose(Transaction, Transaction) -&gt; Transaction</code></li> <li><code>verify(Transaction) -&gt; Bool</code></li> <li><code>delta(Transaction) -&gt; DeltaHash</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#create","title":"<code>create</code>","text":"<p>Given a set of actions alongside delta data, a transaction is formed as follows:</p> <ol> <li><code>tx.actions = actions</code></li> <li><code>tx.deltaProof = DeltaProvingSystem.Prove(DeltaProvingSystem.ProvingKey, DeltaProvingSystem.Instance, DeltaProvingSystem.Witness)</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#compose","title":"<code>compose</code>","text":"<p>Having two transactions <code>tx1</code> and <code>tx2</code>, their composition <code>compose(tx1, tx2)</code> is defined as a transaction <code>tx</code>, where:</p> <ol> <li><code>tx.actions = Set.union(tx1.actions, tx2.actions)</code></li> <li><code>tx.deltaProof, tx.delta_vk = DeltaProvingSystem.aggregate(tx1.deltaProof, tx1.delta_vk, tx2.deltaProof, tx2.delta_vk)</code></li> </ol> <p>Note</p> <p>When composing transactions, action sets are simply united. For example, composing a transaction with two actions and another transaction with three actions will result in a transaction with five actions, given all actions are distinct.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#verify","title":"<code>verify</code>","text":"<p>A transaction is considered valid if the following statements hold:</p> <p>Checks that do not require access to global structures:</p> <ol> <li>all actions in the transaction are valid, as defined per action validity rules</li> <li>actions partition the state change induced by the transaction:<ol> <li>there is no resource created more than once across actions</li> <li>there is no resource consumed more than once across actions</li> </ol> </li> <li><code>deltaProof</code> is valid</li> </ol> <p>A transaction is executable if it is valid and <code>transactionDelta</code> commits to the expected balancing value.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction.html#delta","title":"<code>delta</code>","text":"<p>Transaction delta is a hash of transaction balance - the total quantity change per resource kind induced by the transaction. It isn't computed from the transaction balance directly by applying a hash function to it, but rather by using the homomoprhic properties of <code>deltaHash</code>: adding action deltas together results in transaction delta.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_function.html","title":"Transaction Function","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.transaction_function;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_function.html#transaction-function","title":"Transaction Function","text":"<p>A transaction function <code>TransactionFunction</code> is a function that outputs a transaction: <code>transactionFunction() -&gt; Transaction</code>.</p> <p>Transaction functions take no input but can perform I/O operations to read information about global state either by reading data at the specified global storage address or by fetching data by index. The requirements for transaction functions are further described in Transaction function format.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html","title":"Transaction With Payment","text":"<pre><code>module arch.system.state.resource_machine.data_structures.transaction.transaction_with_payment;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html#transaction-with-payment","title":"Transaction With Payment","text":"<p><code>TransactionWithPayment</code> is a data structure that allows paying for the desired state transitions.</p>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html#definition","title":"Definition","text":"<p><code>TransactionWithPayment</code> contains the following fields:</p> Type <code>stateTransitionFunction</code> <code>TransactionFunction</code> The desired state update. <code>paymentTransaction</code> <code>Transaction</code> The payment transaction. It is unbalanced, contains consumed resources (gas payment sent) but not created (the receiver is not specified). Includes in a special application data field the hash of the transaction function and the gas limit. <code>gasLimit</code> <code>Arithmetic</code> The maximum amount of gas that can be used for execution of the <code>StateTransition</code>","boost":2},{"location":"arch/system/state/resource_machine/data_structures/transaction/transaction_with_payment.html#execution","title":"Execution","text":"<p>When executing a <code>TransactionFunctionWithPayment</code>, the executor takes the following steps:</p> <ol> <li>Checks that <code>paymentTransaction</code> is \u201csimple\u201d. What exactly this means can be executor-specific, but roughly \u201csimple\u201d means \u201cinexpensive to verify\u201d. A basic (very restrictive) check could be that the payment transaction has exactly one consumed resource and nothing else.</li> <li>Decide whether this gas payment is sufficient. This decision can be controller-specific (maybe there are certain assets and certain prices accepted for gas).</li> <li>Alter <code>paymentTransaction</code>, adding new resources assigned to the executor (or whoever is supposed to receive the gas payments) as necessary to make the payment transaction balanced.</li> <li>Verify <code>paymentTransaction</code>, including in a special application data field the hash of the transaction function and the gas limit.</li> <li>Execute <code>paymentTransaction</code> (apply the state changes).</li> <li>Evaluate <code>stateTransitionFunction</code>, limited by <code>gasLimit</code>.</li> <li>If <code>stateTransitionFunction</code> evaluation finishes within <code>gasLimit</code> (returning a transaction object), check that the transaction object is valid and balanced (gas is charged for these checks as well), and if so apply it to state (as previously in the RM).</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html","title":"Execution flow","text":"<pre><code>module arch.system.state.resource_machine.execution_flow.flow;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#intro","title":"Intro","text":"<p>This section describes the resource machine execution flow and how it is used by various actors.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#resource-machine","title":"Resource machine","text":"<p>A resource machine is a deterministic stateless machine that creates, composes, and verifies transaction functions.</p> <p>It has read-only access to the external global state, which includes the content-addressed storage system (which in particular stores resources), global commitment accumulator, and the global nullifier set, and can produce writes to the external local state that will later be applied to the system state.</p> <p>The resource machine must have the functionality to produce, compose, and evaluate transaction functions and transactions.</p> <p>Actors working with resource machine include users, solvers, and executor nodes.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#users","title":"Users","text":"<p>Users are the initiators of the state change. To initiate the state change, users send the information about the desired state change to solvers. Users own the resources to be consumed/created in the transaction, meaning they are the <code>nullifierKey</code> holders and they control the transaction authorisation mechanism (resource logics).</p> <p>Users are not always online and limited in computational power.</p> <p>Users can create initial actions and transactions that don't require matching, but are assumed to delegate all matching computations to solvers (note that users can take the solver role for themselves as well). To create such transactions, users are expected to be able to do all of the things required to create a transaction, which includes creating all existing data structures, creating all types of proofs, and being able to access the global state.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#solvers","title":"Solvers","text":"<p>Solvers are the parties that have the computational power. Solvers are the parties that see intents and try to match them and output a transaction. Users give solvers the data required to create the future transactions, which may include resource objects, <code>nullifierKey</code>, signed messages, etc. Given the data, solvers create, compose, and verify transactions. Once the transaction is complete and valid, the transaction function is sent for ordering.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#executor","title":"Executor","text":"<p>Executors are the final nodes that receive transaction functions after ordering and produce a state change. After receiving a transaction function, the executor runs it, outputting a transaction that describes a state update. The executor node validates the resulting transaction, by performing the checks described here. In case the transaction is valid, the executor applies the state changes: adds nullifiers to the nullifier set, commitments to the commitment tree, and possibly some other data to the storage.</p>","boost":2},{"location":"arch/system/state/resource_machine/execution_flow/flow.html#post-and-pre-ordering-execution","title":"Post- and pre-ordering execution","text":"<p>Pre-ordering execution implies partial evaluation of the transaction function. In practice pre-ordering execution happens before the transactions are ordered by the ordering component external to the ARM.</p> <p>Post-ordering execution implies full evaluation of the transaction function. As the name suggests, post-ordering execution happens after the ordering component external to the ARM completed the ordering of transaction functions.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html","title":"Applications","text":"<pre><code>module arch.system.state.resource_machine.notes.applications;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#applications","title":"Applications","text":"<p>The ARM applications are characterised by a set of resource logics and associated read and write interfaces.</p> <p>\\(Application = (AppLogic, AppReadInterface, AppWriteInterface)\\), where</p> <ol> <li>\\(AppLogic \\subseteq \\mathbb{F}_l\\) is a set of resource logics.</li> <li>\\(AppWriteInterface = \\{tf: TransactionFunction\\}\\) is a set of functions that represents what kinds of state transitions the application offers.</li> <li>\\(AppReadInterface = \\{pf: ProjectionFunction\\}\\) is a set of functions that interprete the current state. Projection functions are defined as \\(ProjectionFunction: AppState \\rightarrow T\\), where \\(AppState = AppResources \\times AppData\\), with \\(AppResources\\) containing all resources bound to the application\u2019s logic and \\(AppData\\) referring to the non-linear data the application might assume.</li> </ol> <p>As any abstract state transition can be represented as a transaction consuming and creating resources of certain kinds (or a transaction function that evaluates to such a transaction), the transaction functions associated with the application represent the set of actions that the application can provide to its users. Each transaction function would require a subset of the application resource logics to approve the transaction in order to realise the desired action. The transaction function evaluated with the exact resources to be created and consumed forms a transaction.</p> <p>The resources that are bound with the application resource logics are said to belong to the application and, along with some non-linear data the application might assume, constitute the application state. When the application does not have any resources that were created but not consumed yet, the application only exists virtually but not tangibly.</p> <p>The abstraction of an application is virtual - applications are not deployed or tracked in any sort of global registry, and the ARM is unaware of the existence of applications.</p> <p>We define \\(AppKinds \\subseteq \\mathbb{F}_{kind}\\) as a union of all resource kinds that are involved in the transaction functions that comprise the application interface.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#composition","title":"Composition","text":"<p>Applications are composable. The composition of two (or more) applications would be a composition of the corresponding logics and interfaces.</p> <p>\\(App_12 = App_1 \\circ App_2\\):</p> <ol> <li>\\(AppLogic_{12} = AppLogic_1 \\cup AppLogic_2\\)</li> <li>\\(AppWriteInterface_{12} = AppWriteInterface_1 \\cup AppWriteInterface_2\\)</li> <li>\\(AppReadInterface_{12} = AppReadInterface_1 \\cup AppReadInterface_2\\)</li> <li>\\(AppKinds_{12} = AppKinds_1 \\cup AppKinds_2\\)</li> </ol> <p>In this type of composition the order in which the applications are composed doesn't matter.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#application-extension","title":"Application extension","text":"<p>Application extension is a way to generate a new application starting from an existing one by enhancing the application logic and the application interface with operations on more resource kinds. The new application is dependent on the initial one, meaning that the new application logic includes constraints involving the first application resource kinds, and the new interface requires the presence of resources of the first application kinds.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#distributed-application-state-synchronisation","title":"Distributed application state synchronisation","text":"<p>In the controllers report, a controller is defined as a component that orders transactions. The resource machine is designed to work in both single-controller and multi-controller environments, such as Anoma. In the context of multi-controller environments, each resource contains information about its current controller, can only be consumed on its controller, and can be transferred from one controller to another, meaning that a new controller becomes responsible for the correct resource consumption. Transferring a resource can be done by consuming a resource on the old controller and creating a similar resource on the new controller.</p> <p>Applications do not have to exist within the bounds of a single controller, and can maintain a single virtual state while the application resources being distributed among multiple controllers, which forms a distributed application state. To make sure such a distributed state correctly represents the application state, state synchronisation between multiple controllers is required.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/applications.html#controller-state-synchronisation","title":"Controller state synchronisation","text":"<p>Each controller would have their own commitment tree associated with it. Treated as subtrees of a larger Merkle tree, the controller commitment trees comprise a global commitment tree, where the leaves are the roots of the controller trees.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html","title":"Nockma implementation","text":"Juvix imports <pre><code>module arch.system.state.resource_machine.notes.nockma;\nimport prelude open;\nimport Stdlib.Data.Nat open;\nimport Stdlib.Data.List open;\nimport Stdlib.Trait.Show open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#nockma-implementation","title":"Nockma Implementation","text":"Operation Code Name Description 0 Slash (/) Address/path selection 1 Constant Returns operand unchanged 2 Apply/Ap/S Function application 3 Cell test (?) Tests if noun is cell 4 Increment (+) Add 1 to atom 5 Equality test (=) Compare nouns 6 If-then-else Conditional execution 7 Compose Function composition 8 Extend subject Extends the subject 9 Invoke Call function by arm name 10 Pound (#) Handle operation 11 Match Case split on Cells vs Atoms 12 Scry Read storage","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#core-data-types","title":"Core Data Types","text":"<p>The fundamental data structures for Nockma implementation, including the <code>Noun</code> type that represents all data in Nock, along with equality and display instances.</p> <pre><code>-- Basic Nock types\ntype Noun :=\n  | Atom : Nat -&gt; Noun\n  | Cell : Noun -&gt; Noun -&gt; Noun;\n</code></pre> <pre><code>terminating\nnounEq (n1 n2 : Noun) : Bool :=\n  case mkPair n1 n2 of {\n    | mkPair (Noun.Atom x) (Noun.Atom y) := x == y\n    | mkPair (Noun.Cell a b) (Noun.Cell c d) := nounEq a c &amp;&amp; nounEq b d\n    | _ := false\n  };\n\ninstance EqNoun : Eq Noun := Eq.mk@{ isEqual := nounEq };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#pretty-printer-for-noun","title":"Pretty-printer for Noun","text":"<pre><code>terminating\nshowNoun (n : Noun) : String :=\n  case n of {\n    | Noun.Atom a := natToString a\n    | Noun.Cell l r := \"[\" ++str (showNoun l) ++str \" \" ++str (showNoun r) ++str \"]\"\n  };\n\ninstance ShowNoun : Show Noun := Show.mk@{ show := showNoun };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#storage-system-and-operation-types","title":"Storage System and Operation Types","text":"<p>Storage abstraction for scrying operations and the enumeration of all Nock operations with their corresponding opcodes.</p> <pre><code>-- Helper to convert storage values to Nouns\naxiom convertToNoun : {val : Type} -&gt; val -&gt; Noun;\n-- Helper to convert Nouns to storage values\naxiom convertFromNoun : {val : Type} -&gt; Noun -&gt; Option val;\n</code></pre> <pre><code>type ScryOp :=\n  | Direct\n  | Index;\n</code></pre> <pre><code>type Storage addr val := mkStorage {\n  readDirect : addr -&gt; Option val;\n  readIndex : val -&gt; Option val\n};\n\nemptyStorage {addr val : Type} : Storage addr val :=\n  Storage.mkStorage@{\n    readDirect := \\{_ := none};\n    readIndex := \\{_ := none};\n  };\n\naxiom externalStorage : {addr val : Type} -&gt; Storage addr val;\n</code></pre> <pre><code>type NockOp :=\n  | Slash -- /\n  | Constant -- Returns operand unchanged\n  | Apply\n  | CellTest -- ?\n  | Increment -- +\n  | EqualOp -- =\n  | IfThenElse -- 6\n  | Compose -- 7\n  | Extend -- 8\n  | Invoke -- 9\n  | Pound -- #\n  | Match -- 11\n  | Scry; -- 12\n</code></pre> <pre><code>opOr {A : Type} (n m : Option A) : Option A :=\n  case n of {\n    | none := m\n    | (some n) := some n\n  };\n</code></pre> <pre><code>parseOp (n : Nat) : Option NockOp :=\n  let test := \\{m op :=\n    case (n == m) of {\n      | true := some op\n      | false := none\n    }} in\n  foldr opOr none\n    (zipWith test\n      [0; 1; 2; 3; 4; 5; 6; 7; 8; 9; 10; 11; 12]\n      [NockOp.Slash; NockOp.Constant; NockOp.Apply; NockOp.CellTest; NockOp.Increment;\n      NockOp.EqualOp; NockOp.IfThenElse; NockOp.Compose; NockOp.Extend; NockOp.Invoke;\n      NockOp.Pound; NockOp.Match; NockOp.Scry]);\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#gas-state-monad","title":"Gas State Monad","text":"<p>A monadic framework for tracking gas consumption and handling errors during Nock evaluation. This ensures computations can be bounded and failures can be properly handled.</p> <pre><code>-- Monad to encompass gas consumption and error handling.\ntype GasState A := mk {\n  runGasState : Nat -&gt; Result String (Pair A Nat)\n};\n</code></pre> <pre><code>instance\nGasStateMonad : Monad GasState := Monad.mk@{\n  applicative := Applicative.mk@{\n    functor := Functor.mk@{\n      map := \\{f s := GasState.mk \\{gas :=\n        case GasState.runGasState s gas of {\n          | ok (mkPair x remaining) := ok (mkPair (f x) remaining)\n          | error e := error e\n        }}\n    }};\n    pure := \\{x := GasState.mk \\{gas := ok (mkPair x gas)}};\n    ap := \\{sf sa := GasState.mk \\{gas :=\n      case GasState.runGasState sf gas of {\n        | ok (mkPair f remaining) :=\n          case GasState.runGasState sa remaining of {\n            | ok (mkPair x final) := ok (mkPair (f x) final)\n            | error e := error e\n          }\n        | error e := error e\n      }}\n    }\n  };\n  bind := \\{ma f := GasState.mk \\{gas :=\n    case GasState.runGasState ma gas of {\n      | ok (mkPair a remaining) := GasState.runGasState (f a) remaining\n      | error e := error e\n    }}\n  }\n};\n\nerr {A : Type} (str : String) : GasState A := GasState.mk \\{_ := error str};\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#gas-management-and-storage-operations","title":"Gas Management and Storage Operations","text":"<p>Functions for managing computational costs and implementing storage read operations (scrying) that allow Nock programs to interact with external data.</p> <pre><code>-- Gas cost values for each operation type\n-- These are made up for demo purposes\ngetGasCost (cost : NockOp) : Nat :=\n  case cost of {\n    | NockOp.Slash := 1\n    | NockOp.CellTest := 1\n    | NockOp.Increment := 1\n    | NockOp.EqualOp := 2\n    | NockOp.IfThenElse := 3\n    | NockOp.Compose := 2\n    | NockOp.Extend := 2\n    | NockOp.Invoke := 3\n    | NockOp.Pound := 1\n    | NockOp.Scry := 10\n    | _ := 0\n  };\n</code></pre> <pre><code>consume (op : NockOp) : GasState Unit :=\n  GasState.mk \\{gas :=\n  let cost := getGasCost op in\n  case cost &gt; gas of {\n    | true := error \"Out of gas\"\n    | false := ok (mkPair unit (sub gas cost))\n  }};\n</code></pre> <pre><code>-- Implementation of storage read operations (scrying)\nscry {val : Type} (stor : Storage Nat val) (op : ScryOp) (addr : Nat) : Result String Noun :=\n  case op of {\n    | ScryOp.Direct := case Storage.readDirect stor addr of {\n      | some val := ok (convertToNoun val)\n      | none := error \"Direct storage read failed\"\n    }\n    | ScryOp.Index := case Storage.readDirect stor addr of {\n      | some indexFn := case Storage.readIndex stor indexFn of {\n        | some val := ok (convertToNoun val)\n        | none := error \"Index computation failed\"\n      }\n      | none := error \"Index function not found\"\n    }\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#helper-operations","title":"Helper Operations","text":"<p>Implementation of the fundamental slash (<code>/</code>) and pound (<code>#</code>) operations that provide tree navigation and editing capabilities respectively.</p> <pre><code>-- Helper for slash (/) operations\nterminating\nslash {val : Type} (stor : Storage Nat val) (n : Noun) (subject : Noun) : GasState Noun :=\n  case n of {\n    | Noun.Atom x := case x == 1 of {\n      | true := pure subject -- Rule: /[1 a] -&gt; a\n      | false := case x == 2 of {\n        | true := case subject of { -- Rule: /[2 a b] -&gt; a\n          | Noun.Cell a _ := pure a\n          | _ := err (\"Cannot take slash (/2) of atom: \" ++str (showNoun subject))\n        }\n        | false := case x == 3 of {\n          | true := case subject of { -- Rule: /[3 a b] -&gt; b\n            | Noun.Cell _ b := pure b\n            | _ := err (\"Cannot take slash (/3) of atom: \" ++str (showNoun subject))\n          }\n          | false := case (mod x 2) == 0 of {\n            | true :=  -- Rule: /[(a + a) b] -&gt; /[2 /[a b]]\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom (div x 2)) subject &gt;&gt;= \\{res :=\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom 2) res\n                }}}\n            | false := -- Rule: /[(a + a + 1) b] -&gt; /[3 /[a b]]\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom (div x 2)) subject &gt;&gt;= \\{res :=\n                consume NockOp.Slash &gt;&gt;= \\{_ :=\n                slash stor (Noun.Atom 3) res\n                }}}\n          }\n        }\n      }\n    }\n    | _ := err (\"Slash axis must be atom, got: \" ++str (showNoun n))\n  };\n</code></pre> <pre><code>-- Helper for pound (#) operations\nterminating\npound {val : Type} (stor : Storage Nat val) (n : Noun) (b : Noun) (c : Noun) : GasState Noun :=\n  case n of {\n    | Noun.Atom x := case x == 1 of {\n      | true := pure b  -- Rule: #[1 a b] -&gt; a\n      | false := case mod x 2 == 0 of {\n        | true := case c of { -- Rule: #[(a + a) b c] -&gt; #[a [b /[(a + a + 1) c]] c]\n          | Noun.Cell _ _ :=\n            consume NockOp.Slash &gt;&gt;= \\{_ :=\n            slash stor (Noun.Atom ((2 * div x 2) + 1)) c &gt;&gt;= \\{slashResult :=\n            consume NockOp.Pound &gt;&gt;= \\{_ :=\n            pound stor (Noun.Atom (div x 2)) (Noun.Cell b slashResult) c\n            }}}\n          | _ := err (\"Invalid pound target (must be cell): \" ++str (showNoun c))\n        }\n        | false := case c of { -- Rule: #[(a + a + 1) b c] -&gt; #[a [/[(a + a) c] b] c]\n          | Noun.Cell _ _ :=\n            consume NockOp.Slash &gt;&gt;= \\{_ :=\n            slash stor (Noun.Atom (2 * div x 2)) c &gt;&gt;= \\{slashResult :=\n            consume NockOp.Pound &gt;&gt;= \\{_ :=\n            pound stor (Noun.Atom (div x 2)) (Noun.Cell slashResult b) c\n            }}}\n          | _ := err (\"Invalid pound target (must be cell): \" ++str (showNoun c))\n        }\n      }\n    }\n    | _ := err (\"Pound axis must be atom, got: \" ++str (showNoun n))\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#operation-evaluator","title":"Operation Evaluator","text":"<p>The main dispatcher that handles evaluation of each Nock operation according to the Nock specification. Each case implements one of the 13 fundamental Nock operations.</p> <pre><code>terminating\nevalOp\n  {val : Type} (stor : Storage Nat val) (op : NockOp) (a : Noun) (args : Noun) : GasState Noun :=\n  case op of {\n    -- *[a 0 b] -&gt; /[b a]\n    | NockOp.Slash := slash stor args a\n\n    -- *[a 1 b] -&gt; b\n    | NockOp.Constant := pure args\n\n    -- *[a 2 b c] -&gt; *[*[a b] *[a c]]\n    | NockOp.Apply := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r2 :=\n        nock stor (Noun.Cell r1 r2)\n        }}\n      | _ := err (\"Invalid apply (2) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 3 b] -&gt; ?*[a b]\n    -- ?[a b] -&gt; 0\n    -- ?a -&gt; 1\n    | NockOp.CellTest := case args of {\n      | Noun.Cell b _ :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{res :=\n        case res of {\n          | Noun.Cell _ _ := pure (Noun.Atom 0)\n          | _ := pure (Noun.Atom 1)\n        }\n        }\n      | _ := err (\"Invalid cell test (3) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 4 b] -&gt; +*[a b]\n    -- +[a b] -&gt; error (specs say this should loop infinitely?)\n    -- +a -&gt; 1 + a\n    | NockOp.Increment :=\n        -- First, evaluate the argument expression *[subject args]\n        nock stor (Noun.Cell a args) &gt;&gt;= \\{res :=\n          -- Then, check if the result is an atom and increment it\n          case res of {\n            | (Noun.Atom n) := pure (Noun.Atom (suc n))\n            | x := err (\"Increment (4) target must be atom, got: \" ++str (showNoun x))\n          }\n        }\n\n    -- *[a 5 b c] -&gt; =*[a b] *[a c]\n    -- =[a a] -&gt; 0\n    -- =[a b] -&gt; 1\n    | NockOp.EqualOp := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r2 :=\n        pure (Noun.Atom (case nounEq r1 r2 of {\n              | true := 0\n              | false := 1\n            }))\n        }}\n      | _ := err (\"Invalid equality (5) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 6 b c d] -&gt; *[a *[[c d] 0 *[[2 3] 0 *[a 4 4 b]]]]\n    | NockOp.IfThenElse := case args of {\n      | Noun.Cell b (Noun.Cell c d) :=\n        nock stor (Noun.Cell a (Noun.Cell (Noun.Atom 4) (Noun.Cell (Noun.Atom 4) b))) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell (Noun.Cell (Noun.Atom 2) (Noun.Atom 3)) (Noun.Cell (Noun.Atom 0) r1)) &gt;&gt;= \\{r2 :=\n        nock stor (Noun.Cell (Noun.Cell c d) (Noun.Cell (Noun.Atom 0) r2)) &gt;&gt;= \\{r3 :=\n        nock stor (Noun.Cell a r3)\n        }}}\n      | _ := err (\"Invalid if-then-else (6) args (must be [b [c d]]): \" ++str (showNoun args))\n    }\n\n    -- *[a 7 b c] -&gt; *[*[a b] c]\n    | NockOp.Compose := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r :=\n        nock stor (Noun.Cell r c)\n        }\n      | _ := err (\"Invalid compose (7) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 8 b c] -&gt; *[[*[a b] a] c]\n    | NockOp.Extend := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a b) &gt;&gt;= \\{r :=\n        nock stor (Noun.Cell (Noun.Cell r a) c)\n        }\n      | _ := err (\"Invalid extend (8) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 9 b c] -&gt; *[*[a c] 2 [0 1] 0 b]\n    | NockOp.Invoke := case args of {\n      | Noun.Cell b c :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{core :=\n        let formula := Noun.Cell (Noun.Atom 2) (Noun.Cell (Noun.Cell (Noun.Atom 0) (Noun.Atom 1)) (Noun.Cell (Noun.Atom 0) b)) in\n        nock stor (Noun.Cell core formula)\n        }\n      | _ := err (\"Invalid invoke (9) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 10 [b c] d] -&gt; #[b *[a c] *[a d]]\n    | NockOp.Pound := case args of {\n      | Noun.Cell (Noun.Cell b c) d :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a d) &gt;&gt;= \\{r2 :=\n        pound stor b r1 r2\n        }}\n      | _ := err (\"Invalid pound (10) args (must be [[b c] d]): \" ++str (showNoun args))\n    }\n\n    -- *[a 11 [b c] d] -&gt; *[[*[a c] *[a d]] 0 3]\n    -- *[a 11 b c] -&gt; *[a c]\n    | NockOp.Match := case args of {\n      | Noun.Cell (Noun.Cell b c) d :=\n        nock stor (Noun.Cell a c) &gt;&gt;= \\{r1 :=\n        nock stor (Noun.Cell a d) &gt;&gt;= \\{r2 :=\n        nock stor (Noun.Cell (Noun.Cell r1 r2) (Noun.Cell (Noun.Atom 0) (Noun.Atom 3)))\n        }}\n      | Noun.Cell b c := nock stor (Noun.Cell a c) -- Corrected to take 'a' as subject\n      | _ := err (\"Invalid match (11) args (must be cell): \" ++str (showNoun args))\n    }\n\n    -- *[a 12 b c d] -&gt; result &lt;- SCRY b c; *[a result d]\n    | Scry := case args of {\n      | Noun.Cell b (Noun.Cell c d) :=\n          -- First evaluate b to get the opcode\n          nock stor b &gt;&gt;= \\{opcode :=\n            case opcode of {\n              | Noun.Atom opval :=\n                  -- Then evaluate c to get the address\n                  nock stor c &gt;&gt;= \\{addr :=\n                    case addr of {\n                      | Noun.Atom addrVal :=\n                          -- Convert opcode to ScryOp\n                          let scryType := case opval == 0 of {\n                            | true := ScryOp.Direct\n                            | false := ScryOp.Index\n                          } in\n                          -- Perform the scry operation and wrap result in GasState\n                          GasState.mk \\{gas :=\n                            scry stor scryType addrVal &gt;&gt;= \\{scryResult :=\n                            -- Continue evaluation with the scry result\n                            GasState.runGasState (nock stor (Noun.Cell a (Noun.Cell scryResult d))) gas\n                            }\n                          }\n                      | _ := err (\"Scry address must be atom, got: \" ++str (showNoun addr))\n                    }\n                  }\n              | _ := err (\"Scry type must be atom, got: \" ++str (showNoun opcode))\n            }\n          }\n      | _ := err (\"Invalid scry (12) args (must be [b [c d]]): \" ++str (showNoun args))\n    }\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma.html#core-nockma-evaluator","title":"Core Nockma Evaluator","text":"<p>The main entry point for Nock evaluation. This function handles the parsing of Nock expressions and dispatches to the appropriate operation evaluators.</p> <pre><code>-- Core Nockma evaluator\nterminating\nnock {val : Type} (stor : Storage Nat val) (input : Noun) : GasState Noun :=\n  case input of {\n    -- Rule: *a -&gt; *a\n    | Noun.Atom n := err (\"Cannot evaluate atom as program: \" ++str (showNoun (Noun.Atom n)))\n\n    | Noun.Cell a b := case b of {\n\n      | Noun.Cell first rest := case first of {\n        -- Rule: *[a [b c] d] -&gt; [*[a b c] *[a d]]\n        | Noun.Cell b c :=\n          nock stor (Noun.Cell a (Noun.Cell b c)) &gt;&gt;= \\{r1 :=\n          nock stor (Noun.Cell a rest) &gt;&gt;= \\{r2 :=\n          pure (Noun.Cell r1 r2)\n          }}\n\n        | Noun.Atom n := case parseOp n of {\n          | some opcode := consume opcode &gt;&gt;= \\{_ :=\n              evalOp stor opcode a rest -- Evaluate [subject rest] with opcode n\n            }\n          | none := err (\"Invalid operation code: \" ++str (natToString n) ++str \" in formula: \" ++str (showNoun b))\n        }\n      }\n      -- Rule: *[a b] where b is an atom is an error\n      | Noun.Atom bn := err (\"Formula cannot be an atom: \" ++str (showNoun (Noun.Atom bn)) ++str \" in input: \" ++str (showNoun input))\n    }\n  };\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html","title":"Nockma runnable","text":"Juvix imports <pre><code>module arch.system.state.resource_machine.notes.nockma_runnable;\nimport prelude open;\nimport arch.system.state.resource_machine.notes.nockma open;\nimport arch.system.state.resource_machine.notes.runnable open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html#nockma-runnable-implementation","title":"Nockma Runnable Implementation","text":"<p>This module implements the <code>Runnable</code> trait for Nockma, allowing it to be used as an executor in the Anoma system.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html#types","title":"Types","text":"<pre><code>-- The program state for Nockma is just the current Noun being evaluated\ntype NockmaProgramState := mk {\n  current_noun : Noun;\n  storage : Storage Nat Noun;\n  gas_limit : Nat;\n};\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/nockma_runnable.html#runnable-instance","title":"Runnable Instance","text":"<pre><code>instance nockmaRunnable : Runnable Nat Nat Noun NockmaProgramState :=\n  Runnable.mkRunnable@{\n    -- Execute one step of Nockma evaluation\n    executeStep := \\{executable state input :=\n      let\n        -- Convert input key-value pair to a Noun for evaluation\n        -- The input value is already a Noun since KVSDatum is Nat\n        input_noun := Noun.Cell (Noun.Atom (fst input)) (Noun.Atom (snd input));\n        -- Construct the Nock subject: [state [key val]]\n        subject := Noun.Cell (NockmaProgramState.current_noun state) input_noun;\n        -- Construct the full input for Nock evaluation: [subject formula]\n        full_input := Noun.Cell subject executable;\n        -- Run Nockma evaluation with current gas limit\n        result := GasState.runGasState (nock (NockmaProgramState.storage state) full_input) (NockmaProgramState.gas_limit state);\n      in case result of {\n        | error err := error err\n        | ok (mkPair result_noun remaining_gas) :=\n          -- Parse the result noun which should be of the form (Noun.Atom new_state output_requests)\n          -- where output_requests is a list encoded as (Noun.Atom req1 (Noun.Atom req2 (Noun.Atom ... (Noun.Atom last_req 0))))\n          -- A request is either:\n          -- - (Noun.Atom key value) for write requests\n          -- - (Noun.Atom key) for read requests\n          case result_noun of {\n            | Noun.Cell (Noun.Atom new_state) requests :=\n              let\n                -- Helper to parse a single request\n                parseRequest (req : Noun) : Option (Either Nat (Pair Nat Nat)) :=\n                  case req of {\n                    | Noun.Atom key := some (left key)  -- Read request\n                    | Noun.Cell (Noun.Atom key) (Noun.Atom value) := some (right (mkPair key value))  -- Write request\n                    | _ := none  -- Invalid request format, ignore it\n                  };\n                -- Helper to parse the linked list of requests\n                terminating\n                parseRequests (reqs : Noun) : List (Either Nat (Pair Nat Nat)) :=\n                  case reqs of {\n                    | Noun.Atom zero := nil  -- End of list\n                    | Noun.Cell (Noun.Atom req) rest :=\n                      case parseRequest (Noun.Atom req) of {\n                        | none := parseRequests rest\n                        | some parsed := parsed :: parseRequests rest\n                      }\n                    | _ := nil  -- Invalid request list format, return empty list\n                  };\n                -- Parse all requests\n                parsed_requests := parseRequests requests;\n                -- Update program state with new state and remaining gas\n                new_state := state@NockmaProgramState{\n                  current_noun := Noun.Atom new_state;\n                  gas_limit := remaining_gas\n                };\n              in ok (mkPair new_state parsed_requests)\n            | _ := error \"Invalid result format\"\n          }\n      }\n    };\n\n    -- Check if program has halted (out of gas or reached final value)\n    halted := \\{state :=\n      -- Program halts if out of gas or reaches specific state value\n      NockmaProgramState.gas_limit state == zero ||\n      case NockmaProgramState.current_noun state of {\n        | Noun.Atom n := n == 1702390132\n        | _ := false\n      }\n    };\n\n    -- Initial program state\n    startingState := NockmaProgramState.mk@{\n      current_noun := Noun.Atom zero;  -- Start with empty noun\n      storage := emptyStorage;  -- Use external storage\n      gas_limit := 1000  -- Start with 1000 gas units\n    }\n  };\n</code></pre> <p>This implementation:</p> <ol> <li> <p>Defines a <code>NockmaProgramState</code> type that tracks:</p> <ul> <li>The current Noun being evaluated</li> <li>The storage interface for reading/writing Nouns</li> <li>The remaining gas limit</li> </ul> </li> <li> <p>Implements <code>executeStep</code> to:</p> <ul> <li>Convert input key-value pair to a Noun (using direct Noun.Atom construction since KVSDatum is Nat)</li> <li>Construct the Nock subject: [state [key val]]</li> <li>Construct the full input for Nock evaluation: [subject formula]</li> <li>Run one step of Nockma evaluation</li> <li>Parse the result which should be of the form (Noun.Atom new_state output_requests)</li> <li>Parse the output_requests which is a linked list of requests</li> <li>Each request is either:<ul> <li>(Noun.Atom key) for read requests</li> <li>(Noun.Atom key value) for write requests</li> </ul> </li> <li>Update program state with new state and remaining gas</li> <li>Return new state and parsed requests</li> </ul> </li> <li> <p>Implements <code>halted</code> to check if program has run out of gas or is in designated halting state</p> </li> <li> <p>Provides <code>startingState</code> with initial values</p> </li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html","title":"Roles and requirements","text":"<pre><code>module arch.system.state.resource_machine.notes.roles_and_requirements;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html#roles-and-requirements","title":"Roles and requirements","text":"<p>The table below contains a list of resource-related roles. In the Anoma protocol, the role of the resource creator will often be taken by a solver, which creates additional security requirements compared to the case when protocol users solve their own intents. Because of that, extra measures are required to ensure reliable distribution of the information about the created resource to the resource receiver.</p> Role Description Authorizer approves the resource consumption on the application level. The resource logic encodes the mechanism that connects the authorizer's external identity (public key) to the decision-making process Annuler knows the data required to nullify a resource Creator creates the resource and shares the data with the receiver Owner can both authorize and annul a resource Sender owns the resources that were consumed to create the created resource Receiver owns the created resource","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html#reliable-resource-object-distribution","title":"Reliable resource object distribution","text":"<p>In the case of in-band distribution of created resources in contexts with higher security requirements, the resource creator is responsible for encrypting the resource object. Verifiable encryption must be used to ensure the correctness of the encrypted data: the encrypted object must be proven to correspond to the resource object, which is passed as a private input.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/roles_and_requirements.html#reliable-nullifier-key-distribution","title":"Reliable nullifier key distribution","text":"<p>Knowing the resource\u2019s nullifier reveals information about when the resource is consumed, as the nullifier will be published when it happens, which might be undesirable in the contexts with higher security requirements. For that reason, it is advised to keep the number of parties who can compute the resource\u2019s nullifier as low as possible in such contexts.</p> <p>In particular, the resource creator should not be able to compute the resource nullifier, and as the nullifier key allows to compute the resource's nullifier, it shouldn't be known to the resource creator. At the same time, the resource object must contain some information about the nullifier key. One way to fulfil both requirements is, instead of sharing the nullifier key itself with the resource creator, to share some parameter derived from the nullifier key, but that does not allow computing the nullifier key or any meaningful information about it. This parameter is called a nullifier key commitment and is computed as \\(cnk = h_{cnk}(nk)\\).</p> <p>These concerns are not meaningful in the contexts with lower security requirements.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/runnable.html","title":"Runnable trait","text":"<p>icon: octicons/container-24 search:   exclude: false tags:   - resource-machine</p> Juvix imports <pre><code>module arch.system.state.resource_machine.notes.runnable;\nimport prelude open;\n</code></pre> <pre><code>trait\ntype Runnable KVSKey KVSDatum Executable ProgramState :=\n  mkRunnable@{\n    executeStep : Executable -&gt; ProgramState -&gt; Pair KVSKey KVSDatum -&gt; Result String (Pair ProgramState (List (Either KVSKey (Pair KVSKey KVSDatum))));\n    halted : ProgramState -&gt; Bool;\n    startingState : ProgramState;\n  };\n</code></pre> <code>executeStep</code>: Takes the executable code, current program state, and read key-value pair and returns either:   - Error string on failure   - New program state and list of either:     - Left key for read requests     - Right (key, value) for write requests"},{"location":"arch/system/state/resource_machine/notes/storage.html","title":"Stored data format","text":"<pre><code>module arch.system.state.resource_machine.notes.storage;\n</code></pre> <p>Warning</p> <p>Will be updated soon</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#stored-data-format","title":"Stored data format","text":"<p>The ARM state that needs to be stored includes resource objects, the commitment accumulator and the nullifier set. The table below defines the format of that data assumed by the ARM.</p> Name Structure Key Type Value Type Commitment accumulator (node) Cryptographic accumulator timestamp \\(\\mathbb{F}\\) Commitment accumulator (leaf) - (<code>timestamp</code>, \\(\\mathbb{F}\\)) \\(\\mathbb{F}\\) Nullifier set Set \\(\\mathbb{F}\\) \\(\\mathbb{F}\\) Hierarchical index Chained Hash sets Tree path \\(\\mathbb{F}\\) Data blob storage Key-value store with deletion criterion \\(\\mathbb{F}\\) (<code>variable length byte array</code>, <code>deletion criterion</code>)","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#cmtree","title":"\\(CMtree\\)","text":"<p>Each commitment tree node has a timestamp associated with it, such that a lower depth (closer to the root) tree node corresponds to a less specified timestamp: a parent node timestamp is a prefix of the child node timestamp, and only the leaves of the tree have fully specified timestamps (i.e. they are only prefixes of themselves). For a commitment tree of depth \\(d\\), a timestamp for a commitment \\(cm\\) would look like \\(t_{cm} =t_1:t_2:..:t_d\\), with the parent node corresponding to it having a timestamp \\(t_1:t_2:..:*\\). The timestamps are used as keys for the key-value store. For the tree leaves, \\(&lt;cm, t_{cm}&gt;\\) pairs are used as keys. Merkle paths to resource commitments can be computed from the hierarchy of the timestamps.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#nfset","title":"\\(NFset\\)","text":"<p>Nullifiers are used as keys in the key-value store. In future versions, a more complex structure that supports efficient non-membership proofs might be used for storing the nullifier set.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#hierarchical-index","title":"Hierarchical index","text":"<p>The hierarchical index is organised as a tree where the leaves refer to the resources, and the intermediate nodes refer to resource subkinds that form a hierarchy. The label of a resource \\(r\\) stored in the hierarchical index tree is interpreted as an array of sublabels: \\(r.label = [label_1, label_2, label_3, ...]\\), and the i-th subkind is computed as \\(r.subkind_i = H_{kind}(r.l, r.label_i)\\).</p> <p>In the current version, only the subkinds derived from the same resource logic can be organized in the same hierarchical index path.</p> <p>The interface of the tree enables efficient querying of all children of a specific path and verifying that the returned children are the requested nodes. Permissions to add data to the hierarchical index are enforced by the resource logics and do not require additional checks.</p>","boost":2},{"location":"arch/system/state/resource_machine/notes/storage.html#data-blob-storage","title":"Data blob storage","text":"<p>Data blob storage stores data without preserving any specific structure. The data is represented as a variable length byte array and comes with a deletion criterion that determines for how long the data will be stored. The deletion criterion, in principle, is an arbitrary predicate, which in practice currently is assumed to be instantiated by one of the following options:</p> <ol> <li>delete immediately</li> <li>delete after \\(block\\)</li> <li>delete after \\(timestamp\\)</li> <li>delete after \\(sig\\) over \\(data\\)</li> <li>delete after either predicate \\(p_1\\) or \\(p_2\\) is true; the predicates are instantiated by options from this list</li> <li>store forever</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/notes/function_formats/transaction_function_format.html","title":"Transaction function format","text":"<pre><code>module arch.system.state.resource_machine.notes.function_formats.transaction_function_format;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/notes/function_formats/transaction_function_format.html#transaction-function-format","title":"Transaction function format","text":"<p>The system used to represent and interpret transaction functions must have a deterministic computation model; each operation should have a fixed cost of space and time (for total cost computation). To support content addressing, it must have memory and support memory operations (specifically <code>read</code>, <code>write</code>, <code>allocate</code>).</p> <p>The system must support the following I/O operations:</p> <ol> <li><code>readStorage</code>(<code>address</code>: <code>Commitment</code>): read the global content-addressed storage at the specified address and return the value stored at the address. If the value is not found, the operation should return an error. Storage not accessible to the machine should be treated as non-existent.</li> <li><code>dataByIndex</code>(<code>indexFunction)</code>: read data from the storage (either resources or arbitrary data kept in the storage requested by the transaction function) at the execution time by the specified index function. If the index function output is invalid or uncomputable, or the data cannot be located, the operation should return an error. Typically, the index functions allowed will be very restricted, e.g. an index function returning current unspent resources of a particular kind.</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/notes/function_formats/transaction_function_format.html#gas-model","title":"Gas model","text":"<p>To compute and bound the total cost of computation, the transaction function system must support a gas model. Each evaluation would have a gas limit \\(g_{limit}\\), and the evaluation would start with \\(g_{count} = 0\\). Evaluating an operation, the system would add the cost of the operation to the counter \\(g_{count}\\) and compare it to \\(g_{limit}\\). When making recursive calls, \\(g_{count}\\) is incremented before the recursion occurs. If the value of \\(g_{count}\\) is greater than \\(g_{limit}\\), the execution is terminated with an error message indicating that the gas limit has been surpassed.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html","title":"Commitment accumulator","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.commitment_accumulator;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#commitment-accumulator","title":"Commitment accumulator","text":"<p>All resource commitments are stored in an append-only data structure called a commitment accumulator. Every time a resource is created, its commitment is added to the commitment accumulator. The resource commitment accumulator is external to the resource machine, but the resource machine can read from it. A commitment accumulator is a cryptographic accumulator that allows to prove membership for elements accumulated in it, provided a witness and the accumulated value.</p> <p>Each time a commitment is added to the accumulator, the accumulator and all witnesses of the already accumulated commitments are updated. For a commitment that existed in the accumulator before a new one was added, both the old witness and the new witness (with the corresponding accumulated value parameter) can be used to prove membership. However, the older the witness (and, consequently, the accumulator) that is used in the proof, the more information about the resource it reveals (an older accumulator gives more concrete boundaries on the resource's creation time). For that reason, it is recommended to use fresher parameters when proving membership.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#accumulator-functionality","title":"Accumulator functionality","text":"<p>Note</p> <p>The witness we are talking about here is not related to proving system witness. It is a distinct concept of cryptographic accumulators.</p> <p>The commitment accumulator has type <code>Accumulator</code> and is parametrised over the types <code>AccumulatorWitness</code>,<code>CommitmentIdentifier</code>, and <code>AccumulatedValue</code>. The commitment accumulator interface must support the following functionality:</p> <ol> <li><code>add(Accumulator, CommitmentIdentifier) -&gt; AccumulatorWitness</code> adds an element to the accumulator, returning the accumulator witness used to prove membership.</li> <li><code>witness(Accumulator, CommitmentIdentifier) -&gt; Maybe AccumulatorWitness</code> for a given element, returns the accumulator witness used to prove membership if the element is present, otherwise returns nothing.</li> <li><code>verify(CommitmentIdentifier, AccumulatorWitness, AccumulatedValue) -&gt; Bool</code> verifies the membership proof for a commitment identified with <code>CommitmentIdentifier</code> element with a membership witness <code>AccumulatorWitness</code> for the accumulated value <code>AccumulatedValue</code>.</li> <li><code>value(Accumulator) -&gt; AccumulatedValue</code> returns the accumulator value.</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#merkle-tree","title":"Merkle tree","text":"<p>Currently, the commitment accumulator is assumed to be a Merkle tree <code>CMTree</code> of depth \\(depth_{CMtree}\\), where the leaves contain the resource commitments and the intermediate nodes' values are of type <code>MerkleTreeNodeHash</code>.</p> <p>Note</p> <p>The type <code>MerkleTreeNodeHash</code> of the <code>CMTree</code> nodes and the type of the leafs <code>Commitment</code> are distinct types.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/commitment_accumulator.html#interface","title":"Interface","text":"<p>For a Merkle tree:</p> <ol> <li><code>CommitmentIdentifier</code> type corresponds to the identifier of the resource commitment used to locate the commitment's position in the tree</li> <li><code>AccumulatorWitness</code> element is a path to the stored commitment</li> <li><code>AccumulatedValue</code> corresponds to the Merkle tree root</li> </ol> <p>and the functions:</p> <ol> <li><code>add</code> adds the resource commitment to the tree, returning the path to the commitment</li> <li><code>witness</code> finds the resource commitment in the tree and returns the path to it</li> <li><code>verify</code> uses the resource commitment and the path to reconstruct the root. Returns <code>True</code> if the constructed value is equal to the provided value</li> <li><code>value</code> returns the tree root</li> </ol> <p>Todo</p> <p>shielded notes: To support the systems with stronger privacy requirements, the witness for such a proof must be a private input when proving membership.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.index;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/index.html#primitive-interfaces","title":"Primitive interfaces","text":"<p>This section defines the hierarchy of primitives used in resource machine design and describes interfaces for each primitive.</p> <p>The diagram below illustrates the primitive types required for resource machine. Red nodes correspond to primitive interfaces, green nodes correspond to instantiations of the interfaces. Each primitive instantiation has an associated type, e.g. delta hash instantiation of <code>Hash</code> interface has an associated type <code>DeltaHash</code>. Primitive instantiations' names are derived from the type name but written in lower camel case, e.g., for <code>DeltaHash</code> the corresponding function would be <code>deltaHash(..)</code>.</p> <pre><code>flowchart LR\n    ProvingSystem\n    Map --&gt; MapInstance\n    CommitmentAccumulator --&gt; CommitmentAccumulatorInstance\n    NullifierSet --&gt; NullifierSetInstance\n\n    List --&gt; ListInstance\n    Set --&gt; SetInstance\n\n    style SetInstance fill:transparent\n    style ListInstance fill:transparent\n    style MapInstance fill:transparent\n    style CommitmentAccumulatorInstance fill:transparent\n    style NullifierSetInstance fill:transparent\n\n\n    ProvingSystem --&gt; ComplianceProvingSystem\n    ProvingSystem --&gt; ResourceLogicProvingSystem\n    ProvingSystem --&gt; IDeltaProvingSystem\n    IDeltaProvingSystem --&gt; DeltaProvingSystem\n    style ComplianceProvingSystem fill:transparent\n    style ResourceLogicProvingSystem fill:transparent\n    style DeltaProvingSystem fill:transparent</code></pre> Primitive interfaces <pre><code>flowchart LR\n\n    FixedSize --&gt; Arithmetic\n    FixedSize --&gt; Hash\n\n\n    FixedSize --&gt; Nonce\n    FixedSize --&gt; RandSeed\n    FixedSize --&gt; NullifierKeyCommitment\n    FixedSize --&gt; NullifierKey\n\n    style Nonce fill:transparent\n    style RandSeed fill:transparent\n    style NullifierKey fill:transparent\n    style NullifierKeyCommitment fill:transparent\n\n\n    Arithmetic --&gt; Quantity\n    Arithmetic --&gt; Balance\n\n    Arithmetic --&gt; DeltaHash\n\n    style Quantity fill:transparent\n    style Balance fill:transparent\n    style DeltaHash fill:transparent\n\n\n    Hash --&gt; PS\\.VerifyingKey\n    Hash --&gt; LabelHash\n    Hash --&gt; ValueHash\n    Hash --&gt; DeltaHash\n\n    Hash --&gt; Commitment\n    Hash --&gt; Nullifier\n    Hash --&gt; Kind\n    Hash --&gt; LogicVKOuterHash\n    Hash --&gt; MerkleTreeNodeHash\n\n    style LogicVKCompact fill:transparent\n    style LabelHash fill:transparent\n    style ValueHash fill:transparent\n    style DeltaHash fill:transparent\n    style Commitment fill:transparent\n    style Nullifier fill:transparent\n    style Kind fill:transparent\n    style LogicVKOuterHash fill:transparent\n    style MerkleTreeNodeHash fill:transparent\n\n\n    Hash --&gt; AppDataValueHash\n    style AppDataValueHash fill:transparent</code></pre> Primitive types","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/list.html","title":"List","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.ordered_set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/list.html#list","title":"List","text":"<ol> <li><code>new() -&gt; List</code> - creates an empty list</li> <li><code>size(Set) -&gt; Nat</code> - returns the number of elements in the list</li> <li><code>elem(List, Nat) -&gt; Maybe T</code> - returns an element from the list at the given position</li> <li><code>append(List, T) -&gt; List</code> - appends an element to the list</li> <li><code>delete(List, Nat) -&gt; List</code> - removes an element at the given position from the list</li> <li><code>contains(List, T) -&gt; Bool</code> - checks if an element is in the list</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/list.html#used-in","title":"Used in","text":"<ol> <li>Action</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html","title":"Map","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.map;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html#map","title":"Map","text":"<p>Map is a structure that contains pairs (key: value), where key is of type <code>K</code> and value is of type <code>V</code>.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html#interface","title":"Interface","text":"<ol> <li><code>new() -&gt; Map</code></li> <li><code>add(Map, K, V) -&gt; Map</code></li> <li><code>size(Map) -&gt; Nat</code></li> <li><code>get(Map, K) -&gt; V</code></li> <li><code>keys(Map) -&gt; List K</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/map.html#used-in","title":"Used in","text":"<ol> <li>Action</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/nullifier_set.html","title":"Nullifier set","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.nullifier_set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/nullifier_set.html#nullifier-set","title":"Nullifier set","text":"<p>The nullifier set interface requires two main operations:</p> <ol> <li><code>insert(NFSet, T) -&gt; NFSet</code> - adds the nullifier of type T to the nullifier set.</li> <li><code>contains(NFSet, T) -&gt; Bool</code> - searchers for the given element and returns <code>True</code> if the element was found.</li> </ol> <p>At this point, this interface seems to be fully covered by the set interface.</p> <p>Note</p> <p>For the future versions of the nullifier set:</p> <pre><code>1.`Contains` should perform the check in O(1)\n2. The data structure should support proofs of non-existence\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/ordered_set.html","title":"Ordered set","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.ordered_set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/ordered_set.html#ordered-set","title":"Ordered set","text":"<p>Ordered set is a set that preserves order</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/ordered_set.html#used-in","title":"Used in","text":"<ol> <li>Action (commitments, nullifiers)</li> <li>Compliance unit</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html","title":"Set interface","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.set;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html#set-primitive-interface","title":"Set primitive interface","text":"<p>A set is an unordered data structure that contains only distinct elements.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html#the-interface","title":"The interface","text":"<p>For a set parametrised over the element type <code>T</code>:</p> <ol> <li><code>new() -&gt; Set</code> - creates an empty set.</li> <li><code>new(List) -&gt; Set</code> - creates a set from the given list of elements. If the list contains duplicating elements, ignores them.</li> <li><code>size(Set) -&gt; Nat</code> - returns the number of elements in the set.</li> <li><code>insert(Set, T) -&gt; Set</code> - adds an element of type <code>T</code> to the set.</li> <li><code>union(Set, Set) -&gt; Set</code> - computes the union of two sets.</li> <li><code>intersection(Set, Set) -&gt; Set</code> - computes the intersection of two sets.</li> <li><code>difference(Set, Set) -&gt; Set</code> - computes the difference of two sets. Note that this operation is not commutative.</li> <li><code>disjointUnion(Set, Set) -&gt; Set</code> - computes the union of two sets. If the sets intersect, returns an error.</li> <li><code>contains(Set, T) -&gt; Bool</code> - checks if an element is in the set.</li> </ol> <pre><code>\nclassDiagram\n\n    class ISet~T~ {\n         &lt;&lt;Interface&gt;&gt;\n         new() Set\n         new(List) Set\n         size(Set) Nat\n         insert(Set, T) Set\n         union(Set, Set) Set\n         intersection(Set, Set) Set\n         difference(Set, Set) Set\n         disjointUnion(Set, Set) Set\n         contains(Set, T) Bool\n    }\n\n    class IList~T~ {\n         &lt;&lt;Interface&gt;&gt;\n    }\n\n    ISet &lt;|-- IList\n\n    ISet &lt;-- Set\n\n    IList &lt;-- List\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/set.html#used-in","title":"Used in","text":"<ol> <li>Transaction</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/transaction_function_vm.html","title":"Transaction function vm","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.transaction_function_vm;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/transaction_function_vm.html#transaction-function-vm","title":"Transaction function VM","text":"<p>Transaction function VM is used to interpret transaction functions.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/transaction_function_vm.html#interface","title":"Interface","text":"<ul> <li><code>eval(TransactionFunction, GasLimit) -&gt; Transaction</code></li> </ul> <p>Examples: - nock (transparent-only; transaction function) - (?) cairo, risc0 (circuits)</p> <p>Todo</p> <p>are nock and cairo/risc0 on the same level? What exactly transaction functions look like in cairo/risk0 case? What about the relationship with proving systems?</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/arithmetic.html","title":"Arithmetic","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.arithmetic;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/arithmetic.html#arithmetic","title":"Arithmetic","text":"<p>Arithmetic fixed size type is a type of fixed size that additionally supports addition and subtraction.</p> <pre><code>\nclassDiagram\n    class FixedSize~T, Arg~ {\n         &lt;&lt;Interface&gt;&gt;\n         +bit_size: Int\n         +new(Arg) T\n         +equal(T, T) Bool\n    }\n\n    FixedSize &lt;|-- Arithmetic\n\n    class Arithmetic~T, Arg~ {\n        &lt;&lt;Interface&gt;&gt;\n        +add(T, T) T\n        +sub(T, T) T\n    }\n\n    Arithmetic &lt;|-- Quantity\n    Arithmetic &lt;|-- Balance\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/arithmetic.html#used-in","title":"Used in","text":"<ol> <li>Resource component: <code>quantity</code></li> <li><code>DeltaHash</code></li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/delta_hash.html","title":"Delta hash","text":"<pre><code>module\narch.system.state.resource_machine.primitive_interfaces.fixed_size_type.delta_hash;\n\nimport prelude open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/delta_hash.html#delta-hash","title":"Delta hash","text":"<p>Delta hash is an interface that implements both <code>Hash</code> type and <code>Arithmetic</code> type. It is also required to be additively homomorphic and kind-distinct:</p> <ol> <li>For resources of the same kind \\(kind\\), \\(h_{\\Delta}\\) should be additively homomorphic: \\(\\Delta_1 + \\Delta_2 = h_{\\Delta}(kind, q_1) + h_{\\Delta}(kind, q_2) = h_{\\Delta}(kind, q_1 + q_2)\\)</li> </ol> <pre><code>--- A trait describing additive homomorphicity.\ntrait\ntype AdditivelyHomomorphic T :=\n  mkAdditivelyHomomorphic@{\n    --- Adds two types implementing the ;AdditivelyHomomorphic; trait.\n    add : (v1 v2 : T) -&gt; T;\n  };\n</code></pre> <pre><code>--- Implements the trait ;Eq; for ;AdditivelyHomomorphic; types.\nProperty-AdditivelyHomomorphic\n  {T} {{Eq T}} {{AdditivelyHomomorphic T}} (f : T -&gt; T) (v1 v2 : T) : Bool :=\n  f (AdditivelyHomomorphic.add v1 v2)\n    == AdditivelyHomomorphic.add (f v1) (f v2);\n</code></pre> <ol> <li>For resources of different kinds, \\(h_\\Delta\\) has to be computationally kind-distinct: if there exists \\(kind\\) and \\(q\\) s.t. \\(h_\\Delta(kind_1, q_1) + h_\\Delta(kind_2, q_2) = h_\\Delta(kind, q)\\), it is computationally infeasible to compute \\(kind\\) and \\(q\\).</li> </ol> <pre><code>--- A trait describing kind distinctness.\ntrait\ntype KindDistinct T :=\n  mkKindDistinct@{\n    --- Adds two types implementing the ;KindDistinct; trait.\n    add : (v1 v2 : T) -&gt; T;\n  };\n</code></pre> <p>Note</p> <p>An example of a function that satisfies these properties is the Pedersen commitment scheme: it is additively homomorphic, and its kind-distinctness property comes from the discrete logarithm assumption.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/delta_hash.html#used-in","title":"Used in","text":"<ol> <li>Resource delta</li> <li>Compliance unit delta</li> <li>Action delta</li> <li>Transaction delta</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html","title":"Interface","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.fixed_size_type;\nimport prelude open;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html#fixed-size-type","title":"Fixed Size Type","text":"<pre><code>type FixedSize T :=\n  mkFixedSize@{\n    -- bit_size : Nat;\n    -- new : Arg -&gt; T;\n    -- equal : (T, T) Bool;\n  };\n</code></pre> <p>Fixed size type is a type, as the name suggests, of a fixed size. An example of such a type could be a prime field, unit32, or a string of a fixed size. An example of a type of not fixed size would be a list. All resource components and computable components are elements of a fixed size type. <p>The two child interfaces are arithmetic fixed size type - the fixed size type that supports addition and subtraction, and hash - the fixed size type for which the type derivation function <code>new(Arg)</code> is binding.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html#fixed-size-type-hierarchy-diagram","title":"Fixed size type hierarchy diagram","text":"<pre><code>\nclassDiagram\n    class FixedSize~T, Arg~ {\n         &lt;&lt;Interface&gt;&gt;\n         +bit_size: Int\n         +new(Arg) T\n         +equal(T, T) Bool\n    }\n\n    FixedSize &lt;|-- Nonce\n    FixedSize &lt;|-- RandSeed\n    FixedSize &lt;|-- NullifierKeyCommitment\n    FixedSize &lt;|-- NullifierKey\n\n    FixedSize &lt;|-- Arithmetic\n    FixedSize &lt;|-- Hash\n\n\n    note for Hash \"fixed size types that are binding (to Arg) and collision resistant\"\n    class Hash~T, Arg~ {\n        &lt;&lt;Interface&gt;&gt;\n    }\n\n    class Arithmetic~T, Arg~ {\n        &lt;&lt;Interface&gt;&gt;\n        +add(T, T) T\n        +sub(T, T) T\n    }\n\n    Hash &lt;|-- DeltaHash\n    Arithmetic &lt;|-- DeltaHash\n\n    note for DeltaHash \"additively homomorphic and kind-distnict\"\n    class DeltaHash {\n        &lt;&lt;Interface&gt;&gt;\n    }\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/fixed_size_type.html#used-in-raw","title":"Used in (raw)","text":"<ol> <li> <p>Resource components:</p> <ol> <li><code>randSeed</code></li> <li><code>nonce</code></li> <li><code>nullifierKeyCommitment</code></li> </ol> </li> <li> <p><code>nullifierKey</code></p> </li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html","title":"Hash","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.fixed_size_type.hash;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html#hash","title":"Hash","text":"<p>Hash type is defined as a fixed size type that is binding, meaning that if the input value of type <code>Arg</code> changed, the output value would change as well.</p> <p>In the context of hashes, we say <code>a</code> is an opening of a hash <code>h: Hash</code> if <code>h = hash(a)</code>.</p> <p>Todo</p> <ol> <li>for shielded: cryptographic hash, hiding</li> <li>do we want a separate interface for the logic hash, given it is a verifier key? UPD in Taiga we had the verifier key hashed. Is it fixed size? If not, what was the reason for tripple hashing? vk + hash + function privacy commitment</li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html#hash-interface-diagram","title":"Hash interface diagram","text":"<pre><code>\nclassDiagram\n\n    class Hash~T, Arg~ {\n         &lt;&lt;Interface&gt;&gt;\n    }\n\n    Hash &lt;|-- LogicVKCompact\n    Hash &lt;|-- LabelHash\n    Hash &lt;|-- ValueHash\n\n    Hash &lt;|-- Commitment\n    Hash &lt;|-- Nullifier\n    Hash &lt;|-- Kind\n    Hash &lt;|-- DeltaHash\n    Hash &lt;|-- LogicVKOuterHash\n    Hash &lt;|-- MerkleTreeNodeHash\n\n    Hash &lt;|-- AppDataValueHash\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/fixed_size_type/hash.html#used-in","title":"Used in","text":"<ol> <li> <p>Resource components:</p> <ol> <li><code>logicRef</code></li> <li><code>labelRef</code></li> <li><code>valueRef</code></li> </ol> </li> <li> <p>Resource computable components:</p> <ol> <li><code>commitment</code></li> <li><code>nullifier</code></li> <li><code>kind</code></li> <li><code>delta</code></li> </ol> </li> <li> <p>Computing Merkle tree nodes and roots</p> </li> </ol>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html","title":"Index","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#proving-system","title":"Proving system","text":"<p>Todo</p> <p>add efficiency expectations (what to prioritise)</p> <p>The resource machine differentiates between three kinds of proofs, each of which can have a distinct proving system used to produce that sort of proofs:</p> <ol> <li>resource logic proofs</li> <li>compliance proofs</li> <li>delta proofs</li> </ol> Execution context Constraints defined by Are the constraints public by default? Meaning Resource logic proof Action Application No Action is compliant with the application constraints Compliance proof Compliance unit RM instance Yes Action (partitioned into compliance units) is compliant with the RM rules Delta proof Transaction RM interface Yes Transaction is balanced <p>Every proof has three types of inputs and constraints:</p> <ol> <li>Architecture-level inputs and constraints. This type of inputs and constraints allow to enforce certain resource machine properties and have to be present in each resource logic, no matter in the context of which instantiation and application the resource logic was produced. These contraints ensure basic resource machine properties.</li> <li>Instantiation-level inputs and constraints. These inputs and constraints must be present in every resource logic compatible with a concrete resource machine instantiation but might not be required by other instantiations. These constraints ensure additional resource machine properties desired by the instantiation.</li> <li>Application-level (custom) inputs and constraints that are present in every resource logic specified by a concrete application. These constraints define how the application works.</li> </ol> <p>This specification explicitly defines only the architecture-level inputs and constraints. Only application-level constraints are referred to as custom.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#proving-system-requirements","title":"Proving system requirements","text":"<p>The first two kinds of proofs, resource logic proofs and compliance proofs, follow the standard proving system interface defined here. The delta proof has an additional functionality required and is further described here.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#resource-logic-proving-system-choice","title":"Resource logic proving system choice","text":"<p>Resource logic proof is the most common proof type. Each action that modifies the state of <code>n</code> resources (creates or consumes) has at least <code>n</code> resource logic proofs attached to it. In principle, the predicate checked with each proof can be different for all <code>n</code> proofs. For that reason, the proving system of choice should support easy proof instantiation process for new predicates (e.g., a SNARK that requires a trusted setup ceremony initiated for every predicate is probably not the most efficient choice for this proving system).</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#compliance-proving-system-choice","title":"Compliance proving system choice","text":"<p>Compliance constraints are fixed per RM instantiation, meaning that the predicate being checked is the same for each compliance unit, with only the instance and witness being different each time. For that reason, a proving system that prioritises efficiency for a single predicate over the ease of creating proofs for new predicates might be more suitable.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/index.html#proving-system-hierarchy","title":"Proving system hierarchy","text":"<p>The diagram below describes the relationships between the proving system and delta proof interfaces and their instantiations that correspond to the proving system for each proof type.</p> <pre><code>---\ntitle: Proving System hierarchy\n---\nclassDiagram\n    class IProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n         +prove(ProvingKey, Instance, Witness) Proof\n         +verify(VerifyingKey, Instance, Proof) Bool\n    }\n\n    IProvingSystem &lt;|-- ResourceLogicProvingSystem\n    IProvingSystem &lt;|-- ComplianceProvingSystem\n    IProvingSystem &lt;|-- IDeltaProvingSystem\n\n    class ResourceLogicProvingSystem\n    class ComplianceProvingSystem\n\n    class IDeltaProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n        +aggregate(Proof, Proof) Proof\n    }\n    IDeltaProvingSystem &lt;|-- DeltaProvingSystem\n\n    class DeltaProvingSystem\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_delta.html","title":"Delta proving system","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_delta;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_delta.html#delta-proving-system","title":"Delta Proving System","text":"<p>Delta proving system is used to prove that the transaction delta is equal to a certain value. To support transaction composition that results in a new transaction being produced, the delta proving system must, in addition to the standard proving system interface, provide a proof aggregation function:</p> <p><code>DeltaProvingSystem</code>:</p> <ol> <li><code>prove(PS.ProvingKey, PS.Instance, PS.Witness) -&gt; PS.Proof</code></li> <li><code>verify(PS.VerifyingKey, PS.Instance, PS.Proof) -&gt; Bool</code></li> <li><code>aggregate(PS.Proof, PS.Proof) -&gt; PS.Proof</code></li> </ol> <p>The aggregation function allows to aggregate proofs in a way that if \\(\\pi_1\\) proves that the first transaction's balance is \\(b_1\\) and the second proof \\(\\pi_2\\) proves the second transaction's balance is \\(b_2\\), then the proof \\(Aggregate(\\pi_1, \\pi_2)\\) proves that the composed transaction's balance is \\(b_1 + b_2\\).</p> <pre><code>---\ntitle: Proving System hierarchy\n---\nclassDiagram\n    class IProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n         +prove(ProvingKey, Instance, Witness) Proof\n         +verify(VerifyingKey, Instance, Proof) Bool\n    }\n\n    IProvingSystem &lt;|-- IDeltaProvingSystem\n\n    class IDeltaProvingSystem~VerifyingKey, ProvingKey, Instance, Witness, Proof~ {\n         &lt;&lt;Interface&gt;&gt;\n        +aggregate(Proof, Proof) Proof\n    }\n    IDeltaProvingSystem &lt;|-- DeltaProvingSystem\n\n    class DeltaProvingSystem\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html","title":"Definitions","text":"<pre><code>module arch.system.state.resource_machine.primitive_interfaces.proving_system.proving_system_types;\n</code></pre>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html#proving-system-definition","title":"Proving system definition","text":"<p>We define a set of structures required to define a proving system \\(PS\\) as follows:</p> <ul> <li>Proof \\(\\pi: PS.Proof\\) - proves that a specific statement <code>f</code> with the inputs <code>x</code> and <code>w</code> evaluates to <code>True</code>.</li> <li>Instance \\(x: PS.Instance\\) is the ordered input data structure used to produce and verify a proof.</li> <li>Witness \\(w: PS.Witness\\) is the ordered input data structure used to produce (but not verify) a proof.</li> <li>Proving key \\(pk: PS.ProvingKey\\) contains the data required to produce a proof for a pair \\((x, w)\\). Specific to a particular statement (different statements <code>f</code> and <code>f'</code> imply different proving keys) being proven, but doesn't depend on the inputs.</li> <li>Verifying key \\(vk: PS.VerifyingKey\\) contains the data required, along with the instance \\(x\\), to verify a proof \\(\\pi\\). Specific to a particular statement being proven (different statements <code>f</code> and <code>f'</code> imply different verifying keys), but doesn't depend on the inputs. The verifying key is assumed to be of fixed size.</li> </ul> <p>A proving system \\(PS\\) consists of a pair of algorithms, \\((Prove, Verify)\\):</p> <ul> <li>\\(Prove(pk, x, w): PS.ProvingKey \\times PS.Instance \\times PS.Witness \\rightarrow PS.Proof\\)</li> <li>\\(Verify(vk, x, \\pi): PS.VerifyingKey \\times PS.Instance \\times PS.Proof \\rightarrow Bool\\).</li> </ul> <p>Note</p> <p>To verify a proof created for instance <code>x</code>, the same instance <code>x</code> must be used. For instances that contain elements of the same type, the order of the elements must be preserved.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html#properties","title":"Properties","text":"<p>A proving system must have the following properties:</p> <ul> <li>Completeness: it must be possible to make a proof for a statement which is true.</li> <li>Soundness: it must not be possible to make a proof for a statement which is false.</li> </ul> <p>For a statement <code>f</code>, <code>Verify(vk, x, proof) = True</code> implies that <code>f x w = True</code> and <code>Verify(vk, x, proof) = False</code> implies that <code>f x w = False</code>.</p> <p>Certain proving systems may also be zero-knowledge, meaning that the produced proofs reveal no information other than their own validity.</p> <p>A proof \\(\\pi\\) for which \\(Verify(pr) = True\\) is considered valid.</p>","boost":2},{"location":"arch/system/state/resource_machine/primitive_interfaces/proving_system/proving_system_types.html#common-proving-scheme-types","title":"Common proving scheme types","text":"<ul> <li>The trivial scheme is one where computation is simply replicated. The   trivial scheme is defined as <code>verify(predicate, x, _) = predicate x</code>. It has no extra security assumptions but is not succinct. In this case, all of the data is used for both proving and verifying and witness and proof has unit type <code>()</code>.</li> </ul> <ul> <li>The trusted delegation scheme is one where computation is delegated to a   known, trusted party whose work is not checked. The trusted delegation scheme   is defined as <code>verify((predicate, pk), x, sig) = checkSignature pk (predicate, x) sig</code>, where the trusted party is assumed to produce such a   signature only if <code>predicate x = True</code>. This scheme is succinct but requires a   trusted party assumption (which could be generalised to a threshold quorum in   the obvious way). Note that since the computation is still verifiable, a   signer of <code>(predicate, x)</code> where <code>predicate x = False</code> could be held   accountable by anyone else who later evaluated the predicate. In this case witness also has unit type and the proof has the type <code>Signature</code>.</li> </ul> <ul> <li>The succinct proof-of-knowledge scheme is one where the result of computation is attested to with a cryptographic proof (of the sort commonly instantiated by modern-day SNARKs &amp; STARKs). Succinct proof-of-knowledge schemes provide succinctness as well as verifiability subject to the scheme-specific cryptographic assumptions. They may also possibly be zero-knowledge, in which the verifier learns nothing other than <code>predicate x w = True</code> (in this case, and in others, <code>w</code> will be \"hidden\" with hash functions and <code>x</code> will remain public (and include the hiding representations of <code>w</code>), such that the verifier knows only <code>hash w</code> and <code>x</code> but the substance of the relation obtains over the preimages).</li> </ul> <p>Assuming the proving system is used to verify that a predicate evaluated on its inputs returns <code>True</code>, the table below describes what each parameter will be for each of the three common proving system instantiations:</p> Proving key Verifying key Instance (x) Witness (w) Proof Properties Trivial scheme hash of the predicate hash of the predicate predicate's arguments, predicate () () transparent, not succinct Trusted delegation hash of the predicate + signing key hash of the predicate + signature verifying key predicate's arguments, predicate () signature succinct, trusted, verifiable Succinct PoK defined by the scheme (incl. predicate representation) defined by the scheme public input private input defined by the scheme succinct, verifiable, possibly zero knowledge <p>Note</p> <p>In the trivial scheme, verification requires the pre-images of the verifying key / instance hashes. In the trusted delegation case, the pre-images are not required if the signature is produced over the hashed values.</p> <p>Note</p> <p>Proving-related data structures described further are written with a PoK proving system in mind. For a transparent system, all values that are marked as witness in the specification shouldn't be discarded but rather moved to instance.</p> <p>Note</p> <p>For application developers: writing applications that can work with all types of proving systems can be challenging since different proof types require different argument split between instance and witness (e.g., trivial scheme, unlike succinct PoK, expects no witness). The current solution is to write applications with succinct PoK types of proving systems in mind, which then can be translated to other proving systems by moving witness arguments to instance.</p>","boost":2},{"location":"indexes/modules.html","title":"Modules","text":"<p>All the Juvix modules for the Anoma Specification are listed below.</p>","tags":["index"]},{"location":"indexes/modules.html#juvix-package-version","title":"Juvix Package version","text":"<pre><code>package : Package :=\n  defaultPackage@{\n    name := \"nspec\";\n    version := mkVersion 1 0 0;\n    dependencies :=\n      [github \"anoma\" \"juvix-stdlib\" \"v0.11.0\"]\n  };\n</code></pre>","tags":["index"]},{"location":"indexes/modules.html#modules-by-letter","title":"Modules by letter","text":"","tags":["index"]},{"location":"indexes/tags.html","title":"List of tags","text":"","tags":["index"]},{"location":"indexes/tags.html#tag:accumulator","title":"accumulator","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:commitment","title":"commitment","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:evm","title":"evm","text":"<ul> <li>            EVM Datatypes          </li> <li>            EVM Execution Flow          </li> <li>            EVM Interoperability Achitecture Motivation          </li> <li>            EVM Interoperability Implementation          </li> <li>            EVM Interoprability Example Applications          </li> <li>            EVM Primitive Interfaces          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:identity","title":"identity","text":"<ul> <li>            Identity Architecture Types          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:nullifier","title":"nullifier","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:protocol","title":"protocol","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:protocol-adapter","title":"protocol-adapter","text":"<ul> <li>            EVM Datatypes          </li> <li>            EVM Execution Flow          </li> <li>            EVM Interoperability Achitecture Motivation          </li> <li>            EVM Interoperability Implementation          </li> <li>            EVM Interoprability Example Applications          </li> <li>            EVM Primitive Interfaces          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:resource-logic","title":"resource logic","text":"<ul> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:resource-machine","title":"resource-machine","text":"<ul> <li>            EVM Datatypes          </li> <li>            EVM Execution Flow          </li> <li>            EVM Interoperability Achitecture Motivation          </li> <li>            EVM Interoperability Implementation          </li> <li>            EVM Interoprability Example Applications          </li> <li>            EVM Primitive Interfaces          </li> <li>            Index          </li> </ul>","tags":["index"]},{"location":"indexes/tags.html#tag:system-architecture","title":"system-architecture","text":"<ul> <li>            Identity Architecture Types          </li> </ul>","tags":["index"]},{"location":"tutorial/branch.html","title":"Git branching strategy","text":"<p>The general workflow is to branch off from the latest version's branch, perform your changes, open a pull request, and merge your updates.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#branching-strategy","title":"Branching strategy","text":"","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#for-changes-to-the-latest-version","title":"For changes to the latest version","text":"<p>For changes to the latest version, branch off from <code>main</code>. Name your branch by prefixing your name and an issue identifier, like <code>your-name/issue-identifier</code>.</p> <pre><code>git fetch\ngit checkout -b your-name/issue-identifier origin/main\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#for-changes-to-older-published-versions","title":"For changes to older published versions","text":"<p>For patching older versions, branch off from the specific version branch. Published versions follow the pattern <code>vX</code>, where <code>X</code> is the version number. For example, say the latest version is <code>v0.1.0</code>.</p> <p>Name your branch by prefixing your name and a patch topic, like <code>your-name/patch-topic</code>.</p> <pre><code>git checkout -b your-name/patch-topic v0.1.0\n</code></pre> <p>The git graph will look like:</p> <pre><code>%%{init: { 'theme': 'neutral' } }%%\ngitGraph:\n    commit\n    branch vX\n    checkout vX\n    commit\n    branch your-name/issue-identifier\n    checkout your-name/issue-identifier\n    commit\n    checkout vX\n    merge your-name/issue-identifier</code></pre> <p>So, if your PR is merged, the changes will be incorporated into the version branch and on the website.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#pushing-changes","title":"Pushing changes","text":"<p>When pushing changes for the first time in a new branch, set the upstream tracking branch:</p> <pre><code>git push -u origin some-branch:some-branch\n</code></pre> <p>Afterwards, for subsequent pushes the following is sufficient: <pre><code>git push\n</code></pre></p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#rebasing-your-work","title":"Rebasing your work","text":"<p>Every once in a while, you should rebase your branch onto the base branch, if the current version has been updated. This will incorporate the latest changes from the base branch into your branch. The steps to rebase are usually the following.</p> <ul> <li>Switch to your working branch:<pre><code>git checkout your-name/issue-identifier\n</code></pre> </li> </ul> <ul> <li>Initiate the rebase onto the target branch:<pre><code>git pull origin main --rebase\n</code></pre> <p>Or merge the changes from the base branch which is convenient most of the   time:</p> <pre><code>git merge main\n</code></pre> </li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#resolve-conflicts","title":"Resolve conflicts","text":"<ul> <li>Git will pause for conflict resolution.</li> <li> <p>After resolving each conflict:</p> <pre><code>git rebase --continue\n</code></pre> </li> </ul> <ul> <li> <p>To stop the rebase process:</p> <pre><code>git rebase --abort\n</code></pre> </li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#push-your-changes","title":"Push your changes","text":"<ul> <li>Once rebase is complete, push changes:<pre><code>git push origin your-name/issue-identifier\n</code></pre> </li> </ul> <ul> <li>A force push may be required:<pre><code>git push origin your-name/issue-identifier --force-with-lease\n</code></pre> </li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#important-notes","title":"Important notes","text":"<ul> <li>Ensure you are on the correct branch before making changes.</li> <li>Regularly update your branch to minimise conflicts.</li> <li>Ask for help if you encounter any issues to the maintainers.</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#merging-prs","title":"Merging PRs","text":"<p>Before a PR can be merged into the <code>main</code> branch, it must be able to build the whole codebase. The CI checks this automatically, and can be also verified manually:</p> <p>First, we must check the Juvix codebase, running the following command:</p> <pre><code>juvix typecheck docs/everything.juvix.md\n</code></pre> <p>Next, we must verify the MkDocs site build by running the following command:</p> <pre><code>uv run mkdocs build\n</code></pre> <p>or with <code>just</code></p> <pre><code>just build\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#integration-branches-for-complex-changes","title":"Integration branches for complex changes","text":"<p>When making complex changes that consist of a set of interdependent changes, it's best to split them up into smaller PRs that each address a single topic.</p> <p>For example, making a change to a type can be in one PR, a change to a different type in a second PR, and applying the type changes in the rest of the code base in a third one. In this case, branch 3 needs to merge branch 1 &amp; 2 first.</p> <p>We also need to create an integration branch, which becomes the base branch for all the interdependent PRs, and a corresponding integration PR to be merged into the <code>main</code> branch.</p> <p>On GitHub, make sure to include the list of auxiliary PRs as part of the description of the integration PR.</p> <p>This way the topic branches need not be able to build the whole codebase, while the integration branch must be able to build it once all the topic branches are merged into it.</p> <p>A possible diagram of the integration branch and topic branches is the following, assuming the integration branch is <code>example/integration</code> against <code>main</code>, and the topic branches are <code>example/topic-1</code> against <code>main</code>, <code>example/topic-2</code> against <code>main</code>, and <code>example/topic-3</code> against <code>main</code>. The topic branches are squashed-and-merged into the integration branch.</p> <pre><code>%%{init: { 'theme': 'neutral' } }%%\ngitGraph:\n    commit\n    branch example/topic-1\n    checkout example/topic-1\n    commit\n    checkout main\n    branch example/topic-2\n    checkout example/topic-2\n    commit\n    checkout main\n    branch example/integration\n    checkout example/integration\n    merge example/topic-1\n    merge example/topic-2\n    commit \"Fix merge conflicts\"\n    checkout main\n    merge example/integration</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#fetch-the-latest-updates","title":"Fetch the latest updates","text":"<pre><code>git fetch\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-integration-branch","title":"Create integration branch","text":"<pre><code>git branch example/integration origin/main\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-topic-branches","title":"Create topic branches","text":"<pre><code>git branch example/topic-1 example/integration\ngit branch example/topic-2 example/integration\ngit branch example/topic-3 example/integration\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#merge-dependencies","title":"Merge dependencies","text":"<pre><code>git checkout example/topic-3\ngit merge example/topic-1\ngit merge example/topic-2\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#using-git-worktrees","title":"Using Git Worktrees","text":"<p>When working on multiple branches simultaneously, git worktrees come handy. Here's how to use them.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#fetch-the-latest-updates_1","title":"Fetch the latest updates","text":"<pre><code>git fetch\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-a-branch","title":"Create a branch","text":"<pre><code>git branch some-branch origin/main\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/branch.html#create-a-worktree-for-the-branch","title":"Create a Worktree for the branch","text":"<p>Either inside the repo starting with a dot (to avoid build issues):</p> <pre><code>git worktree add /path/to/repo/.tree/some-branch some-branch\n</code></pre> <p>Or outside the repo:</p> <pre><code>git worktree add /path/to/repo-some-branch some-branch\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/changelog.html","title":"Managing the Changelog","text":"<p>We now use <code>Commitizen</code> to manage our changelog entries. This simplifies the process and ensures consistent formatting. The <code>Commitizen</code> binary should be available after installation.</p>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#adding-a-new-unreleased-entry","title":"Adding a New Unreleased Entry","text":"<p>To add a new changelog entry, use the <code>cz</code> command provided by <code>Commitizen</code>. This will guide you through the process interactively.</p>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#using-commitizen","title":"Using Commitizen","text":"","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#available-types","title":"Available Types","text":"<p>When prompted, choose one of these types for your commit message:</p> <ul> <li><code>feat</code> - For new features</li> <li><code>fix</code> - For bug fixes</li> <li><code>docs</code> - For documentation changes</li> <li><code>style</code> - For code style changes (formatting, missing semi-colons, etc.)</li> <li><code>refactor</code> - For code changes that neither fix a bug nor add a feature</li> <li><code>perf</code> - For performance improvements</li> <li><code>test</code> - For adding or correcting tests</li> <li><code>chore</code> - For changes to the build process or auxiliary tools</li> </ul>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/changelog.html#recommended-commit-message-format","title":"Recommended Commit Message Format","text":"<p>For consistency, follow the prompts to:</p> <ul> <li>Specify the type of change</li> <li>Provide a concise description of the change</li> <li>Optionally, include the issue number if the change is related to an issue</li> </ul> <p>More information about the command syntax can be found in the Commitizen documentation.</p>","tags":["tutorial","changelog"],"boost":3},{"location":"tutorial/commit_checks.html","title":"Run pre-commit checks","text":"<p>Pre-commit hooks are scripts that run before each commit to ensure code quality by checking for common issues.</p>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/commit_checks.html#running-pre-commit-checks","title":"Running pre-commit checks","text":"<p>After installing the development tools, you can, for example, invoke all checks, by running the following command:</p> <pre><code>uv run pre-commit -- run --all-files\n</code></pre> <p>Or shorter:</p> <pre><code>just check\n</code></pre>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html","title":"<code>snake_case</code> convention for naming files and folders","text":"<p>The Anoma Specification uses the <code>snake_case</code> convention for naming files and folders.</p>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html#guidelines","title":"Guidelines","text":"<ul> <li>Use lowercase letters.</li> <li>Separate words with underscores <code>_</code>, instead of dashes <code>-</code> or camel case.</li> <li>No special characters or spaces.</li> </ul>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html#pros","title":"Pros","text":"<ul> <li>Readability: Improves readability by clearly separating words in names, making   code more understandable.</li> <li>Consistency: Creates a uniform naming style throughout the codebase.</li> <li>Compatibility: Widely supported across different programming languages and   platforms, no issues with case sensitivity.</li> </ul>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/file_naming.html#cons","title":"Cons","text":"<ul> <li>Length: Can make names longer.</li> <li>Visual Clutter: The underscores can create visual clutter, especially in   longer names. We suffer from this, specially in engine's description files.</li> </ul> <p>Info</p> <p>If you find any file or folder that does not follow this convention, please create an issue or a pull request to fix it. Thank you for your help!</p>","tags":["tutorial","conventions"],"boost":3},{"location":"tutorial/juvix.html","title":"Render Juvix code","text":"<p>Another feature of the Anoma documentation is the inclusion of Juvix code throughout its Markdown support. Here we assume you have Juvix already installed.</p> <p>A Juvix Markdown file is a file with extension <code>.juvix.md</code>. These files are preprocesses by the Juvix compiler to generate the final Markdown file. For this website, we are using <code>mkdocs-juvix-plugin</code>.</p>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#juvix-markdown-file-structure","title":"Juvix Markdown file structure","text":"<p>Very important to note is that the first Juvix code block must declare a module with the name of the file, and each block should be a sequence of well-defined expressions. This means submodules cannot be split across blocks. The name of  module must follow the folder structure of the file is in. For example, the  file <code>tutorial/basics.juvix.md</code> must declare the module <code>tutorial.basics</code>.</p> <pre><code>```juvix\nmodule tutorial.basics;\n-- ...\n```</code></pre> <p>Refer to the <code>everything.juvix.md</code> file located in the <code>docs</code> folder to see an example.</p>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#hide-juvix-code-blocks","title":"Hide Juvix code blocks","text":"<p>Juvix code blocks come with a few extra features, such as the ability to hide the code block from the final output. This is done by adding the <code>hide</code> attribute to the code block. For example:</p> <pre><code>```juvix hide\nmodule tutorial.basics;\n-- ...\n```</code></pre>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#extract-inner-module-statements","title":"Extract inner module statements","text":"<p>Another feature is the ability to extract inner module statements from the code block. This is done by adding the <code>extract-module-statements</code> attribute to the code block. This option can be accompanied by a number to indicate the number of statements to extract. For example, the following would only display the content inside the module <code>B</code>, that is, the module <code>C</code>.</p> <pre><code>```juvix extract-module-statements\nmodule B;\nmodule C;\n-- ...\n```</code></pre>","tags":["tutorial","juvix"]},{"location":"tutorial/juvix.html#snippets-of-juvix-code","title":"Snippets of Juvix code","text":"<p>You can also include snippets of Juvix code in your Markdown files. This is done by adding the <code>--8&lt;--</code> comment followed by the path to the file, and optionally a snippet identifier.</p> <p>Note</p> <p>If the path of the file ends with <code>!</code>, the raw content of the file will be included. Otherwise, for Juvix Markdown files, the content will be preprocessed by the Juvix compiler and then the generated HTML will be included.</p> <p>Snippet identifier</p> <p>To use a snippet identifier, you must wrap the Juvix code block with the syntax <code>&lt;!-- --8&lt;-- [start:snippet_identifier] --&gt;</code> and <code>&lt;!-- --8&lt;-- [end:snippet_identifier] --&gt;</code>. This technique is useful for including specific sections of a file. Alternatively, you use the standard <code>--8&lt;--</code> markers within the code and extract the snippet by appending a ! at the end of the path.</p>","tags":["tutorial","juvix"]},{"location":"tutorial/principles_and_guidelines.html","title":"Global principles and guidelines for writing Anoma Specification documentation","text":"","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#principles","title":"Principles","text":"","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#clarity","title":"Clarity","text":"<p>Make every page clear and concise. Footnotes may be used to add context. Additional notes that exceed a paragraph may deserve to be put into a separate file (and thus will appear in the navigation bar).</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#dont-repeat-yourself","title":"Don't repeat yourself!","text":"<p>Do not paste any copied material. Instead, include the material, e.g., via snippeting. The only exception is material for which there is no established method for inclusion; in this case, include the material inside a todo note <code>!!! todo \"unrepeat this\"</code>, paired with a reference to its source.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#consistency","title":"Consistency","text":"<p>Terms from the glossary must be used consistently throughout the specification. Where applicable, adhere to naming schemes.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#style","title":"Style","text":"<p>Conform to style guides, unless this would lead to inconsistency.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#citations","title":"Citations","text":"<p>Use citations to refer to articles, books, and similar publications.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#guidelines","title":"Guidelines","text":"","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#accessibility","title":"Accessibility","text":"<p>The specification should be accessible to its intended readership, which should encompass at least the members of the Anoma engineering team.</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#internal-and-external-linking","title":"Internal and external linking","text":"<p>If you have a link for something, please use it. Chances are that it improves accessibility and moreover it helps discover inconsistencies. Use wikilinks for internal links and URL links (<code>[target](URL)</code>) only for external material (or if wikilinks do not work as expected).</p>","tags":["tutorial"]},{"location":"tutorial/principles_and_guidelines.html#implementability","title":"Implementability","text":"<p>The specification should keep design decisions to a minimum, but design decisions that are left to the potential implementer on purpose should be discussed in footnotes or notes.</p>","tags":["tutorial"]},{"location":"tutorial/versioning.html","title":"Versioning","text":"<p>The Anoma Specification follows semantic versioning.</p> <pre><code>MAJOR.MINOR.PATCH\n</code></pre> <ul> <li>MAJOR version when you make incompatible API changes</li> <li>MINOR version when you add functionality in a backward compatible manner</li> <li>PATCH version when you make backward compatible bug fixes</li> </ul>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#more-on-versioning-criteria","title":"More on versioning criteria","text":"<ul> <li>Major version (X.0.0): Incremented for backwards-incompatible changes, like:<p>- Breaking changes to core interfaces or types   - Removal of deprecated functionality   - Major architectural changes</p> </li> </ul> <ul> <li>Minor version (0.X.0): Incremented for backwards-compatible feature additions:<p>- New engines, message types, or behaviours   - New functionality that doesn't break existing code   - Deprecation notices for future breaking changes</p> </li> </ul> <ul> <li>Patch version (0.0.X): Incremented for backwards-compatible bug fixes:<p>- Documentation improvements   - Bug fixes that don't change interfaces   - Minor code clean-up and refactoring</p> </li> </ul>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#preparing-a-new-version","title":"Preparing a new version","text":"<ul> <li> Update <code>mkdocs.yml</code></li> <li> Update <code>docs/Package.juvix</code></li> <li> Update <code>docs/references/ref.bib</code></li> <li> Make sure to run <code>just sync</code> to update the dependencies and <code>just build</code> to check that the code is still typechecking.</li> <li> Git tag the new version</li> <li> Release a new changelog entry</li> </ul>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-mkdocsyml","title":"Update <code>mkdocs.yml</code>","text":"<p>Update the <code>site_version</code> to the new version.</p> mkdocs.yml<pre><code>- site_version: !ENV [SITE_VERSION, \"v0.1.0\"]\n+ site_version: !ENV [SITE_VERSION, \"v0.1.1\"]\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-nspec-juvix-package-version","title":"Update <code>nspec</code> Juvix package version","text":"docs/Package.juvix<pre><code>package : Package :=\n  defaultPackage@{\n    name := \"nspec\";\n-    version := mkVersion 0 1 0;\n+    version := mkVersion 0 1 1;\n    dependencies :=\n      [github \"anoma\" \"juvix-stdlib\" \"v0.6.0\"; github \"anoma\" \"juvix-containers\" \"v0.14.1\"]\n  };\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-docsrefbib","title":"Update <code>docs/ref.bib</code>","text":"<p>Update the version of the <code>nspec</code> package in the <code>ref.bib</code> file.</p> docs/ref.bib<pre><code>@software{nspec,\n  author = {Anoma},\n  title = {Anoma Specification},\n-  version = {0.1.0},\n+  version = {0.1.1},\n  url = {https://github.com/anoma/nspec}\n}\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-version","title":"Update <code>VERSION</code>","text":"VERSION<pre><code>-0.1.0\n+0.1.1\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#update-pyprojecttoml","title":"Update <code>pyproject.toml</code>","text":"pyproject.toml<pre><code>- version = \"0.1.0\"\n+ version = \"0.1.1\"\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#git-tag-the-new-version","title":"Git tag the new version","text":"<pre><code>git tag v0.1.1\n</code></pre>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/versioning.html#release-a-new-changelog-entry","title":"Release a new changelog entry","text":"<p>Follow the Updating the changelog tutorial for more information on how to release a new changelog entry. This tutorial uses <code>unclog</code> to create a new changelog entry.</p> <p>The package started at version 0.1.0 as the initial release.</p>","tags":["tutorial","conventions","versioning"]},{"location":"tutorial/install/index.html","title":"Preparing the local environment for writing documentation","text":"","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#getting-started","title":"Getting Started","text":"<p>Welcome to the Anoma Specs repository! This project uses Material for MkDocs for documentation and is designed for easy contribution and local development.</p> <ul> <li>Latest Specs: https://specs.anoma.net/latest/</li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#quick-start","title":"Quick Start","text":"","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#1-prerequisites","title":"1. Prerequisites","text":"<p>Make sure you have the following tools installed:</p> <ul> <li>uv (Python package/dependency manager)<ul> <li>macOS/Linux:   <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre></li> <li>Windows:   <pre><code>powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre></li> <li>Or via Homebrew:   <pre><code>brew install uv\n</code></pre></li> </ul> </li> </ul> <ul> <li>graphviz (for local documentation deployment)</li> </ul> <ul> <li>juvix (for typechecking and specs development)   <pre><code>curl --proto '=https' --tlsv1.2 -sSfL https://get.juvix.org | sh\n</code></pre></li> </ul> <ul> <li>just (a simple command runner, replacement for Make)<ul> <li>Install via your package manager.</li> </ul> </li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#2-installation","title":"2. Installation","text":"<p>Choose one of the following:</p> <ul> <li>With uv:   <pre><code>uv sync\n</code></pre></li> <li>With just:   <pre><code>just sync\n</code></pre></li> <li>With pip:   <pre><code>pip install -r requirements.txt\n</code></pre></li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#3-common-commands","title":"3. Common Commands","text":"<p>You can use either <code>just</code> or <code>uv run</code> for most tasks. Below are the most common commands:</p>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#dependency-management","title":"Dependency Management","text":"Task Command Command (just) Synchronize dependencies <code>uv sync</code> <code>just sync</code> Run all pre-commit checks <code>uv run pre-commit -- run --all-files</code> <code>just check</code> Typecheck the code <code>juvix typecheck docs/everything.juvix.md</code> <code>just juvix-check</code>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#development-tools","title":"Development Tools","text":"<ul> <li>Install pre-commit hooks (for specs writers only):   <pre><code>uv run pre-commit -- install --install-hooks\n</code></pre>   or   <pre><code>just install-hooks\n</code></pre></li> </ul> <ul> <li>Install development tools:   <pre><code>uv tool install pre-commit\nuv tool install commitizen\n</code></pre>   or   <pre><code>just install-tools\n</code></pre></li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#documentation","title":"Documentation","text":"Task Command Command (just) Build documentation <code>uv run mkdocs build --config-file mkdocs.yml</code> <code>just build</code> Serve documentation locally <code>uv run mkdocs serve --config-file mkdocs.yml</code> <code>just serve</code>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#git-operations","title":"Git Operations","text":"Task Command Command (just) Commit using commitizen <code>uv run cz commit</code> <code>just commit</code> Commit skipping hooks <code>git commit --no-verify -m \"&lt;msg&gt;\"</code> <code>just commit-skip</code> Amend commit (skip hooks) <code>git commit --amend --no-verify</code> <code>just commit-amend</code> Amend using commitizen <code>uv run cz commit --amend</code> <code>just cz-amend</code> <p>If you have installed the pre-commit hooks (which is recommended), but need to make a commit or push changes without running the hooks (for example, when working on a branch or PR), you can use the <code>--no-verify</code> flag as shown in the table above. The Commitizen is a tool to help you write better commit messages.</p>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#4-short-reference","title":"4. Short Reference","text":"<ul> <li>Install: <code>uv sync</code> or <code>pip install -r requirements.txt</code></li> <li>Build: <code>just build</code> or <code>uv run mkdocs build</code></li> <li>Serve Locally: <code>just serve</code> or <code>uv run mkdocs serve</code></li> </ul>","tags":["tutorial","install"]},{"location":"tutorial/install/index.html#development-with-nix","title":"Development with Nix","text":"<p>If you use Nix:</p> <ol> <li>Install Nix: Download</li> <li>Enable Flakes: Guide</li> <li>Enter Development Shell:    <pre><code>nix develop\n</code></pre></li> </ol>","tags":["tutorial","install"]},{"location":"tutorial/md/index.html","title":"Markdown Basics for Anoma Documentation","text":"<p>Our theme and main Markdown reference is Material for MkDocs. You may use anything found in this reference, including all possible Markdown extensions.</p> <p>This guide provides an overview of the key markdown features we use in the documentation. Please note that this guide is a work-in-progress.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/index.html#front-matter","title":"Front Matter","text":"<p>Each markdown file should begin with a front matter section. It typically includes metadata such as <code>icon</code>, <code>tags</code>, <code>categories</code>. For more examples, refer to other files within the documentation. For example, the icons name can be found here.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/index.html#example-front-matter","title":"Example Front Matter","text":"<pre><code>---\nicon: material/auto-download\nsearch:\n  exclude: false\n  boost: 3\ntags:\n  - harware-subsystem\n  - logging\n---\n</code></pre> <p>Warning</p> <p>Any new markdown file added to the <code>docs</code> directory must, in principle, have an entry in the <code>mkdocs.yml</code> file, specifically in the <code>nav</code> section.</p> <p>The filename may be relevant depending on where it is placed in the navigation. For example, any file intended to be the landing page of a section, say Section X, must be named <code>index.md</code> and placed right below the <code>Section X</code> item. Children of <code>Section X</code> do not need to follow any specific naming convention.</p> <pre><code>...\n- Section X:\n    - ./path-to/index.md\n    - NameRef Child1 : ./path-to/child1.md\n    - NameRef Child2 : ./path-to/child2.md\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/citations.html","title":"Bibliography","text":"<p>Place your <code>.bib</code> files within the <code>docs/references</code> directory. For convenience, we have included all the ART published papers in the <code>docs/references/art.bib</code> file.</p> <p>Any new <code>.bib</code> file added to this folder will automatically be processed.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/citations.html#citing-in-markdown","title":"Citing in Markdown","text":"<p>Use the citation key from your <code>.bib</code> files to cite references in your markdown files. The syntax is as follows:</p> <pre><code>This statement requires a citation .\n</code></pre> <p>Info</p> <p>We have <code>docs/references/update_repo_bibtexs.py</code> script that can be used to update the <code>docs/references/anoma_repos.bib</code> file to cite Anoma repositories in the documentation.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/citations.html#references-available","title":"References available","text":"Anoma Research Topics (ART) papers <pre><code>% https://art.anoma.net\n\n\n@article{ art-2025-optimising-shielded-state-synchronization,\n    author    = { Larraia, Enrique and Khalniyazova, Yulia },\n    title     = { {Optimising Shielded State Synchronization with FMD and TEEs} },\n    journal   = { Anoma Research Topics },\n    month     = { Apr },\n    year      = { 2025 },\n    publisher = { Zenodo },\n    version   = { April 10, 2025 },\n    doi       = { 10.5281/zenodo.15186457 },\n    url       = { https://doi.org/10.5281/zenodo.15186456 }\n}\n\n\n@article{ art-2025-dynamic-effective-timed-communication-systems,\n    author    = { Heindel, Tobias and Prieto-Cubides, Jonathan and Hart, Anthony },\n    title     = { {Dynamic Effective Timed Communication Systems} },\n    journal   = { Anoma Research Topics },\n    month     = { Mar },\n    year      = { 2025 },\n    publisher = { Zenodo },\n    version   = { March 06, 2025 },\n    doi       = { 10.5281/zenodo.14984148 },\n    url       = { https://doi.org/10.5281/zenodo.14984147 }\n}\n\n\n@article{ art-2024-nock-functional-programmers,\n    author    = { Czajka, Lukasz },\n    title     = { {Nock for Functional Programmers} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 18, 2024 },\n    doi       = { 10.5281/zenodo.14511714 },\n    url       = { https://doi.org/10.5281/zenodo.14511713 }\n}\n\n\n@article{ art-2024-message-logic,\n    author    = { Gabbay, Murdoch J. and Zarin, Naqib },\n    title     = { {Message Logic} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 04, 2024 },\n    doi       = { 10.5281/zenodo.14251398 },\n    url       = { https://doi.org/10.5281/zenodo.14251397 }\n}\n\n\n@article{ art-2024-anoma-state-architecture,\n    author    = { Sheff, Isaac },\n    title     = { {Anoma State Architecture} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 04, 2024 },\n    doi       = { 10.5281/zenodo.14265827 },\n    url       = { https://doi.org/10.5281/zenodo.14265826 }\n}\n\n\n@article{ art-2024-heterogeneous-paxos-20-specs,\n    author    = { Karbyshev, Aleksandr and Sheff, Isaac },\n    title     = { {Heterogeneous Paxos 2.0: the Specs} },\n    journal   = { Anoma Research Topics },\n    month     = { Dec },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { December 04, 2024 },\n    doi       = { 10.5281/zenodo.14276903 },\n    url       = { https://doi.org/10.5281/zenodo.12572557 }\n}\n\n\n@article{ art-2024-slow-games-policy-enforcement-under,\n    author    = { Reusche, D and Goes, Christopher and Della Penna, Nicolas },\n    title     = { {Slow Games: Policy Enforcement under Uncertainty} },\n    journal   = { Anoma Research Topics },\n    month     = { Sep },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { September 15, 2024 },\n    doi       = { 10.5281/zenodo.13765214 },\n    url       = { https://doi.org/10.5281/zenodo.13765213 }\n}\n\n\n@article{ art-2024-compiling-juvix-cairo-assembly,\n    author    = { Czajka, \u0141ukasz },\n    title     = { {Compiling Juvix to Cairo Assembly} },\n    journal   = { Anoma Research Topics },\n    month     = { Sep },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { September 10, 2024 },\n    doi       = { 10.5281/zenodo.13739344 },\n    url       = { https://doi.org/10.5281/zenodo.13739343 }\n}\n\n\n@article{ art-2024-comparing-two-hash-functions,\n    author    = { Y\u0131ld\u0131z, Burcu and Maller, Mary },\n    title     = { {Comparing Two Hash Functions for Multi-Party Computation and Zero-Knowledge} },\n    journal   = { Anoma Research Topics },\n    month     = { Sep },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { September 10, 2024 },\n    doi       = { 10.5281/zenodo.13739511 },\n    url       = { https://doi.org/10.5281/zenodo.13739510 }\n}\n\n\n@article{ art-2024-intentcentric-applications-anoma,\n    author    = { Heuer, Michael and Reusche, D },\n    title     = { {Intent-centric Applications for the Anoma Resource Machine} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { August 26, 2024 },\n    doi       = { 10.5281/zenodo.13340448 },\n    url       = { https://doi.org/10.5281/zenodo.13340447 }\n}\n\n\n@article{ art-2024-heterogeneous-narwhal-paxos,\n    author    = { Heindel, Tobias and Karbyshev, Aleksandr and Sheff, Isaac },\n    title     = { {Heterogeneous Narwhal and Paxos} },\n    journal   = { Anoma Research Topics },\n    month     = { Jun },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { June 27, 2024 },\n    doi       = { 10.5281/zenodo.10498999 },\n    url       = { https://doi.org/10.5281/zenodo.10498998 }\n}\n\n\n@article{ art-2024-crosschain-integrity-controller-labels,\n    author    = { Isaac, Sheff },\n    title     = { {Cross-Chain Integrity with Controller Labels and Endorsement} },\n    journal   = { Anoma Research Topics },\n    month     = { Jun },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { June 25, 2024 },\n    doi       = { 10.5281/zenodo.10498997 },\n    url       = { https://doi.org/10.5281/zenodo.10498996 }\n}\n\n\n@article{ art-2024-anoma-resource-machine-specification,\n    author    = { Khalniyazova, Yulia and Goes, Christopher },\n    title     = { {Anoma Resource Machine Specification} },\n    journal   = { Anoma Research Topics },\n    month     = { Jun },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { June 25, 2024 },\n    doi       = { 10.5281/zenodo.10689620 },\n    url       = { https://doi.org/10.5281/zenodo.10498990 }\n}\n\n\n@article{ art-2024-compiling-zkvms,\n    author    = { Centelles, Alberto },\n    title     = { {Compiling to ZKVMs} },\n    journal   = { Anoma Research Topics },\n    month     = { Apr },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { April 19, 2024 },\n    doi       = { 10.5281/zenodo.10998758 },\n    url       = { https://doi.org/10.5281/zenodo.10498994 }\n}\n\n\n@article{ art-2024-intent-machines,\n    author    = { Hart, Anthony and Reusche, D },\n    title     = { {Intent Machines} },\n    journal   = { Anoma Research Topics },\n    month     = { Feb },\n    year      = { 2024 },\n    publisher = { Zenodo },\n    version   = { February 21, 2024 },\n    doi       = { 10.5281/zenodo.10654543 },\n    url       = { https://doi.org/10.5281/zenodo.10498992 }\n}\n\n\n@article{ art-2023-vampir-bestiary,\n    author    = { Fitzgerald, Joshua and Centelles, Alberto },\n    title     = { {VampIR Bestiary} },\n    journal   = { Anoma Research Topics },\n    month     = { Nov },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { November 13, 2023 },\n    doi       = { 10.5281/zenodo.10118865 },\n    url       = { https://doi.org/10.5281/zenodo.10118864 }\n}\n\n\n@article{ art-2023-constraint-satisfaction-problems-survey,\n    author    = { Hart, Anthony },\n    title     = { {Constraint Satisfaction Problems: A Survey for Anoma} },\n    journal   = { Anoma Research Topics },\n    month     = { Oct },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { October 18, 2023 },\n    doi       = { 10.5281/zenodo.10019113 },\n    url       = { https://doi.org/10.5281/zenodo.10019112 }\n}\n\n\n@article{ art-2023-exploring-cryptographic-approaches-enhance,\n    author    = { Khalniyazova, Yulia },\n    title     = { {Exploring Cryptographic Approaches to Enhance Privacy in Intent Solving} },\n    journal   = { Anoma Research Topics },\n    month     = { Oct },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { October 02, 2023 },\n    doi       = { 10.5281/zenodo.8321167 },\n    url       = { https://doi.org/10.5281/zenodo.8321166 }\n}\n\n\n@article{ art-2023-core-language-juvix,\n    author    = { Lukasz Czajka },\n    title     = { {The Core language of Juvix} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 29, 2023 },\n    doi       = { 10.5281/zenodo.8268850 },\n    url       = { https://doi.org/10.5281/zenodo.8268849 }\n}\n\n\n@article{ art-2023-rethinking-vampir,\n    author    = { Anthony Hart },\n    title     = { {Rethinking VampIR} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 29, 2023 },\n    doi       = { 10.5281/zenodo.8262815 },\n    url       = { https://doi.org/10.5281/zenodo.8262814 }\n}\n\n\n@article{ art-2023-anoma-unified-architecture,\n    author    = { Christopher Goes and Awa Sun Yin and Adrian Brink },\n    title     = { {Anoma: a unified architecture for full-stack decentralised applications} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 24, 2023 },\n    doi       = { 10.5281/zenodo.8279842 },\n    url       = { https://doi.org/10.5281/zenodo.8279841 }\n}\n\n\n@article{ art-2023-geb-pipeline,\n    author    = { Artem Gureev and Jonathan Prieto-Cubides },\n    title     = { {Geb Pipeline} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 21, 2023 },\n    doi       = { 10.5281/zenodo.8262747 },\n    url       = { https://doi.org/10.5281/zenodo.8262746 }\n}\n\n\n@article{ art-2023-juvix-vampir-pipeline,\n    author    = { Lukasz Czajka },\n    title     = { {Juvix to VampIR Pipeline} },\n    journal   = { Anoma Research Topics },\n    month     = { Aug },\n    year      = { 2023 },\n    publisher = { Zenodo },\n    version   = { August 14, 2023 },\n    doi       = { 10.5281/zenodo.8252903 },\n    url       = { https://doi.org/10.5281/zenodo.8246535 }\n}\n</code></pre> Anoma Public GitHub repositories <pre><code>  author = {anoma},\n  title = {juvix},\n  year = {2017},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/juvix}\n}\n\n@misc{github-masp-mpc,\n  author = {anoma},\n  title = {masp-mpc},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/masp-mpc}\n}\n\n@misc{github-masp,\n  author = {anoma},\n  title = {masp},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/masp}\n}\n\n@misc{github-ferveo,\n  author = {anoma},\n  title = {ferveo},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/ferveo}\n}\n\n@misc{github-anoma,\n  author = {anoma},\n  title = {anoma},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/anoma}\n}\n\n@misc{github-group-threshold-crypto,\n  author = {anoma},\n  title = {group-threshold-crypto},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/group-threshold-crypto}\n}\n\n@misc{github-research,\n  author = {anoma},\n  title = {research},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/research}\n}\n\n@misc{github-plonkup-hash,\n  author = {anoma},\n  title = {plonkup-hash},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/plonkup-hash}\n}\n\n@misc{github-plonkup,\n  author = {anoma},\n  title = {plonkup},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/plonkup}\n}\n\n@misc{github-typhon,\n  author = {anoma},\n  title = {typhon},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/typhon}\n}\n\n@misc{github-exhibit_plonkup,\n  author = {anoma},\n  title = {exhibit_plonkup},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/exhibit_plonkup}\n}\n\n@misc{github-taiga,\n  author = {anoma},\n  title = {taiga},\n  year = {2021},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/taiga}\n}\n\n@misc{github-juvix-stdlib,\n  author = {anoma},\n  title = {juvix-stdlib},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/juvix-stdlib}\n}\n\n@misc{github-namada-trusted-setup,\n  author = {anoma},\n  title = {namada-trusted-setup},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada-trusted-setup}\n}\n\n@misc{github-alucard,\n  author = {anoma},\n  title = {alucard},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/alucard}\n}\n\n@misc{github-masp-phase2,\n  author = {anoma},\n  title = {masp-phase2},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/masp-phase2}\n}\n\n@misc{github-vamp-ir,\n  author = {anoma},\n  title = {vamp-ir},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/vamp-ir}\n}\n\n@misc{github-namada-testnets,\n  author = {anoma},\n  title = {namada-testnets},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada-testnets}\n}\n\n@misc{github-ethereum-bridge,\n  author = {anoma},\n  title = {ethereum-bridge},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/ethereum-bridge}\n}\n\n@misc{github-vscode-juvix,\n  author = {anoma},\n  title = {vscode-juvix},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/vscode-juvix}\n}\n\n@misc{github-whitepaper,\n  author = {anoma},\n  title = {whitepaper},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/whitepaper}\n}\n\n@misc{github-devchain-container,\n  author = {anoma},\n  title = {devchain-container},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/devchain-container}\n}\n\n@misc{github-wasm-workspace,\n  author = {anoma},\n  title = {wasm-workspace},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/wasm-workspace}\n}\n\n@misc{github-devtool,\n  author = {anoma},\n  title = {devtool},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/devtool}\n}\n\n@misc{github-anoma-wasm-multitoken,\n  author = {anoma},\n  title = {anoma-wasm-multitoken},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/anoma-wasm-multitoken}\n}\n\n@misc{github-dev-utils,\n  author = {anoma},\n  title = {dev-utils},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/dev-utils}\n}\n\n@misc{github-namada,\n  author = {anoma},\n  title = {namada},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada}\n}\n\n@misc{github-namada-interface,\n  author = {anoma},\n  title = {namada-interface},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/namada-interface}\n}\n\n@misc{github-zkp-compiler-shootout,\n  author = {anoma},\n  title = {zkp-compiler-shootout},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/zkp-compiler-shootout}\n}\n\n@misc{github-homebrew-juvix,\n  author = {anoma},\n  title = {homebrew-juvix},\n  year = {2022},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  url = {https://github.com/anoma/homebrew-juvix}\n}\n</code></pre> Other literature <pre><code>  title={Heterogeneous Paxos: Technical Report},\n  author={Isaac Sheff and Xinwen Wang and Robbert van Renesse and Andrew C. Myers},\n  year={2020},\n  eprint={2011.08253},\n  archivePrefix={arXiv},\n  primaryClass={cs.DC}\n}\n\n@misc{karbyshevsheff2024heterogeneous,\n  title={Heterogeneous Paxos 2.0: the Specs},\n  author={Aleksandr Karbyshev and Isaac Sheff},\n  year={2024},\n  url={https://pomf2.lain.la/f/owqf7ws.pdf},\n}\n\n@misc{goes2024anoma,\n  author = {Christopher Goes},\n  title = {Anoma as the Universal Intent Machine for Ethereum},\n  year = {2024},\n  howpublished = {{Ethereum Research}},\n  note = {Draft},\n  url = {https://ethresear.ch/t/rfc-draft-anoma-as-the-universal-intent-machine-for-ethereum/19109},\n  urldate = {2024-06-17}\n}\n\n@inproceedings{Hewitt2006,\n  title     = {What Is Commitment? Physical, Organizational, and Social (Revised)},\n  author    = {Hewitt, Carl},\n  year      = 2007,\n  publisher = {Springer Berlin Heidelberg},\n  address   = {Berlin, Heidelberg},\n  pages     = {293--307}\n}\n\n@phdthesis{clinger1981,\n  title     = {Foundations of Actor Semantics},\n  author    = {William Douglas Clinger},\n  year      = 1981,\n  url       = {https://dspace.mit.edu/handle/1721.1/6935},\n  school    = {Massachusetts Institute of Technology (MIT)}\n}\n\n@inproceedings{Hewitt1973,\n  title     = {A Universal Modular Actor Formalism for Artificial Intelligence},\n  author    = {Carl Hewitt and Peter Bishop and Richard Steiger},\n  year      = 1973,\n  location  = {San Francisco, CA, USA},\n  publisher = {Morgan Kaufmann Publishers Inc.},\n  pages     = {235--245}\n}\n\n@book{Scott1976,\n  title     = {Toward a Mathematical Semantics for Computer Languages},\n  author    = {Dana Scott and Christopher Strachey},\n  year      = 1976,\n  publisher = {Prentice-Hall}\n}\n\n@book{Agha1986,\n  title     = {Actors: A Model of Concurrent Computation in Distributed Systems},\n  author    = {Gul A. Agha},\n  year      = 1986,\n  publisher = {MIT Press}\n}\n\n@article{agha-overview-actor-languages,\n  title     = {An overview of actor languages},\n  author    = {Agha, Gul},\n  year      = 1986,\n  month     = {jun},\n  journal   = {SIGPLAN Not.},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 21,\n  number    = 10,\n  pages     = {58\u201367},\n  doi       = {10.1145/323648.323743},\n  url       = {https://doi.org/10.1145/323648.323743},\n}\n\n@article{erlang,\n  title     = {The development of Erlang},\n  author    = {Armstrong, Joe},\n  year      = 1997,\n  month     = {aug},\n  journal   = {SIGPLAN Not.},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 32,\n  number    = 8,\n  pages     = {196\u2013203},\n  doi       = {10.1145/258949.258967},\n  url       = {https://doi.org/10.1145/258949.258967}\n}\n\n@book{milner-concurrency,\n  title     = {Communication and Concurrency},\n  author    = {Milner, R.},\n  year      = 1989,\n  publisher = {Prentice-Hall, Inc.},\n  address   = {USA}\n}\n\n@article{behavioural-timed-systems,\n  title     = {{Behavioural equivalences for timed systems}},\n  author    = {Tomasz Brengos and Marco Peressotti},\n  year      = 2019,\n  month     = Feb,\n  journal   = {{Logical Methods in Computer Science}},\n  volume    = {{Volume 15, Issue 1}},\n  doi       = {10.23638/LMCS-15(1:17)2019},\n  url       = {https://lmcs.episciences.org/5220}\n}\n\n@inproceedings{actario,\n  title     = {Actario: A framework for reasoning about actor systems},\n  author    = {Yasutake, Shohei and Watanabe, Takuo},\n  year      = 2015\n}\n\n@article{Talcott1998,\n  title     = {Composable Semantic Models for Actor Theories},\n  author    = {Talcott,  Carolyn L.},\n  year      = 1998,\n  journal   = {Higher Order Symbolic Computation},\n  publisher = {Springer Science and Business Media LLC},\n  volume    = 11,\n  number    = 3,\n  pages     = {281\u2013343},\n  doi       = {10.1023/a:1010042915896},\n  url       = {http://dx.doi.org/10.1023/A:1010042915896}\n}\n\n@article{lamport-global-states,\n  title     = {Distributed snapshots: determining global states of distributed systems},\n  author    = {Chandy, K. Mani and Lamport, Leslie},\n  year      = 1985,\n  month     = {feb},\n  journal   = {ACM Transactions on Computer Systems},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 3,\n  number    = 1,\n  pages     = {63\u201375},\n  doi       = {10.1145/214451.214456},\n  url       = {https://doi.org/10.1145/214451.214456},\n}\n\n@article{selectors-actors-2014,\n  title     = {Selectors: Actors with Multiple Guarded Mailboxes},\n  author    = {Imam,  Shams M. and Sarkar,  Vivek},\n  year      = 2014,\n  month     = oct,\n  publisher = {ACM},\n  journal   = {AGERE! '14: Proceedings of the 4th International Workshop on Programming based on Actors Agents and Decentralized Control},\n  series    = {SPLASH '14},\n  doi       = {10.1145/2687357.2687360},\n  url       = {http://dx.doi.org/10.1145/2687357.2687360},\n  collection = {SPLASH '14}\n}\n\n@article{special-delivery-mailbox-types-2023,\n  title     = {Special Delivery: Programming with Mailbox Types},\n  author    = {Fowler,  Simon and Attard,  Duncan Paul and Sowul,  Franciszek and Gay,  Simon J. and Trinder,  Phil},\n  year      = 2023,\n  month     = aug,\n  journal   = {Proceedings of the ACM on Programming Languages},\n  publisher = {Association for Computing Machinery (ACM)},\n  volume    = 7,\n  number    = {ICFP},\n  pages     = {78\u2013107},\n  doi       = {10.1145/3607832},\n  url       = {http://dx.doi.org/10.1145/3607832}\n}\n\n@article{there-is-no-now-2015,\n  title     = {There is No Now: Problems with simultaneity in distributed systems},\n  author    = {Sheehy, Justin},\n  year      = 2015,\n  month     = {mar},\n  journal   = {Queue},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 13,\n  number    = 3,\n  pages     = {20\u201327},\n  doi       = {10.1145/2742694.2745385},\n  url       = {https://doi.org/10.1145/2742694.2745385}\n}\n\n@article{why-local-clocks-are-easy-2016,\n  title     = {Why Logical Clocks are Easy: Sometimes all you need is the right language.},\n  author    = {Baquero, Carlos and Pregui\\c{c}a, Nuno},\n  year      = 2016,\n  month     = {feb},\n  journal   = {Queue},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 14,\n  number    = 1,\n  pages     = {53\u201369},\n  doi       = {10.1145/2898442.2917756},\n  url       = {https://doi.org/10.1145/2898442.2917756}\n}\n\n@article{lamport-time-clocks-1978,\n  title     = {Time, clocks, and the ordering of events in a distributed system},\n  author    = {Lamport, Leslie},\n  year      = 1978,\n  month     = {jul},\n  journal   = {Commun. ACM},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  volume    = 21,\n  number    = 7,\n  pages     = {558\u2013565},\n  doi       = {10.1145/359545.359563},\n  url       = {https://doi.org/10.1145/359545.359563},\n}\n\n@inproceedings{taxonomy-of-actor-models-2016,\n  title     = {43 years of actors: a taxonomy of actor models and their key properties},\n  author    = {De Koster, Joeri and Van Cutsem, Tom and De Meuter, Wolfgang},\n  year      = 2016,\n  location  = {Amsterdam, Netherlands},\n  publisher = {Association for Computing Machinery},\n  address   = {New York, NY, USA},\n  series    = {AGERE 2016},\n  pages     = {31\u201340},\n  doi       = {10.1145/3001886.3001890},\n  url       = {https://doi.org/10.1145/3001886.3001890},\n  booktitle = {Proceedings of the 6th International Workshop on Programming Based on Actors, Agents, and Decentralized Control}\n}\n\n@book{Nissanke1999,\n  title = {Formal Specification},\n  ISBN = {9781447107910},\n  url = {http://dx.doi.org/10.1007/978-1-4471-0791-0},\n  DOI = {10.1007/978-1-4471-0791-0},\n  publisher = {Springer London},\n  author = {Nissanke,  Nimal},\n  year = {1999}\n}\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/headers_and_other_conventions.html","title":"Headers and other Markdown conventions","text":"<ul> <li> <p>Use semantic headers to structure your content.</p> <ul> <li>Use <code>#</code> for the main title, <code>##</code> for the first-level header, <code>###</code> for the   second-level header.</li> <li>Only use up to the third level of headers. If you need more levels, consider   restructuring your content.</li> </ul> </li> </ul> <ul> <li> <p>Use sentence case for headers. For example,</p> <ul> <li>use \"How to use this glossary\" instead of \"How to Use This Glossary\", or,</li> <li>use \"Anoma protocol\" instead of  \"Anoma Protocol\", or</li> <li>use \"On engine systems for the Anoma Specification\" instead of \"On Engine   Systems For The Anoma Specification\".</li> </ul> </li> </ul> <ul> <li>Always add a front matter as described in Write using Markdown.</li> </ul> <ul> <li>The (Juvix) Markdown filenames should follow the convention as described in File naming conventions.</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/images.html","title":"Support for including images","text":"<p>Images should be stored in the <code>docs/images</code> folder. Use the File Naming Conventions also for naming images.</p> <p>Image handling in Markdown</p> <p>Use standard Markdown image syntax (<code>![Alt text](image.png)</code>) rather than HTML image tags. HTML image tags are not processed by MkDocs, are not validated, and may not work as expected. In particular, their <code>src</code> attribute is not processed by our image processing script.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/images.html#syntax","title":"Syntax","text":"<p>To add an image, apply the following syntax:</p> <pre><code>![Alt Text](logo.svg){: width=\"200\"}\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/images.html#displayed-image-example","title":"Displayed Image Example","text":"<p>The syntax above will render the image in your document like so:</p> <p></p> <p>Enhanced Image Display</p> <p>Use an HTML <code>&lt;figure&gt;</code> element with a <code>&lt;figcaption&gt;</code> for a refined presentation with captions. Markdown can also be used within the caption:</p> <pre><code>&lt;figure markdown=\"1\"&gt;\n\n  ![Alt Text](image-name.png)\n\n  &lt;figcaption markdown=\"span\"&gt;Image caption text can include *Markdown*!&lt;/figcaption&gt;\n&lt;/figure&gt;\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html","title":"Support for Wiki Links","text":"<p>Wiki links offer a simple method for citing and referencing other pages in the documentation without lengthy URLs. Wiki links are the preferred method for linking to other pages in the documentation, so please use them whenever possible.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#basic-syntax","title":"Basic Syntax","text":"<p>The basic syntax for a wiki link is:</p> <pre><code>page\n</code></pre> <p>Where:</p> <ul> <li><code>page</code> is the title of the target page</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#full-syntax","title":"Full Syntax","text":"<p>The full syntax for a wiki link is: Wiki Link Syntax<pre><code>  Custom caption\n</code></pre></p> <p>When resolving a wiki link, the system follows these rules:</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#page-title","title":"Page Title","text":"<p>(Mandatory) The 'page' in a wiki link refers to the title specified in the <code>nav</code> attribute of the <code>mkdocs.yml</code> file. For example,</p> mkdocs.yml<pre><code>nav:\n  - Home: index.md\n  - MyRef X: reference.md\n</code></pre> <p>provides the following wiki link:</p> <pre><code>MyRef X\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#path-hints","title":"Path Hints","text":"<p>(Optional) You can use path hints to specify the location of the file. The syntax is:</p> Path Hints<pre><code>page\n</code></pre> <p>Where:</p> <ul> <li><code>hintpath/to</code> is the path (or prefix) to the file</li> <li><code>page</code> is the title of the target page</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#anchors","title":"Anchors","text":"<p>(Optional) Use anchors to link to specific sections within a page. If the page does not have an anchor, the link would render as the caption provided, and you'll find a warning in the build process.</p> Anchors<pre><code>page\n</code></pre> <p>Where:</p> <ul> <li><code>page</code> is the title of the target page</li> <li><code>anchor</code> is a specific section within the page</li> </ul>","tags":["tutorial","conventions"]},{"location":"tutorial/md/links.html#custom-captions","title":"Custom captions","text":"<p>(Optional) Provide custom text to display for the link instead of the page title.</p> Custom Captions<pre><code>Custom caption\n</code></pre> <p>Where:</p> <ul> <li><code>page</code> is the title of the target page</li> <li><code>anchor</code> is a specific section within the page</li> </ul> <p>Captions can include icons, for example:</p> MarkdownPreview <pre><code>[:material-link: this is a caption with an icon](https://specs.anoma.net/pr-387/index.html)\n</code></pre> <p> this is a caption with an icon</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html","title":"Include code snippets","text":"","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html#code-snippets","title":"Code Snippets","text":"<p>Include excerpts from other files using the Snippet extension detailed here: PyMdown Extensions - Snippets.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html#excerpt-wrapping-syntax","title":"Excerpt Wrapping Syntax","text":"<p>Enclose the excerpt with the following tags:</p> <pre><code>&lt;!-- Start snippet --&gt;\n;--8&lt;-- [start:TAG]\n...\n;--8&lt;-- [end:TAG]\n&lt;!-- End snippet --&gt;\n</code></pre>","tags":["tutorial","conventions"]},{"location":"tutorial/md/snippets.html#snippet-inclusion-syntax","title":"Snippet Inclusion Syntax","text":"<p>To incorporate the excerpt elsewhere, specify its path and tag:</p> <pre><code>;--8&lt;-- \"path/to/file.ext:TAG\"\n</code></pre> <p>Following these practices ensures consistency, navigability, and professionalism in the Anoma documentation.</p>","tags":["tutorial","conventions"]},{"location":"tutorial/md/todos.html","title":"Add pending tasks with Todos admonition","text":"","tags":["tutorial","conventions"]},{"location":"tutorial/md/todos.html#todos","title":"Todos","text":"<p>Incorporate todos with the following syntax:</p> <pre><code>!!! todo\n\n    Content of the todo\n</code></pre> <p>The above renders as:</p> <p>Todo</p> <p>Content of the todo</p> <p>Info</p> <p>Be aware that todos are automatically removed from the online version. If you want to keep them, set <code>todos: True</code> in the front matter.</p>","tags":["tutorial","conventions"]}]}